{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import json\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import remove\n",
    "from pprint import pprint\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from gensim.models import KeyedVectors\n",
    "import word2vecReader as godin_embedding\n",
    "import fasttext\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [12,10]\n",
    "from base_learners import cnn,lstm,bi_lstm,cnn_bi_lstm,cnn_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    with open(filename,'r', errors='ignore') as fin:\n",
    "        lines = fin.readlines()\n",
    "    label = [int(x.split()[0]) for x in lines]\n",
    "    sentence = [' '.join(x.split()[1:]) for x in lines]\n",
    "    return label,sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels,train_sentences = load_data_from_file('dataset/sst2/stsa.binary.train')\n",
    "dev_label,dev_sentence = load_data_from_file('dataset/sst2/stsa.binary.dev')\n",
    "test_labels,test_sentences = load_data_from_file('dataset/sst2/stsa.binary.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = train_sentences+dev_sentence\n",
    "train_labels = train_labels+dev_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7792, 7792, 1821, 1821)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels),len(train_sentences),len(test_labels),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = len(set(train_labels))\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3738\n",
      "1 4054\n"
     ]
    }
   ],
   "source": [
    "for x in range(number_of_classes):\n",
    "    print(x,train_labels.count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 912\n",
      "1 909\n"
     ]
    }
   ],
   "source": [
    "for x in range(number_of_classes):\n",
    "    print(x,test_labels.count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_sentences = train_sentences[:500]\n",
    "# train_labels = train_labels[:500]\n",
    "# test_sentences=test_sentences[:100]\n",
    "# test_labels = test_labels[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(string.punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    # should have used translate but for some reason it breaks on my server\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = [clean_sentence(s) for s in train_sentences]\n",
    "testX = [clean_sentence(s) for s in test_sentences]\n",
    "trainY = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(line.split()) for line in trainX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 366., 1409., 1747., 1739., 1292.,  733.,  350.,  129.,   20.,\n",
       "           7.]),\n",
       " array([ 0.,  3.,  6.,  9., 12., 15., 18., 21., 24., 27., 30.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAJCCAYAAAA/XCqxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ca8990898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(max(lengths))\n",
    "plt.hist(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading Goding model.\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_google_word2vec(file_name):\n",
    "    print(\"Loading google news word2vec\")\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_embedding_matrix(model,dim):\n",
    "    #dim = 300 for google word2vec\n",
    "    #dim = 400 for godin\n",
    "    #dim = 100 for fast text\n",
    "    embedding_matrix = np.zeros((vocab_size,dim))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 25\n",
      "Vocabulary size: 15312\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(trainX)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "trainX = encode_text(tokenizer, trainX, max_len)\n",
    "testX = encode_text(tokenizer, testX, max_len)\n",
    "trainY = to_categorical(trainY,num_classes=number_of_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google news word2vec\n"
     ]
    }
   ],
   "source": [
    "# glove_model = load_GloVe_embedding('word_embeddings/glove.6B.300d.txt')\n",
    "# fast_text_model = load_fast_text_model(back_up_for_fasttext)\n",
    "# godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")\n",
    "word2vec_model= load_google_word2vec('../word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding_matrix_glove = get_GloVe_embedding_matrix(glove_model)\n",
    "embedding_matrix_word2vec = get_word_embedding_matrix(word2vec_model,300)\n",
    "# embedding_matrix_fast_text = get_word_embedding_matrix(fast_text_model,100)\n",
    "# embedding_matrix_godin = get_word_embedding_matrix(godin_model,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform',name='learning_rate')\n",
    "para_dropout = Categorical(categories=[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],name = 'dropout')\n",
    "# para_em = Categorical(categories=[embedding_matrix_godin,embedding_matrix_word2vec],name='em')\n",
    "para_em = Categorical(categories=['embedding_matrix_word2vec'],name='em')\n",
    "para_em_trainable_flag = Categorical(categories=[True,False],name='em_trainable_flag')\n",
    "para_batch_size = Categorical(categories=[8,16,32,64],name='batch_size')\n",
    "para_epoch = Categorical(categories=[5,10,15,20],name='epoch')\n",
    "para_n_hidden_layers = Integer(low=1,high=5,name = 'n_hidden_layers')\n",
    "\n",
    "para_units_out = Categorical(categories=[64,128,256,512], name='units_out')\n",
    "\n",
    "para_dropout_cnn_lstm = Categorical(categories=[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],name = 'dropout')\n",
    "\n",
    "# para_n_dense = Categorical(categories=[100,200,300,400], name='n_dense')\n",
    "# para_n_filters = Categorical(categories=[100,200,300],name='n_filters')\n",
    "# para_filter_size = Integer(low=1,high=6,name = 'filter_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_cnn = [para_learning_rate,para_dropout,para_n_dense,para_n_filters,para_filter_size,para_em,para_em_trainable_flag,para_batch_size,para_epoch,para_n_hidden_layers]\n",
    "parameters_lstm = [para_learning_rate,para_dropout,para_units_out,para_em,para_em_trainable_flag,para_batch_size,para_epoch,para_n_hidden_layers]\n",
    "# parameters_cnn_lstm = [para_learning_rate,para_dropout,para_dropout_cnn_lstm,para_units_out,para_n_filters,para_filter_size,para_em,para_em_trainable_flag,para_batch_size,para_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default_parameters_cnn = [0.0001,0.6,100,200,1,'embedding_matrix_word2vec',True,8,20]\n",
    "default_parameters_lstm = [0.001,0.5,128,'embedding_matrix_word2vec',True,32,10,2]\n",
    "# default_parameters_cnn_lstm = [0.001,0.2,0.2,128,100,5,embedding_matrix_word2vec,True,32,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = 1\n",
    "record = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##this will change based on the model\n",
    "@use_named_args(dimensions=parameters_lstm)\n",
    "def fitness(learning_rate,dropout,units_out,em,em_trainable_flag,batch_size,epoch,n_hidden_layers):\n",
    "    global key\n",
    "    global record\n",
    "    global number_of_classes\n",
    "    print('-----------------------------combination no={0}------------------'.format(key))\n",
    "    parameters = {\n",
    "            \"dropout\": 0.5,\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"units_out\": 64,\n",
    "            \"em\": embedding_matrix_word2vec,\n",
    "            \"em_trainable_flag\":True,\n",
    "            \"batch\": 32,\n",
    "            \"epoch\": 4,\n",
    "            \"n_hidden_layers\":int(n_hidden_layers)\n",
    "        }\n",
    "    \n",
    "    pprint(parameters)\n",
    "    \n",
    "    model = bi_gru(length=max_len,\n",
    "#              vocab_size=vocab_size,\n",
    "#              learning_rate=parameters_lstm_or_gru['learning_rate'],\n",
    "#              dropout=parameters_lstm_or_gru['dropout'],\n",
    "#              units_out=parameters_lstm_or_gru['units_out'],\n",
    "#              em=parameters_lstm_or_gru['em'],\n",
    "#              number_of_classes=number_of_classes,\n",
    "#              em_trainable_flag=parameters_lstm_or_gru['em_trainable_flag'])\n",
    "\n",
    "    history = model.fit(trainX,trainY,epochs=parameters[\"epoch\"],batch_size=parameters[\"batch\"])\n",
    "    pred = model.predict(testX)\n",
    "    pred_class = [np.argmax(x) for x in pred]\n",
    "    acc = accuracy_score(test_labels,pred_class)\n",
    "    print(acc)\n",
    "    record[key] = {}\n",
    "    record[key][\"parameter\"] = parameters\n",
    "    record[key][\"acc\"] = acc\n",
    "    with open(\"results/cnn.json\",'w')as fout:\n",
    "        json.dump(record,fout,indent=4)\n",
    "    key+=1\n",
    "    \n",
    "    del model\n",
    "    K.clear_session()\n",
    "    \n",
    "    return -acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------combination no=1------------------\n",
      "{'batch': 8,\n",
      " 'dropout': 0.6,\n",
      " 'em': 'embedding_matrix_word2vec',\n",
      " 'em_trainable_flag': True,\n",
      " 'epoch': 20,\n",
      " 'filter_size': 1,\n",
      " 'learning_rate': 0.0001,\n",
      " 'n_dense': 100,\n",
      " 'n_filters': 200}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 24, 300)           5130900   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 24, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 24, 200)           60200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 505       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,211,705\n",
      "Trainable params: 5,211,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4978 - acc: 0.7988\n",
      "Epoch 2/20\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.4849 - acc: 0.7998\n",
      "Epoch 3/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4748 - acc: 0.7995\n",
      "Epoch 4/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4610 - acc: 0.7989\n",
      "Epoch 5/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4493 - acc: 0.7995: 0s - loss: 0.4492 - acc: 0.79\n",
      "Epoch 6/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4387 - acc: 0.8004\n",
      "Epoch 7/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4318 - acc: 0.8002: 2s - loss: 0.431 - ETA: 1s - loss: 0.\n",
      "Epoch 8/20\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.4238 - acc: 0.8018\n",
      "Epoch 9/20\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.4211 - acc: 0.8015\n",
      "Epoch 10/20\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.4148 - acc: 0.8028\n",
      "Epoch 11/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.4106 - acc: 0.8061\n",
      "Epoch 12/20\n",
      "9645/9645 [==============================] - 77s 8ms/step - loss: 0.4031 - acc: 0.8077\n",
      "Epoch 13/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.3984 - acc: 0.8108\n",
      "Epoch 14/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3940 - acc: 0.8112\n",
      "Epoch 15/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3908 - acc: 0.8145\n",
      "Epoch 16/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3840 - acc: 0.8182\n",
      "Epoch 17/20\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.3802 - acc: 0.8191\n",
      "Epoch 18/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3750 - acc: 0.8230\n",
      "Epoch 19/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3707 - acc: 0.8244: 1s\n",
      "Epoch 20/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3652 - acc: 0.8293\n",
      "0.4638009049773756\n",
      "-----------------------------combination no=2------------------\n",
      "{'batch': 16,\n",
      " 'dropout': 0.6,\n",
      " 'em': 'embedding_matrix_word2vec',\n",
      " 'em_trainable_flag': True,\n",
      " 'epoch': 50,\n",
      " 'filter_size': 3,\n",
      " 'learning_rate': 0.01,\n",
      " 'n_dense': 300,\n",
      " 'n_filters': 100}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 24, 300)           5130900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 22, 100)           90100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               30300     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1505      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,252,805\n",
      "Trainable params: 5,252,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "9645/9645 [==============================] - 38s 4ms/step - loss: 0.4952 - acc: 0.7957\n",
      "Epoch 2/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4897 - acc: 0.7984\n",
      "Epoch 3/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4913 - acc: 0.7998\n",
      "Epoch 4/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 5/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 6/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 7/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4904 - acc: 0.8000\n",
      "Epoch 8/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 9/50\n",
      "9645/9645 [==============================] - 39s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 10/50\n",
      "9645/9645 [==============================] - 38s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 11/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4908 - acc: 0.8000\n",
      "Epoch 12/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 13/50\n",
      "9645/9645 [==============================] - 37s 4ms/step - loss: 0.4904 - acc: 0.8000\n",
      "Epoch 14/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 15/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4906 - acc: 0.8000\n",
      "Epoch 16/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 17/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4904 - acc: 0.8000\n",
      "Epoch 18/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 19/50\n",
      "9645/9645 [==============================] - 37s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 20/50\n",
      "7616/9645 [======================>.......] - ETA: 8s - loss: 0.4900 - acc: 0.8000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-59232f39866f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             x0=default_parameters_cnn)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-55699580de94>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(learning_rate, dropout, n_dense, n_filters, filter_size, em, em_trainable_flag, batch_size, epoch)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 em_trainable_flag=parameters['em_trainable_flag'])\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mpred_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=parameters_cnn,\n",
    "                            acq_func='EI',\n",
    "                            n_calls=11,\n",
    "                            x0=default_parameters_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters_cnn = {\n",
    "#             \"n_dense\": 250,\n",
    "#             \"dropout\": 0.2,\n",
    "#             \"learning_rate\": 0.001,\n",
    "#             \"n_filters\": 100,\n",
    "#             \"filter_size\": 5,\n",
    "#             \"em\": embedding_matrix_word2vec,\n",
    "#             \"em_trainable_flag\":True,\n",
    "#             \"batch\": 32,\n",
    "#             \"epoch\": 5\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters_lstm_or_gru = {\n",
    "#             \"dropout\": 0.5,\n",
    "#             \"learning_rate\": 0.001,\n",
    "#             \"units_out\": 64,\n",
    "#             \"em\": embedding_matrix_word2vec,\n",
    "#             \"em_trainable_flag\":True,\n",
    "#             \"batch\": 32,\n",
    "#             \"epoch\": 4\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters_cnn_lstm_or_gru = {\n",
    "#             \"n_filters\": 100,\n",
    "#             \"filter_size\": 5,\n",
    "#             \"conv_dropout\": 0.5,\n",
    "#             \"l_or_g_dropout\":0.5,\n",
    "#             \"learning_rate\": 0.001,\n",
    "#             \"units_out\": 64,\n",
    "#             \"em\": embedding_matrix_word2vec,\n",
    "#             \"em_trainable_flag\":True,\n",
    "#             \"batch\": 32,\n",
    "#             \"epoch\": 4\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = cnn(length=max_len,\n",
    "#             vocab_size=vocab_size,\n",
    "#             n_dense=parameters_cnn['n_dense'],\n",
    "#             dropout=parameters_cnn['dropout'],\n",
    "#             learning_rate=parameters_cnn['learning_rate'],\n",
    "#             n_filters=parameters_cnn['n_filters'],\n",
    "#             filter_size=parameters_cnn['filter_size'],\n",
    "#             em = parameters_cnn['em'],\n",
    "#             free_em_dim=parameters_cnn['free_em_dim'],\n",
    "#             number_of_classes=number_of_classes,\n",
    "#             em_trainable_flag=parameters_cnn['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = bi_gru(length=max_len,\n",
    "#              vocab_size=vocab_size,\n",
    "#              learning_rate=parameters_lstm_or_gru['learning_rate'],\n",
    "#              dropout=parameters_lstm_or_gru['dropout'],\n",
    "#              units_out=parameters_lstm_or_gru['units_out'],\n",
    "#              em=parameters_lstm_or_gru['em'],\n",
    "#              number_of_classes=number_of_classes,\n",
    "#              em_trainable_flag=parameters_lstm_or_gru['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = cnn_lstm(length=max_len,\n",
    "#                     vocab_size=vocab_size,\n",
    "#                     n_filters=parameters_cnn_lstm_or_gru['n_filters'],\n",
    "#                     filter_size=parameters_cnn_lstm_or_gru['filter_size'],\n",
    "#                     em=parameters_cnn_lstm_or_gru['em'],\n",
    "#                     number_of_classes=number_of_classes,\n",
    "#                     em_trainable_flag=parameters_cnn_lstm_or_gru['em_trainable_flag'],\n",
    "#                     learning_rate=parameters_cnn_lstm_or_gru['learning_rate'],\n",
    "#                     conv_dropout=parameters_cnn_lstm_or_gru['conv_dropout'],\n",
    "#                     l_or_g_dropout=parameters_cnn_lstm_or_gru['l_or_g_dropout'],\n",
    "#                     units_out=parameters_cnn_lstm_or_gru['units_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
