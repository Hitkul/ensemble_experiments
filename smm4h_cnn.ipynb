{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/hitkul/anaconda3/envs/ps3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "from gensim.models import KeyedVectors\n",
    "import word2vecReader as godin_embedding\n",
    "import fasttext\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,Embedding\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from random import uniform,choice\n",
    "from os import remove\n",
    "import re\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    data = pd.read_csv(filename, sep=\"\\t\", header=None)\n",
    "    data.columns = [\"tweet_id\", \"username\", \"database_id\", \"class\",\"tweet\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = load_data_from_file('dataset/smm4h/personal_intake_tweets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_data = load_data_from_file('dataset/smm4h/personal_intake_tweets_dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = train_data['tweet'].tolist()+dev_data['tweet'].tolist()\n",
    "train_labels = train_data['class'].tolist()+dev_data['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9107, 9107)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences),len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1743, 2837, 4527)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.count(1),train_labels.count(2),train_labels.count(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    #for PYTHON 2.7\n",
    "    #tokens = [w.translate(None, string.punctuation) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning train data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning train data\")\n",
    "trainX = [clean_sentence(s) for s in train_sentences]\n",
    "trainY = np.array([l-1 for l in train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = [len(s.split()) for s in trainX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "881"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAIMCAYAAAAKDkGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np0Y7Us6rh1IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f03bdce8898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(length,bins=[0,10,20,30,40])\n",
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading GloVe embedding\n",
    "def load_GloVe_embedding(file_name):\n",
    "    print('Loading GloVe word vectors.')\n",
    "    embeddings_index = dict()\n",
    "    f = open(file_name)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "def get_GloVe_embedding_matrix(embeddings_index):\n",
    "    embedding_matrix = np.zeros((vocab_size, 300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fast text word embedding\n",
    "def load_fast_text_model(sentences):\n",
    "    try:\n",
    "        m = fasttext.load_model('word_embeddings/fast_text_model.bin')\n",
    "        print(\"trained model loaded\")\n",
    "        return m\n",
    "    except:\n",
    "        print(\"traning new model\")\n",
    "        with open('temp_file.txt','w') as temp_file:\n",
    "            for sentence in sentences:\n",
    "                temp_file.write(sentence)\n",
    "        m = fasttext.cbow('temp_file.txt','word_embeddings/fast_text_model')\n",
    "        remove('temp_file.txt')\n",
    "        print('model trained')\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fast_text_matrix(model):\n",
    "    embedding_matrix = np.zeros((vocab_size,100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading godin word embedding\n",
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading Goding model.\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_godin_embedding_matrix(model):\n",
    "    embedding_matrix = np.zeros((vocab_size,400))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading Google Word2Vec\n",
    "def load_google_word2vec(file_name):\n",
    "    print(\"Loading google news word2vec\")\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word2vec_embedding_matrix(model):\n",
    "    embedding_matrix = np.zeros((vocab_size,300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_model(length,vocab_size,n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,free_em_dim,em_trainable_flag_c1,em_trainable_flag_c2,em_trainable_flag_c3):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    if em_c1 == 'free':\n",
    "        embedding1 = Embedding(vocab_size, free_em_dim)(inputs1)\n",
    "    else:\n",
    "        embedding1 = Embedding(vocab_size, len(eval(em_c1)[0]), weights = [eval(em_c1)],input_length=length,trainable = em_trainable_flag_c1)(inputs1)\n",
    "    \n",
    "    conv1 = Conv1D(filters=n_filters, kernel_size=filter_size_c1, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(dropout)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    if em_c2 == 'free':\n",
    "        embedding2 = Embedding(vocab_size, free_em_dim)(inputs2)\n",
    "    else:\n",
    "        embedding2 = Embedding(vocab_size, len(eval(em_c2)[0]), weights = [eval(em_c2)],input_length=length,trainable = em_trainable_flag_c2)(inputs2)\n",
    "    conv2 = Conv1D(filters=n_filters, kernel_size=filter_size_c2, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(dropout)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    if em_c3 == 'free':\n",
    "        embedding3 = Embedding(vocab_size, free_em_dim)(inputs3)\n",
    "    else:\n",
    "        embedding3 = Embedding(vocab_size, len(eval(em_c3)[0]), weights = [eval(em_c3)],input_length=length,trainable = em_trainable_flag_c3)(inputs3)\n",
    "    conv3 = Conv1D(filters=n_filters, kernel_size=filter_size_c3, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(dropout)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(n_dense, activation='relu')(merged)\n",
    "    outputs = Dense(3, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    # summarize\n",
    "#     print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 150\n",
      "Vocabulary size: 10940\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(trainX)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "trainX = encode_text(tokenizer, trainX, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google news word2vec\n"
     ]
    }
   ],
   "source": [
    "# glove_model = load_GloVe_embedding('word_embeddings/glove.6B.300d.txt')\n",
    "# fast_text_model = load_fast_text_model(train_sentences)\n",
    "# godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")\n",
    "word2vec_model= load_google_word2vec('word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding_matrix_glove = get_GloVe_embedding_matrix(glove_model)\n",
    "embedding_matrix_word2vec = get_word2vec_embedding_matrix(word2vec_model)\n",
    "# embedding_matrix_fast_text = get_fast_text_matrix(fast_text_model)\n",
    "# embedding_matrix_godin = get_godin_embedding_matrix(godin_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform',name='learning_rate')\n",
    "\n",
    "para_dropout = Real(low=0.4, high=0.9,name = 'dropout')\n",
    "\n",
    "para_n_dense = Categorical(categories=[100,200,300,400], name='n_dense')\n",
    "\n",
    "para_n_filters = Categorical(categories=[100,200,300,400],name='n_filters')\n",
    "\n",
    "para_filter_size_c1 = Integer(low=1,high=6,name = 'filter_size_c1')\n",
    "para_filter_size_c2 = Integer(low=1,high=6,name = 'filter_size_c2')\n",
    "para_filter_size_c3 = Integer(low=1,high=6,name = 'filter_size_c3')\n",
    "\n",
    "para_em_c1 = Categorical(categories=['embedding_matrix_fast_text','embedding_matrix_godin','embedding_matrix_word2vec','embedding_matrix_glove','free'],name='em_c1')\n",
    "para_em_c2 = Categorical(categories=['embedding_matrix_fast_text','embedding_matrix_godin','embedding_matrix_word2vec','embedding_matrix_glove','free'],name='em_c2')\n",
    "para_em_c3 = Categorical(categories=['embedding_matrix_fast_text','embedding_matrix_godin','embedding_matrix_word2vec','embedding_matrix_glove','free'],name='em_c3')\n",
    "\n",
    "para_em_trainable_flag_c1 = Categorical(categories=[True,False],name='em_trainable_flag_c1')\n",
    "para_em_trainable_flag_c2 = Categorical(categories=[True,False],name='em_trainable_flag_c2')\n",
    "para_em_trainable_flag_c3 = Categorical(categories=[True,False],name='em_trainable_flag_c3')\n",
    "\n",
    "para_free_em_dim = Categorical(categories=[100,300,400],name='free_em_dim')\n",
    "\n",
    "para_batch_size = Categorical(categories=[8,16,32,64],name='batch_size')\n",
    "\n",
    "para_epoch = Categorical(categories=[10,20,30,50,100],name='epoch')\n",
    "\n",
    "\n",
    "parameters = [para_learning_rate,para_dropout,para_n_dense,para_n_filters,para_filter_size_c1,para_filter_size_c2,para_filter_size_c3,para_em_c1,para_em_c2,para_em_c3,para_em_trainable_flag_c1,para_em_trainable_flag_c2,para_em_trainable_flag_c3,para_free_em_dim,para_batch_size,para_epoch]\n",
    "\n",
    "default_parameters = [0.0071353667446707675,0.5777195655120914,400,100,6,4,4,'embedding_matrix_word2vec','embedding_matrix_word2vec','embedding_matrix_word2vec',False,True,False,100,16,10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = 1\n",
    "record = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=parameters)\n",
    "def fitness(learning_rate,dropout,n_dense,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,em_trainable_flag_c1,em_trainable_flag_c2,em_trainable_flag_c3,free_em_dim,batch_size,epoch):\n",
    "    global key\n",
    "    global record\n",
    "    print('-----------------------------combination no={0}------------------'.format(key))\n",
    "    \n",
    "    parameters = {\n",
    "            \"n_dense\": n_dense,\n",
    "            \"dropout\": dropout,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"n_filters\": n_filters,\n",
    "            \"filter_size_c1\": filter_size_c1,\n",
    "            \"filter_size_c2\": filter_size_c2,\n",
    "            \"filter_size_c3\": filter_size_c3,\n",
    "            \"em_c1\": em_c1,\n",
    "            \"em_c2\": em_c2,\n",
    "            \"em_c3\": em_c3,\n",
    "            \"free_em_dim\": free_em_dim,\n",
    "            \"em_trainable_flag_c1\": em_trainable_flag_c1,\n",
    "            \"em_trainable_flag_c2\": em_trainable_flag_c2,\n",
    "            \"em_trainable_flag_c3\": em_trainable_flag_c3,\n",
    "            \"batch\": batch_size,\n",
    "            \"epoch\": epoch\n",
    "        }\n",
    "    \n",
    "    \n",
    "    pprint(parameters)\n",
    "    \n",
    "    itr = 1\n",
    "    f1_record = []\n",
    "    p_record = []\n",
    "    r_record = []\n",
    "    itr_record = {}\n",
    "    for train,test in kfold.split(trainX,trainY):\n",
    "        print(\"k fold validation itr == {0}\".format(itr))\n",
    "        X = trainX[train]\n",
    "        Y = to_categorical(trainY[train],num_classes=3)\n",
    "        X_ = trainX[test]\n",
    "        Y_ = list(trainY[test])\n",
    "        model = define_model(length = max_len,\n",
    "                             vocab_size=vocab_size,\n",
    "                             n_dense = parameters[\"n_dense\"],\n",
    "                             dropout = parameters[\"dropout\"],\n",
    "                             learning_rate = parameters[\"learning_rate\"],\n",
    "                             n_filters = parameters[\"n_filters\"],\n",
    "                             filter_size_c1 = parameters[\"filter_size_c1\"],\n",
    "                             filter_size_c2 = parameters[\"filter_size_c2\"],\n",
    "                             filter_size_c3 = parameters[\"filter_size_c3\"],\n",
    "                             em_c1 = parameters[\"em_c1\"],\n",
    "                             em_c2 = parameters[\"em_c1\"],\n",
    "                             em_c3 = parameters[\"em_c1\"],\n",
    "                             free_em_dim = parameters[\"free_em_dim\"],\n",
    "                             em_trainable_flag_c1 = parameters[\"em_trainable_flag_c1\"],\n",
    "                             em_trainable_flag_c2 = parameters[\"em_trainable_flag_c2\"],\n",
    "                             em_trainable_flag_c3 = parameters[\"em_trainable_flag_c3\"])\n",
    "        history = model.fit([X,X,X],Y,epochs=parameters[\"epoch\"],batch_size=parameters[\"batch\"])\n",
    "        pred = model.predict([X_,X_,X_])\n",
    "        pred_labels = [x.argmax() for x in pred]\n",
    "\n",
    "        f1 = f1_score(Y_,pred_labels,labels=[0,1],average='micro')\n",
    "        p = precision_score(Y_,pred_labels,labels=[0,1],average='micro')\n",
    "        r = recall_score(Y_,pred_labels,labels=[0,1],average='micro')\n",
    "        print(f1,p,r)\n",
    "        f1_record.append(f1)\n",
    "        p_record.append(p)\n",
    "        r_record.append(r)\n",
    "        itr_record[itr] = {}\n",
    "        itr_record[itr][\"f1\"] = f1\n",
    "        itr_record[itr][\"p\"] = p\n",
    "        itr_record[itr][\"r\"] = r\n",
    "        model.save('models/'+str(key)+'_'+str(itr)+'.h5')\n",
    "        itr+=1\n",
    "    record[key] = {}\n",
    "    record[key][\"parameter\"] = parameters\n",
    "    mean_f1 = np.mean(f1_record)\n",
    "    record[key][\"mean_f1\"] = mean_f1\n",
    "    record[key][\"itr_record\"] = itr_record\n",
    "\n",
    "    with open(\"models/record.json\",'w')as fout:\n",
    "        json.dump(record,fout,indent=4)\n",
    "    key+=1\n",
    "    \n",
    "    del model\n",
    "    K.clear_session()\n",
    "    \n",
    "    return -mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------combination no=1------------------\n",
      "{'batch': 16,\n",
      " 'dropout': 0.5777195655120914,\n",
      " 'em_c1': 'embedding_matrix_word2vec',\n",
      " 'em_c2': 'embedding_matrix_word2vec',\n",
      " 'em_c3': 'embedding_matrix_word2vec',\n",
      " 'em_trainable_flag_c1': False,\n",
      " 'em_trainable_flag_c2': True,\n",
      " 'em_trainable_flag_c3': False,\n",
      " 'epoch': 10,\n",
      " 'filter_size_c1': 6,\n",
      " 'filter_size_c2': 4,\n",
      " 'filter_size_c3': 4,\n",
      " 'free_em_dim': 100,\n",
      " 'learning_rate': 0.0071353667446707675,\n",
      " 'n_dense': 400,\n",
      " 'n_filters': 100}\n",
      "k fold validation itr == 1\n",
      "Epoch 1/10\n",
      "7284/7284 [==============================] - 127s 17ms/step - loss: 0.5648 - acc: 0.7275\n",
      "Epoch 2/10\n",
      "2928/7284 [===========>..................] - ETA: 1:17 - loss: 0.4739 - acc: 0.7894"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-f5b44a4ceba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             x0=default_parameters)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# User suggested points at which to evaluate the objective first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0mn_calls\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-b04ed1223c67>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(learning_rate, dropout, n_dense, n_filters, filter_size_c1, filter_size_c2, filter_size_c3, em_c1, em_c2, em_c3, em_trainable_flag_c1, em_trainable_flag_c2, em_trainable_flag_c3, free_em_dim, batch_size, epoch)\u001b[0m\n\u001b[1;32m     54\u001b[0m                              \u001b[0mem_trainable_flag_c2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"em_trainable_flag_c2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                              em_trainable_flag_c3 = parameters[\"em_trainable_flag_c3\"])\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=parameters,\n",
    "                            acq_func='EI',\n",
    "                            n_calls=11,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_parameters():\n",
    "#     #range values\n",
    "#     para_n_dense = [100,200,300,400]\n",
    "#     para_n_filters = [100,200,300,400]\n",
    "#     para_filter_size = [1,2,3,4,5,6]\n",
    "# #     para_em = ['embedding_matrix_fast_text','embedding_matrix_godin','embedding_matrix_word2vec','embedding_matrix_glove','free']\n",
    "#     para_em = ['embedding_matrix_word2vec']\n",
    "#     para_free_em_dim = [100,300,400]\n",
    "#     para_em_trainable_flag = [True,False]\n",
    "#     para_batch_size = [8,16,32,64]\n",
    "# #     para_epoc = [10,30,60,100]\n",
    "#     para_epoc = [10]\n",
    "# #     para_batch_size = [64]\n",
    "#     #selecting_random_value\n",
    "#     parameters = {\"n_dense\": choice(para_n_dense),\n",
    "#             \"dropout\": uniform(0.4, 0.9),\n",
    "#             \"learning_rate\": uniform(0.0001, 0.01),\n",
    "#             \"n_filters\": choice(para_n_filters),\n",
    "#             \"filter_size_c1\": choice(para_filter_size),\n",
    "#             \"filter_size_c2\": choice(para_filter_size),\n",
    "#             \"filter_size_c3\": choice(para_filter_size),\n",
    "#             \"em_c1\": choice(para_em),\n",
    "#             \"em_c2\": choice(para_em),\n",
    "#             \"em_c3\": choice(para_em),\n",
    "#             \"free_em_dim\": choice(para_free_em_dim),\n",
    "#             \"em_trainable_flag_c1\": choice(para_em_trainable_flag),\n",
    "#             \"em_trainable_flag_c2\": choice(para_em_trainable_flag),\n",
    "#             \"em_trainable_flag_c3\": choice(para_em_trainable_flag),\n",
    "#             \"batch\": choice(para_batch_size),\n",
    "#             \"epoch\": choice(para_epoc)\n",
    "#         }\n",
    "#     return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for _ in range(number_of_models):\n",
    "#     itr = 1\n",
    "#     f1_record = []\n",
    "#     p_record = []\n",
    "#     r_record = []\n",
    "#     itr_record = {}\n",
    "#     parameters = get_parameters()\n",
    "#     parameters = {\n",
    "#             \"n_dense\": 400,\n",
    "#             \"dropout\": 0.5777195655120914,\n",
    "#             \"learning_rate\": 0.0071353667446707675,\n",
    "#             \"n_filters\": 100,\n",
    "#             \"filter_size_c1\": 6,\n",
    "#             \"filter_size_c2\": 4,\n",
    "#             \"filter_size_c3\": 4,\n",
    "#             \"em_c1\": \"embedding_matrix_word2vec\",\n",
    "#             \"em_c2\": \"embedding_matrix_word2vec\",\n",
    "#             \"em_c3\": \"embedding_matrix_word2vec\",\n",
    "#             \"free_em_dim\": 400,\n",
    "#             \"em_trainable_flag_c1\": False,\n",
    "#             \"em_trainable_flag_c2\": True,\n",
    "#             \"em_trainable_flag_c3\": False,\n",
    "#             \"batch\": 16,\n",
    "#             \"epoch\": 1\n",
    "#         }\n",
    "#     print(\"model number {0}\".format(key))\n",
    "#     print(parameters)\n",
    "#     for train,test in kfold.split(trainX,trainY):\n",
    "#         print(\"k fold validation itr == {0}\".format(itr))\n",
    "#         X = trainX[train]\n",
    "#         Y = to_categorical(trainY[train],num_classes=3)\n",
    "#         X_ = trainX[test]\n",
    "#         Y_ = list(trainY[test])\n",
    "#         model = define_model(length = max_len,\n",
    "#                              vocab_size=vocab_size,\n",
    "#                              n_dense = parameters[\"n_dense\"],\n",
    "#                              dropout = parameters[\"dropout\"],\n",
    "#                              learning_rate = parameters[\"learning_rate\"],\n",
    "#                              n_filters = parameters[\"n_filters\"],\n",
    "#                              filter_size_c1 = parameters[\"filter_size_c1\"],\n",
    "#                              filter_size_c2 = parameters[\"filter_size_c2\"],\n",
    "#                              filter_size_c3 = parameters[\"filter_size_c3\"],\n",
    "#                              em_c1 = parameters[\"em_c1\"],\n",
    "#                              em_c2 = parameters[\"em_c1\"],\n",
    "#                              em_c3 = parameters[\"em_c1\"],\n",
    "#                              free_em_dim = parameters[\"free_em_dim\"],\n",
    "#                              em_trainable_flag_c1 = parameters[\"em_trainable_flag_c1\"],\n",
    "#                              em_trainable_flag_c2 = parameters[\"em_trainable_flag_c2\"],\n",
    "#                              em_trainable_flag_c3 = parameters[\"em_trainable_flag_c3\"])\n",
    "#         history = model.fit([X,X,X],Y,epochs=parameters[\"epoch\"],batch_size=parameters[\"batch\"])\n",
    "#         pred = model.predict([X_,X_,X_])\n",
    "#         pred_labels = [x.argmax() for x in pred]\n",
    "#         for foo in zip(Y_[:50],pred_labels[:50]):\n",
    "#             print(foo)\n",
    "#         f1 = f1_score(Y_,pred_labels,labels=[0,1],average='micro')\n",
    "#         p = precision_score(Y_,pred_labels,labels=[0,1],average='micro')\n",
    "#         r = recall_score(Y_,pred_labels,labels=[0,1],average='micro')\n",
    "#         print(f1,p,r)\n",
    "#         f1_record.append(f1)\n",
    "#         p_record.append(p)\n",
    "#         r_record.append(r)\n",
    "#         itr_record[itr] = {}\n",
    "#         itr_record[itr][\"f1\"] = f1\n",
    "#         itr_record[itr][\"p\"] = p\n",
    "#         itr_record[itr][\"r\"] = r\n",
    "#         model.save('models/'+str(key)+'_'+str(itr)+'.h5')\n",
    "#         itr+=1\n",
    "#     record[key] = {}\n",
    "#     record[key][\"parameter\"] = parameters\n",
    "#     record[key][\"mean_f1\"] = np.mean(f1_record)\n",
    "#     record[key][\"itr_record\"] = itr_record\n",
    "\n",
    "#     with open(\"models/record.json\",'w')as fout:\n",
    "#         json.dump(record,fout,indent=4)\n",
    "#     key+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
