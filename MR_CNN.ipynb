{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "from gensim.models import KeyedVectors\n",
    "import word2vecReader as godin_embedding\n",
    "import fasttext\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,Embedding\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename,'r') as fin:\n",
    "        return json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dict = load_data(\"dataset/final_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(dataset_dict):\n",
    "    review = [dataset_dict[key][\"review\"] for key in dataset_dict.keys()]\n",
    "    polarity = [dataset_dict[key][\"polarity\"] for key in dataset_dict.keys()]\n",
    "    return review, polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "review, polarity = extract_data(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review),len(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    #for PYTHON 2.7\n",
    "    #tokens = [w.translate(None, string.punctuation) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = [clean_sentence(s) for s in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = [len(s) for s in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([117., 715., 734., 283., 105.,  32.,  11.,   2.,   0.,   1.]),\n",
       " array([   52. ,  1095.3,  2138.6,  3181.9,  4225.2,  5268.5,  6311.8,\n",
       "         7355.1,  8398.4,  9441.7, 10485. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAIMCAYAAAAHEDHqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ea91d6940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 6500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading GloVe embedding\n",
    "def load_GloVe_embedding(file_name):\n",
    "    print('Loading GloVe word vectors.')\n",
    "    embeddings_index = dict()\n",
    "    f = open(file_name)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "def get_GloVe_embedding_matrix(embeddings_index):\n",
    "    embedding_matrix = np.zeros((vocab_size, 300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fast text word embedding\n",
    "def load_fast_text_model(sentences):\n",
    "    try:\n",
    "        m = fasttext.load_model('word_embeddings/fast_text_model.bin')\n",
    "        print(\"trained model loaded\")\n",
    "        return m\n",
    "    except:\n",
    "        print(\"traning new model\")\n",
    "        with open('temp_file.txt','w') as temp_file:\n",
    "            for sentence in sentences:\n",
    "                temp_file.write(sentence)\n",
    "        m = fasttext.cbow('temp_file.txt','word_embeddings/fast_text_model')\n",
    "        remove('temp_file.txt')\n",
    "        print('model trained')\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fast_text_matrix(model):\n",
    "    embedding_matrix = np.zeros((vocab_size,100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading godin word embedding\n",
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading Goding model.\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_godin_embedding_matrix(model):\n",
    "    embedding_matrix = np.zeros((vocab_size,400))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading Google Word2Vec\n",
    "def load_google_word2vec(file_name):\n",
    "    print(\"Loading google news word2vec\")\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word2vec_embedding_matrix(model):\n",
    "    embedding_matrix = np.zeros((vocab_size,300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(length,vocab_size,n_dense,dropout,learning_rate,n_filters,filter_size_c1,filter_size_c2,filter_size_c3,em_c1,em_c2,em_c3,free_em_dim,em_trainable_flag_c1,em_trainable_flag_c2,em_trainable_flag_c3):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    if em_c1 == 'free':\n",
    "        embedding1 = Embedding(vocab_size, free_em_dim)(inputs1)\n",
    "    else:\n",
    "        embedding1 = Embedding(vocab_size, len(eval(em_c1)[0]), weights = [eval(em_c1)],input_length=length,trainable = em_trainable_flag_c1)(inputs1)\n",
    "    \n",
    "    conv1 = Conv1D(filters=n_filters, kernel_size=filter_size_c1, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(dropout)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    if em_c2 == 'free':\n",
    "        embedding2 = Embedding(vocab_size, free_em_dim)(inputs2)\n",
    "    else:\n",
    "        embedding2 = Embedding(vocab_size, len(eval(em_c2)[0]), weights = [eval(em_c2)],input_length=length,trainable = em_trainable_flag_c2)(inputs2)\n",
    "    conv2 = Conv1D(filters=n_filters, kernel_size=filter_size_c2, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(dropout)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    if em_c3 == 'free':\n",
    "        embedding3 = Embedding(vocab_size, free_em_dim)(inputs3)\n",
    "    else:\n",
    "        embedding3 = Embedding(vocab_size, len(eval(em_c3)[0]), weights = [eval(em_c3)],input_length=length,trainable = em_trainable_flag_c3)(inputs3)\n",
    "    conv3 = Conv1D(filters=n_filters, kernel_size=filter_size_c3, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(dropout)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(n_dense, activation='relu')(merged)\n",
    "    outputs = Dense(2, activation='softmax')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    # summarize\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = review\n",
    "Y = polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 6500\n",
      "Vocabulary size: 46558\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(X)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "X = encode_text(tokenizer, X, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = to_categorical(Y,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
