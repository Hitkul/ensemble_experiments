{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import json\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import remove\n",
    "from pprint import pprint\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from gensim.models import KeyedVectors\n",
    "import word2vecReader as godin_embedding\n",
    "import fasttext\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [12,10]\n",
    "from base_learners import cnn,lstm,gru,bi_lstm,bi_gru,cnn_bi_gru,cnn_bi_lstm,cnn_gru,cnn_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    with open(filename,'r', errors='ignore') as fin:\n",
    "        lines = fin.readlines()\n",
    "    label = [int(x.split()[0]) for x in lines]\n",
    "    sentence = [' '.join(x.split()[1:]) for x in lines]\n",
    "    return label,sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels,train_sentences = load_data_from_file('dataset/sst1/stsa.fine.train')\n",
    "dev_label,dev_sentence = load_data_from_file('dataset/sst1/stsa.fine.dev')\n",
    "test_labels,test_sentences = load_data_from_file('dataset/sst1/stsa.fine.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = train_sentences+dev_sentence\n",
    "train_labels = train_labels+dev_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9645, 9645, 2210, 2210)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels),len(train_sentences),len(test_labels),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = len(set(train_labels))\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1231\n",
      "1 2507\n",
      "2 1853\n",
      "3 2601\n",
      "4 1453\n"
     ]
    }
   ],
   "source": [
    "for x in range(number_of_classes):\n",
    "    print(x,train_labels.count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 279\n",
      "1 633\n",
      "2 389\n",
      "3 510\n",
      "4 399\n"
     ]
    }
   ],
   "source": [
    "for x in range(number_of_classes):\n",
    "    print(x,test_labels.count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(string.punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    # should have used translate but for some reason it breaks on my server\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = [clean_sentence(s) for s in train_sentences]\n",
    "testX = [clean_sentence(s) for s in test_sentences]\n",
    "trainY = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "back_up_for_fasttext = trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(line.split()) for line in trainX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 503., 1766., 2173., 2127., 1592.,  883.,  415.,  156.,   22.,\n",
       "           8.]),\n",
       " array([ 0.,  3.,  6.,  9., 12., 15., 18., 21., 24., 27., 30.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAJCCAYAAAA/XCqxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18baa37828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(max(lengths))\n",
    "plt.hist(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_GloVe_embedding(file_name):\n",
    "    print('Loading GloVe word vectors.')\n",
    "    embeddings_index = dict()\n",
    "    f = open(file_name)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_GloVe_embedding_matrix(embeddings_index):\n",
    "    embedding_matrix = np.zeros((vocab_size, 300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fast_text_model(sentences):\n",
    "    try:\n",
    "        m = fasttext.load_model('fast_text_model.bin')\n",
    "        print(\"trained model loaded\")\n",
    "        return m\n",
    "    except:\n",
    "        print(\"traning new model\")\n",
    "        with open('temp_file.txt','w') as temp_file:\n",
    "            for sentence in sentences:\n",
    "                temp_file.write(sentence)\n",
    "        m = fasttext.cbow('temp_file.txt','fast_text_model')\n",
    "        remove('temp_file.txt')\n",
    "        print('model trained')\n",
    "        return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading Goding model.\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_google_word2vec(file_name):\n",
    "    print(\"Loading google news word2vec\")\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_embedding_matrix(model,dim):\n",
    "    #dim = 300 for google word2vec\n",
    "    #dim = 400 for godin\n",
    "    #dim = 100 for fast text\n",
    "    embedding_matrix = np.zeros((vocab_size,dim))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 24\n",
      "Vocabulary size: 17103\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(trainX)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "trainX = encode_text(tokenizer, trainX, max_len)\n",
    "testX = encode_text(tokenizer, testX, max_len)\n",
    "trainY = to_categorical(trainY,num_classes=number_of_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google news word2vec\n"
     ]
    }
   ],
   "source": [
    "# glove_model = load_GloVe_embedding('word_embeddings/glove.6B.300d.txt')\n",
    "# fast_text_model = load_fast_text_model(back_up_for_fasttext)\n",
    "# godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")\n",
    "word2vec_model= load_google_word2vec('../word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding_matrix_glove = get_GloVe_embedding_matrix(glove_model)\n",
    "embedding_matrix_word2vec = get_word_embedding_matrix(word2vec_model,300)\n",
    "# embedding_matrix_fast_text = get_word_embedding_matrix(fast_text_model,100)\n",
    "# embedding_matrix_godin = get_word_embedding_matrix(godin_model,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_cnn = {\n",
    "            \"n_dense\": 250,\n",
    "            \"dropout\": 0.2,\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"n_filters\": 100,\n",
    "            \"filter_size\": 5,\n",
    "            \"em\": embedding_matrix_word2vec,\n",
    "            \"em_trainable_flag\":True,\n",
    "            \"batch\": 32,\n",
    "            \"epoch\": 5\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_lstm_or_gru = {\n",
    "            \"dropout\": 0.5,\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"units_out\": 64,\n",
    "            \"em\": embedding_matrix_word2vec,\n",
    "            \"em_trainable_flag\":True,\n",
    "            \"batch\": 32,\n",
    "            \"epoch\": 4\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_cnn_lstm_or_gru = {\n",
    "            \"n_filters\": 100,\n",
    "            \"filter_size\": 5,\n",
    "            \"conv_dropout\": 0.5,\n",
    "            \"l_or_g_dropout\":0.5,\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"units_out\": 64,\n",
    "            \"em\": embedding_matrix_word2vec,\n",
    "            \"em_trainable_flag\":True,\n",
    "            \"batch\": 32,\n",
    "            \"epoch\": 4\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix_fast_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-9567ba65257a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpara_learning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'log-uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpara_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dropout'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpara_em\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix_fast_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_matrix_godin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_matrix_word2vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_matrix_glove\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'em'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpara_em_trainable_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'em_trainable_flag'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpara_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix_fast_text' is not defined"
     ]
    }
   ],
   "source": [
    "para_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform',name='learning_rate')\n",
    "para_dropout = Categorical(categories=[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],name = 'dropout')\n",
    "para_em = Categorical(categories=[embedding_matrix_fast_text,embedding_matrix_godin,embedding_matrix_word2vec,embedding_matrix_glove],name='em')\n",
    "para_em_trainable_flag = Categorical(categories=[True,False],name='em_trainable_flag')\n",
    "para_batch_size = Categorical(categories=[8,16,32,64],name='batch_size')\n",
    "para_epoch = Categorical(categories=[5,10,20,50,100],name='epoch')\n",
    "\n",
    "para_units_out = Categorical(categories=[64,128,256,512], name='units_out')\n",
    "\n",
    "para_n_dense = Categorical(categories=[100,200,300,400], name='n_dense')\n",
    "para_n_filters = Categorical(categories=[32,100,200,300],name='n_filters')\n",
    "para_filter_size = Integer(low=1,high=8,name = 'filter_size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'para_n_dense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-8d58288941e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpara_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_n_dense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_n_filters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_filter_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_em\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_em_trainable_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_epoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparameters_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpara_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_units_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_em\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_em_trainable_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_epoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparameters_cnn_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpara_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_units_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_n_filters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_filter_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_em\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_em_trainable_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_epoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'para_n_dense' is not defined"
     ]
    }
   ],
   "source": [
    "parameters_cnn = [para_learning_rate,para_dropout,para_n_dense,para_n_filters,para_filter_size,para_em,para_em_trainable_flag,para_batch_size,para_epoch]\n",
    "parameters_lstm = [para_learning_rate,para_dropout,para_units_out,para_em,para_em_trainable_flag,para_batch_size,para_epoch]\n",
    "parameters_cnn_lstm = [para_learning_rate,para_dropout,para_dropout,para_units_out,para_n_filters,para_filter_size,para_em,para_em_trainable_flag,para_batch_size,para_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = cnn(length=max_len,\n",
    "#             vocab_size=vocab_size,\n",
    "#             n_dense=parameters_cnn['n_dense'],\n",
    "#             dropout=parameters_cnn['dropout'],\n",
    "#             learning_rate=parameters_cnn['learning_rate'],\n",
    "#             n_filters=parameters_cnn['n_filters'],\n",
    "#             filter_size=parameters_cnn['filter_size'],\n",
    "#             em = parameters_cnn['em'],\n",
    "#             free_em_dim=parameters_cnn['free_em_dim'],\n",
    "#             number_of_classes=number_of_classes,\n",
    "#             em_trainable_flag=parameters_cnn['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = bi_gru(length=max_len,\n",
    "#              vocab_size=vocab_size,\n",
    "#              learning_rate=parameters_lstm_or_gru['learning_rate'],\n",
    "#              dropout=parameters_lstm_or_gru['dropout'],\n",
    "#              units_out=parameters_lstm_or_gru['units_out'],\n",
    "#              em=parameters_lstm_or_gru['em'],\n",
    "#              number_of_classes=number_of_classes,\n",
    "#              em_trainable_flag=parameters_lstm_or_gru['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 24, 300)           5130900   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 20, 100)           150100    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 10, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 5,323,565\n",
      "Trainable params: 5,323,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_lstm(length=max_len,\n",
    "                    vocab_size=vocab_size,\n",
    "                    n_filters=parameters_cnn_lstm_or_gru['n_filters'],\n",
    "                    filter_size=parameters_cnn_lstm_or_gru['filter_size'],\n",
    "                    em=parameters_cnn_lstm_or_gru['em'],\n",
    "                    number_of_classes=number_of_classes,\n",
    "                    em_trainable_flag=parameters_cnn_lstm_or_gru['em_trainable_flag'],\n",
    "                    learning_rate=parameters_cnn_lstm_or_gru['learning_rate'],\n",
    "                    conv_dropout=parameters_cnn_lstm_or_gru['conv_dropout'],\n",
    "                    l_or_g_dropout=parameters_cnn_lstm_or_gru['l_or_g_dropout'],\n",
    "                    units_out=parameters_cnn_lstm_or_gru['units_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "9645/9645 [==============================] - 29s 3ms/step - loss: 0.4539 - acc: 0.7986\n",
      "Epoch 2/4\n",
      "9645/9645 [==============================] - 25s 3ms/step - loss: 0.3848 - acc: 0.8132\n",
      "Epoch 3/4\n",
      "9645/9645 [==============================] - 26s 3ms/step - loss: 0.3128 - acc: 0.8579\n",
      "Epoch 4/4\n",
      "9645/9645 [==============================] - 26s 3ms/step - loss: 0.2455 - acc: 0.8978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX,trainY,epochs=parameters_cnn_lstm_or_gru[\"epoch\"],batch_size=parameters_cnn_lstm_or_gru[\"batch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class = [np.argmax(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 2, 4, 3, 1, 1, 1, 2, 1, 1, 0, 2, 2, 1, 1, 3, 1, 0, 3, 1, 4, 3]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class[:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(test_labels,pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3950226244343891"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
