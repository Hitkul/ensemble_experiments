{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/hitkul/anaconda3/envs/ps3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import json\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import remove\n",
    "from pprint import pprint\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from gensim.models import KeyedVectors\n",
    "import word2vecReader as godin_embedding\n",
    "import fasttext\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [12,10]\n",
    "from base_learners import cnn,lstm,bi_lstm,cnn_bi_lstm,cnn_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    with open(filename,'r', errors='ignore') as fin:\n",
    "        lines = fin.readlines()\n",
    "    label = [int(x.split()[0]) for x in lines]\n",
    "    sentence = [' '.join(x.split()[1:]) for x in lines]\n",
    "    return label,sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels,train_sentences = load_data_from_file('dataset/sst1/stsa.fine.train')\n",
    "dev_label,dev_sentence = load_data_from_file('dataset/sst1/stsa.fine.dev')\n",
    "test_labels,test_sentences = load_data_from_file('dataset/sst1/stsa.fine.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = train_sentences+dev_sentence\n",
    "train_labels = train_labels+dev_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9645, 9645, 2210, 2210)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels),len(train_sentences),len(test_labels),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = len(set(train_labels))\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1231\n",
      "1 2507\n",
      "2 1853\n",
      "3 2601\n",
      "4 1453\n"
     ]
    }
   ],
   "source": [
    "for x in range(number_of_classes):\n",
    "    print(x,train_labels.count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 279\n",
      "1 633\n",
      "2 389\n",
      "3 510\n",
      "4 399\n"
     ]
    }
   ],
   "source": [
    "for x in range(number_of_classes):\n",
    "    print(x,test_labels.count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(string.punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    # should have used translate but for some reason it breaks on my server\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = [clean_sentence(s) for s in train_sentences]\n",
    "testX = [clean_sentence(s) for s in test_sentences]\n",
    "trainY = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(line.split()) for line in trainX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 503., 1766., 2173., 2127., 1592.,  883.,  415.,  156.,   22.,\n",
       "           8.]),\n",
       " array([ 0.,  3.,  6.,  9., 12., 15., 18., 21., 24., 27., 30.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAJCCAYAAAA/XCqxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15965b4518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(max(lengths))\n",
    "plt.hist(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading Goding model.\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_google_word2vec(file_name):\n",
    "    print(\"Loading google news word2vec\")\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_embedding_matrix(model,dim):\n",
    "    #dim = 300 for google word2vec\n",
    "    #dim = 400 for godin\n",
    "    #dim = 100 for fast text\n",
    "    embedding_matrix = np.zeros((vocab_size,dim))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 24\n",
      "Vocabulary size: 17103\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(trainX)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "trainX = encode_text(tokenizer, trainX, max_len)\n",
    "testX = encode_text(tokenizer, testX, max_len)\n",
    "trainY = to_categorical(trainY,num_classes=number_of_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google news word2vec\n"
     ]
    }
   ],
   "source": [
    "# glove_model = load_GloVe_embedding('word_embeddings/glove.6B.300d.txt')\n",
    "# fast_text_model = load_fast_text_model(back_up_for_fasttext)\n",
    "# godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")\n",
    "word2vec_model= load_google_word2vec('../word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding_matrix_glove = get_GloVe_embedding_matrix(glove_model)\n",
    "embedding_matrix_word2vec = get_word_embedding_matrix(word2vec_model,300)\n",
    "# embedding_matrix_fast_text = get_word_embedding_matrix(fast_text_model,100)\n",
    "# embedding_matrix_godin = get_word_embedding_matrix(godin_model,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_learning_rate = Categorical(categories=[0.1,0.01,0.001,0.0001],name='learning_rate')\n",
    "para_dropout = Categorical(categories=[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],name = 'dropout')\n",
    "# para_em = Categorical(categories=[embedding_matrix_godin,embedding_matrix_word2vec],name='em')\n",
    "para_em = Categorical(categories=['embedding_matrix_word2vec'],name='em')\n",
    "para_em_trainable_flag = Categorical(categories=[True,False],name='em_trainable_flag')\n",
    "para_batch_size = Categorical(categories=[8,16,32,64],name='batch_size')\n",
    "para_epoch = Categorical(categories=[10,15,20,50],name='epoch')\n",
    "\n",
    "# para_units_out = Categorical(categories=[64,128,256,512], name='units_out')\n",
    "\n",
    "# para_dropout_cnn_lstm = Categorical(categories=[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],name = 'dropout')\n",
    "\n",
    "para_n_dense = Categorical(categories=[100,200,300,400], name='n_dense')\n",
    "para_n_filters = Categorical(categories=[100,200,300],name='n_filters')\n",
    "para_filter_size = Integer(low=1,high=6,name = 'filter_size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_cnn = [para_learning_rate,para_dropout,para_n_dense,para_n_filters,para_filter_size,para_em,para_em_trainable_flag,para_batch_size,para_epoch]\n",
    "# parameters_lstm = [para_learning_rate,para_dropout,para_units_out,para_em,para_em_trainable_flag,para_batch_size,para_epoch]\n",
    "# parameters_cnn_lstm = [para_learning_rate,para_dropout,para_dropout_cnn_lstm,para_units_out,para_n_filters,para_filter_size,para_em,para_em_trainable_flag,para_batch_size,para_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_parameters_cnn = [0.0001,0.6,100,200,1,'embedding_matrix_word2vec',True,8,20]\n",
    "# default_parameters_lstm = [0.001,0.2,128,embedding_matrix_word2vec,True,32,20]\n",
    "# default_parameters_cnn_lstm = [0.001,0.2,0.2,128,100,5,embedding_matrix_word2vec,True,32,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = 1\n",
    "record = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##this will change based on the model\n",
    "@use_named_args(dimensions=parameters_cnn)\n",
    "def fitness(learning_rate,dropout,n_dense,n_filters,filter_size,em,em_trainable_flag,batch_size,epoch):\n",
    "    global key\n",
    "    global record\n",
    "    global number_of_classes\n",
    "    print('-----------------------------combination no={0}------------------'.format(key))\n",
    "    parameters = {\n",
    "            \"learning_rate\": learning_rate,    \n",
    "            \"dropout\": dropout,\n",
    "            \"n_dense\": n_dense,\n",
    "            \"n_filters\": n_filters,\n",
    "            \"filter_size\": int(filter_size),\n",
    "            \"em\": em,\n",
    "            \"em_trainable_flag\":em_trainable_flag,\n",
    "            \"batch\": batch_size,\n",
    "            \"epoch\": epoch\n",
    "        }\n",
    "    \n",
    "    pprint(parameters)\n",
    "    \n",
    "    model = cnn(length=max_len,\n",
    "                vocab_size=vocab_size,\n",
    "                n_dense=parameters['n_dense'],\n",
    "                dropout=parameters['dropout'],\n",
    "                learning_rate = parameters['learning_rate'],\n",
    "                n_filters=parameters['n_filters'],\n",
    "                filter_size=parameters['filter_size'],\n",
    "                em = eval(parameters['em']),\n",
    "                number_of_classes=number_of_classes,\n",
    "                em_trainable_flag=parameters['em_trainable_flag'])\n",
    "\n",
    "    history = model.fit(trainX,trainY,epochs=parameters[\"epoch\"],batch_size=parameters[\"batch\"])\n",
    "    pred = model.predict(testX)\n",
    "    pred_class = [np.argmax(x) for x in pred]\n",
    "    acc = accuracy_score(test_labels,pred_class)\n",
    "    print(acc)\n",
    "    record[key] = {}\n",
    "    record[key][\"parameter\"] = parameters\n",
    "    record[key][\"acc\"] = acc\n",
    "    with open(\"results/cnn.json\",'w')as fout:\n",
    "        json.dump(record,fout,indent=4)\n",
    "    key+=1\n",
    "    \n",
    "    del model\n",
    "    K.clear_session()\n",
    "    \n",
    "    return -acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------combination no=1------------------\n",
      "{'batch': 8,\n",
      " 'dropout': 0.6,\n",
      " 'em': 'embedding_matrix_word2vec',\n",
      " 'em_trainable_flag': True,\n",
      " 'epoch': 20,\n",
      " 'filter_size': 1,\n",
      " 'learning_rate': 0.0001,\n",
      " 'n_dense': 100,\n",
      " 'n_filters': 200}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 24, 300)           5130900   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 24, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 24, 200)           60200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 505       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,211,705\n",
      "Trainable params: 5,211,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4978 - acc: 0.7988\n",
      "Epoch 2/20\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.4849 - acc: 0.7998\n",
      "Epoch 3/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4748 - acc: 0.7995\n",
      "Epoch 4/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4610 - acc: 0.7989\n",
      "Epoch 5/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4493 - acc: 0.7995: 0s - loss: 0.4492 - acc: 0.79\n",
      "Epoch 6/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4387 - acc: 0.8004\n",
      "Epoch 7/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.4318 - acc: 0.8002: 2s - loss: 0.431 - ETA: 1s - loss: 0.\n",
      "Epoch 8/20\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.4238 - acc: 0.8018\n",
      "Epoch 9/20\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.4211 - acc: 0.8015\n",
      "Epoch 10/20\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.4148 - acc: 0.8028\n",
      "Epoch 11/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.4106 - acc: 0.8061\n",
      "Epoch 12/20\n",
      "9645/9645 [==============================] - 77s 8ms/step - loss: 0.4031 - acc: 0.8077\n",
      "Epoch 13/20\n",
      "9645/9645 [==============================] - 80s 8ms/step - loss: 0.3984 - acc: 0.8108\n",
      "Epoch 14/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3940 - acc: 0.8112\n",
      "Epoch 15/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3908 - acc: 0.8145\n",
      "Epoch 16/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3840 - acc: 0.8182\n",
      "Epoch 17/20\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.3802 - acc: 0.8191\n",
      "Epoch 18/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3750 - acc: 0.8230\n",
      "Epoch 19/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3707 - acc: 0.8244: 1s\n",
      "Epoch 20/20\n",
      "9645/9645 [==============================] - 81s 8ms/step - loss: 0.3652 - acc: 0.8293\n",
      "0.4638009049773756\n",
      "-----------------------------combination no=2------------------\n",
      "{'batch': 16,\n",
      " 'dropout': 0.6,\n",
      " 'em': 'embedding_matrix_word2vec',\n",
      " 'em_trainable_flag': True,\n",
      " 'epoch': 50,\n",
      " 'filter_size': 3,\n",
      " 'learning_rate': 0.01,\n",
      " 'n_dense': 300,\n",
      " 'n_filters': 100}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 24, 300)           5130900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 22, 100)           90100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               30300     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1505      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,252,805\n",
      "Trainable params: 5,252,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "9645/9645 [==============================] - 38s 4ms/step - loss: 0.4952 - acc: 0.7957\n",
      "Epoch 2/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4897 - acc: 0.7984\n",
      "Epoch 3/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4913 - acc: 0.7998\n",
      "Epoch 4/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 5/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 6/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 7/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4904 - acc: 0.8000\n",
      "Epoch 8/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 9/50\n",
      "9645/9645 [==============================] - 39s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 10/50\n",
      "9645/9645 [==============================] - 38s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 11/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4908 - acc: 0.8000\n",
      "Epoch 12/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 13/50\n",
      "9645/9645 [==============================] - 37s 4ms/step - loss: 0.4904 - acc: 0.8000\n",
      "Epoch 14/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 15/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4906 - acc: 0.8000\n",
      "Epoch 16/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 17/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4904 - acc: 0.8000\n",
      "Epoch 18/50\n",
      "9645/9645 [==============================] - 36s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 19/50\n",
      "9645/9645 [==============================] - 37s 4ms/step - loss: 0.4905 - acc: 0.8000\n",
      "Epoch 20/50\n",
      "7616/9645 [======================>.......] - ETA: 8s - loss: 0.4900 - acc: 0.8000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-59232f39866f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             x0=default_parameters_cnn)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-55699580de94>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(learning_rate, dropout, n_dense, n_filters, filter_size, em, em_trainable_flag, batch_size, epoch)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 em_trainable_flag=parameters['em_trainable_flag'])\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mpred_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=parameters_cnn,\n",
    "                            acq_func='EI',\n",
    "                            n_calls=11,\n",
    "                            x0=default_parameters_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters_cnn = {\n",
    "#             \"n_dense\": 250,\n",
    "#             \"dropout\": 0.2,\n",
    "#             \"learning_rate\": 0.001,\n",
    "#             \"n_filters\": 100,\n",
    "#             \"filter_size\": 5,\n",
    "#             \"em\": embedding_matrix_word2vec,\n",
    "#             \"em_trainable_flag\":True,\n",
    "#             \"batch\": 32,\n",
    "#             \"epoch\": 5\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters_lstm_or_gru = {\n",
    "#             \"dropout\": 0.5,\n",
    "#             \"learning_rate\": 0.001,\n",
    "#             \"units_out\": 64,\n",
    "#             \"em\": embedding_matrix_word2vec,\n",
    "#             \"em_trainable_flag\":True,\n",
    "#             \"batch\": 32,\n",
    "#             \"epoch\": 4\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters_cnn_lstm_or_gru = {\n",
    "#             \"n_filters\": 100,\n",
    "#             \"filter_size\": 5,\n",
    "#             \"conv_dropout\": 0.5,\n",
    "#             \"l_or_g_dropout\":0.5,\n",
    "#             \"learning_rate\": 0.001,\n",
    "#             \"units_out\": 64,\n",
    "#             \"em\": embedding_matrix_word2vec,\n",
    "#             \"em_trainable_flag\":True,\n",
    "#             \"batch\": 32,\n",
    "#             \"epoch\": 4\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = cnn(length=max_len,\n",
    "#             vocab_size=vocab_size,\n",
    "#             n_dense=parameters_cnn['n_dense'],\n",
    "#             dropout=parameters_cnn['dropout'],\n",
    "#             learning_rate=parameters_cnn['learning_rate'],\n",
    "#             n_filters=parameters_cnn['n_filters'],\n",
    "#             filter_size=parameters_cnn['filter_size'],\n",
    "#             em = parameters_cnn['em'],\n",
    "#             free_em_dim=parameters_cnn['free_em_dim'],\n",
    "#             number_of_classes=number_of_classes,\n",
    "#             em_trainable_flag=parameters_cnn['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = bi_gru(length=max_len,\n",
    "#              vocab_size=vocab_size,\n",
    "#              learning_rate=parameters_lstm_or_gru['learning_rate'],\n",
    "#              dropout=parameters_lstm_or_gru['dropout'],\n",
    "#              units_out=parameters_lstm_or_gru['units_out'],\n",
    "#              em=parameters_lstm_or_gru['em'],\n",
    "#              number_of_classes=number_of_classes,\n",
    "#              em_trainable_flag=parameters_lstm_or_gru['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = cnn_lstm(length=max_len,\n",
    "#                     vocab_size=vocab_size,\n",
    "#                     n_filters=parameters_cnn_lstm_or_gru['n_filters'],\n",
    "#                     filter_size=parameters_cnn_lstm_or_gru['filter_size'],\n",
    "#                     em=parameters_cnn_lstm_or_gru['em'],\n",
    "#                     number_of_classes=number_of_classes,\n",
    "#                     em_trainable_flag=parameters_cnn_lstm_or_gru['em_trainable_flag'],\n",
    "#                     learning_rate=parameters_cnn_lstm_or_gru['learning_rate'],\n",
    "#                     conv_dropout=parameters_cnn_lstm_or_gru['conv_dropout'],\n",
    "#                     l_or_g_dropout=parameters_cnn_lstm_or_gru['l_or_g_dropout'],\n",
    "#                     units_out=parameters_cnn_lstm_or_gru['units_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
