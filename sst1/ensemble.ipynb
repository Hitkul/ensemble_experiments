{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import json\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import remove\n",
    "from pprint import pprint\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from gensim.models import KeyedVectors\n",
    "import word2vecReader as godin_embedding\n",
    "import fasttext\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from base_learners import cnn,lstm,bi_lstm,cnn_bi_lstm,cnn_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    with open(filename,'r', errors='ignore') as fin:\n",
    "        lines = fin.readlines()\n",
    "    label = [int(x.split()[0]) for x in lines]\n",
    "    sentence = [' '.join(x.split()[1:]) for x in lines]\n",
    "    return label,sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels,train_sentences = load_data_from_file('dataset/sst1/stsa.fine.train')\n",
    "dev_label,dev_sentence = load_data_from_file('dataset/sst1/stsa.fine.dev')\n",
    "test_labels,test_sentences = load_data_from_file('dataset/sst1/stsa.fine.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = train_sentences+dev_sentence\n",
    "train_labels = train_labels+dev_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9645, 9645, 2210, 2210)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels),len(train_sentences),len(test_labels),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels[:500]\n",
    "train_sentences = train_sentences[:500]\n",
    "test_labels=test_labels[:100]\n",
    "test_sentences = test_sentences[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = len(set(train_labels))\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 100, 100)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels),len(train_sentences),len(test_labels),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(string.punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    # should have used translate but for some reason it breaks on my server\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = [clean_sentence(s) for s in train_sentences]\n",
    "testX = [clean_sentence(s) for s in test_sentences]\n",
    "trainY = np.array(train_labels)\n",
    "testY=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading Goding model.\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_google_word2vec(file_name):\n",
    "    print(\"Loading google news word2vec\")\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_embedding_matrix(model,dim):\n",
    "    #dim = 300 for google word2vec\n",
    "    #dim = 400 for godin\n",
    "    #dim = 100 for fast text\n",
    "    embedding_matrix = np.zeros((vocab_size,dim))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 24\n",
      "Vocabulary size: 2674\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(trainX)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "trainX = encode_text(tokenizer, trainX, max_len)\n",
    "testX = encode_text(tokenizer, testX, max_len)\n",
    "trainY = to_categorical(trainY,num_classes=number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google news word2vec\n"
     ]
    }
   ],
   "source": [
    "# godin_model = load_godin_word_embedding(\"../word_embeddings/word2vec_twitter_model.bin\")\n",
    "word2vec_model= load_google_word2vec('../word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix_word2vec = get_word_embedding_matrix(word2vec_model,300)\n",
    "# embedding_matrix_godin = get_word_embedding_matrix(godin_model,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_parameter = {'batch': 8,\n",
    "                'dropout': 0.6,\n",
    "                'em': 'embedding_matrix_word2vec',\n",
    "                'em_trainable_flag': True,\n",
    "                'epoch': 10,\n",
    "                'filter_size': 6,\n",
    "                'learning_rate': 0.0001,\n",
    "                'n_dense': 200,\n",
    "                'n_filters': 100}\n",
    "\n",
    "lstm_parameter={'batch': 64,\n",
    "                    'dropout': 0.6,\n",
    "                    'em': 'embedding_matrix_word2vec',\n",
    "                    'em_trainable_flag': False,\n",
    "                    'epoch': 20,\n",
    "                    'learning_rate': 0.0034157107277860235,\n",
    "                    'units_out': 128}\n",
    "\n",
    "cnn_lstm_parameter={'batch': 8,\n",
    "                    'conv_dropout': 0.5,\n",
    "                    'em': 'embedding_matrix_word2vec',\n",
    "                    'em_trainable_flag': False,\n",
    "                    'epoch': 10,\n",
    "                    'filter_size': 1,\n",
    "                    'learning_rate': 0.001,\n",
    "                    'lstm_dropout': 0.4,\n",
    "                    'n_filters': 100,\n",
    "                    'units_out': 64}\n",
    "\n",
    "cnn_bi_lstm_parameter={'batch': 8,\n",
    "                    'conv_dropout': 0.5,\n",
    "                    'em': 'embedding_matrix_word2vec',\n",
    "                    'em_trainable_flag': False,\n",
    "                    'epoch': 5,\n",
    "                    'filter_size': 1,\n",
    "                    'learning_rate': 0.001,\n",
    "                    'lstm_dropout': 0.2,\n",
    "                    'n_filters': 100,\n",
    "                    'units_out': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn\n",
    "# 0.4710\n",
    "def init_cnn():\n",
    "    return cnn(length=max_len,\n",
    "               vocab_size=vocab_size,\n",
    "               learning_rate=cnn_parameter['learning_rate'],\n",
    "               n_dense=cnn_parameter['n_dense'],\n",
    "               dropout=cnn_parameter['dropout'],\n",
    "               n_filters=cnn_parameter['n_filters'],\n",
    "               filter_size=cnn_parameter['filter_size'],\n",
    "               em=eval(cnn_parameter['em']),\n",
    "               number_of_classes=number_of_classes,\n",
    "               em_trainable_flag=cnn_parameter['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  lstm\n",
    "# 0.4701\n",
    "def init_lstm():\n",
    "    return lstm(length=max_len,\n",
    "                vocab_size=vocab_size,\n",
    "                learning_rate=lstm_parameter['learning_rate'],\n",
    "                dropout=lstm_parameter['dropout'],\n",
    "                units_out=lstm_parameter['units_out'],\n",
    "                em=eval(lstm_parameter['em']),\n",
    "                number_of_classes=number_of_classes,\n",
    "                em_trainable_flag=lstm_parameter['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_lstm\n",
    "# 0.4529\n",
    "def init_bi_lstm():\n",
    "    bi_lstm_parameter={'batch':8,\n",
    "                 'dropout': 0.6,\n",
    "                 'em': 'embedding_matrix_word2vec',\n",
    "                 'em_trainable_flag': False,\n",
    "                 'epoch': 5,\n",
    "                 'learning_rate': 0.0001,\n",
    "                 'units_out': 256}\n",
    "    return bi_lstm(length=max_len,\n",
    "                vocab_size=vocab_size,\n",
    "                learning_rate=bi_lstm_parameter['learning_rate'],\n",
    "                dropout=bi_lstm_parameter['dropout'],\n",
    "                units_out=bi_lstm_parameter['units_out'],\n",
    "                em=eval(bi_lstm_parameter['em']),\n",
    "                number_of_classes=number_of_classes,\n",
    "                em_trainable_flag=bi_lstm_parameter['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_lstm\n",
    "# 0.4179\n",
    "def init_cnn_lstm():\n",
    "    return cnn_lstm(length=max_len,\n",
    "                    vocab_size=vocab_size,\n",
    "                    learning_rate=cnn_lstm_parameter['learning_rate'],\n",
    "                    n_filters=cnn_lstm_parameter['n_filters'],\n",
    "                    filter_size=cnn_lstm_parameter['filter_size'],\n",
    "                    em=eval(cnn_lstm_parameter['em']),\n",
    "                    number_of_classes=number_of_classes,\n",
    "                    em_trainable_flag=cnn_lstm_parameter['em_trainable_flag'],\n",
    "                    conv_dropout=cnn_lstm_parameter['conv_dropout'],\n",
    "                    l_or_g_dropout=cnn_lstm_parameter['lstm_dropout'],\n",
    "                    units_out=cnn_lstm_parameter['units_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cnn_bi_lstm\n",
    "# 0.4705\n",
    "def init_cnn_bi_lstm():\n",
    "    return cnn_bi_lstm(length=max_len,\n",
    "                    vocab_size=vocab_size,\n",
    "                    learning_rate=cnn_bi_lstm_parameter['learning_rate'],\n",
    "                    n_filters=cnn_bi_lstm_parameter['n_filters'],\n",
    "                    filter_size=cnn_bi_lstm_parameter['filter_size'],\n",
    "                    em=eval(cnn_bi_lstm_parameter['em']),\n",
    "                    number_of_classes=number_of_classes,\n",
    "                    em_trainable_flag=cnn_bi_lstm_parameter['em_trainable_flag'],\n",
    "                    conv_dropout=cnn_bi_lstm_parameter['conv_dropout'],\n",
    "                    l_or_g_dropout=cnn_bi_lstm_parameter['lstm_dropout'],\n",
    "                    units_out=cnn_bi_lstm_parameter['units_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_of_model(m,epoch,batch):\n",
    "    history = m.fit(trainX,trainY,epochs=epoch,batch_size=batch)\n",
    "    pred = m.predict(testX)    \n",
    "    pred_class = np.argmax(pred,axis=1)\n",
    "    pred_class=pred_class.astype(int)\n",
    "    acc = accuracy_score(testY,pred_class)\n",
    "    print(acc)\n",
    "#     print(pred)\n",
    "    return acc,pred_class,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_base = np.zeros((len(testX),number_of_classes,5))\n",
    "pred_class_base = np.zeros((len(testX),5),dtype=np.int32)\n",
    "acc_results={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 24, 300)           802200    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 24, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 19, 100)           180100    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 5)                 1005      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,003,505\n",
      "Trainable params: 1,003,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5116 - acc: 0.7992\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.4998 - acc: 0.7976\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4979 - acc: 0.7984\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4898 - acc: 0.7988\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4943 - acc: 0.7996\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4861 - acc: 0.8008\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4792 - acc: 0.8004\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4813 - acc: 0.8000\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.4778 - acc: 0.7996\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4772 - acc: 0.8012\n",
      "0.38\n"
     ]
    }
   ],
   "source": [
    "acc_results['cnn'],pred_class_base[:,0],pred_prob_base[:,:,0] = get_pred_of_model(init_cnn(),cnn_parameter['epoch'],cnn_parameter['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 24, 300)           802200    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,022,493\n",
      "Trainable params: 220,293\n",
      "Non-trainable params: 802,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4975 - acc: 0.8000\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4901 - acc: 0.8000\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4899 - acc: 0.8000\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4863 - acc: 0.8000\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4777 - acc: 0.7992\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4902 - acc: 0.7968\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4843 - acc: 0.8000\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4813 - acc: 0.8000\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4687 - acc: 0.7968\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4674 - acc: 0.8008\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4721 - acc: 0.7944\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4665 - acc: 0.7984\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4592 - acc: 0.7952\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4664 - acc: 0.7980\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4605 - acc: 0.8004\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4618 - acc: 0.8012\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4681 - acc: 0.7996\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4614 - acc: 0.7976\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4646 - acc: 0.7964\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4577 - acc: 0.7988\n",
      "0.34\n"
     ]
    }
   ],
   "source": [
    "acc_results['lstm'],pred_class_base[:,1],pred_prob_base[:,:,1] = get_pred_of_model(init_lstm(),lstm_parameter['epoch'],lstm_parameter['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 24, 300)           802200    \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 512)               1140736   \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 1,945,501\n",
      "Trainable params: 1,143,301\n",
      "Non-trainable params: 802,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 0.4975 - acc: 0.8000\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.4885 - acc: 0.8000\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.4799 - acc: 0.8000\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.4777 - acc: 0.8004\n",
      "Epoch 5/5\n",
      "384/500 [======================>.......] - ETA: 1s - loss: 0.4694 - acc: 0.8021"
     ]
    }
   ],
   "source": [
    "acc_results['bi_lstm'],pred_class_base[:,2],pred_prob_base[:,:,2] = get_pred_of_model(init_bi_lstm(),bi_lstm_parameter['epoch'],bi_lstm_parameter['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 24, 300)           802200    \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 24, 100)           30100     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 24, 100)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 12, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 874,865\n",
      "Trainable params: 72,665\n",
      "Non-trainable params: 802,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.4935 - acc: 0.8000\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4914 - acc: 0.8000\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4848 - acc: 0.7996\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4556 - acc: 0.8024\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4242 - acc: 0.8108\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3791 - acc: 0.8284\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3466 - acc: 0.8464\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3079 - acc: 0.8688\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2804 - acc: 0.8772\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2487 - acc: 0.8960\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "acc_results['cnn_lstm'],pred_class_base[:,3],pred_prob_base[:,:,3] = get_pred_of_model(init_cnn_lstm(),cnn_lstm_parameter['epoch'],cnn_lstm_parameter['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 24, 300)           802200    \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 24, 100)           30100     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 24, 100)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 12, 100)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 917,425\n",
      "Trainable params: 115,225\n",
      "Non-trainable params: 802,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4935 - acc: 0.8000\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4799 - acc: 0.8000\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4458 - acc: 0.8012\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4127 - acc: 0.8092\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3833 - acc: 0.8280\n",
      "0.33\n"
     ]
    }
   ],
   "source": [
    "acc_results['cnn_bi_lstm'],pred_class_base[:,4],pred_prob_base[:,:,4] = get_pred_of_model(init_cnn_bi_lstm(),cnn_bi_lstm_parameter['epoch'],cnn_bi_lstm_parameter['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bi_lstm': 0.3,\n",
       " 'cnn': 0.3,\n",
       " 'cnn_bi_lstm': 0.33,\n",
       " 'cnn_lstm': 0.35,\n",
       " 'lstm': 0.36}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.18602401, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.20817187, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.22010143, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.21163753, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.1740652 , 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.16044299, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.21731985, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.21163256, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.24398661, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.16661796, 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.17953719, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.20222722, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.19294149, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.21947268, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.20582145, 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.16442861, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.215902  , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.18465108, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.24197248, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.19304578, 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.18770842, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.21024977, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.20540819, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.20135614, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.19527747, 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.15620753, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.24810392, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.18098746, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.25230643, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.16239455, 0.        , 0.        , 0.        , 0.        ]]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
