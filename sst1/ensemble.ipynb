{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-213-da964081fb71>\", line 21, in <module>\n",
      "    get_ipython().magic('matplotlib inline')\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2146, in magic\n",
      "    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2067, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-107>\", line 2, in matplotlib\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2930, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 307, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 229, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1305, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/home/hitkul/anaconda3/envs/ps3/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import json\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import remove\n",
    "from pprint import pprint\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from gensim.models import KeyedVectors\n",
    "import word2vecReader as godin_embedding\n",
    "import fasttext\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from base_learners import cnn,lstm,bi_lstm,cnn_bi_lstm,cnn_lstm\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams[\"figure.figsize\"] = [12,10]\n",
    "from mlens.visualization import corrmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    with open(filename,'r', errors='ignore') as fin:\n",
    "        lines = fin.readlines()\n",
    "    label = [int(x.split()[0]) for x in lines]\n",
    "    sentence = [' '.join(x.split()[1:]) for x in lines]\n",
    "    return label,sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels,train_sentences = load_data_from_file('dataset/sst1/stsa.fine.train')\n",
    "dev_label,dev_sentence = load_data_from_file('dataset/sst1/stsa.fine.dev')\n",
    "test_labels,test_sentences = load_data_from_file('dataset/sst1/stsa.fine.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = train_sentences+dev_sentence\n",
    "train_labels = train_labels+dev_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9645, 9645, 2210, 2210)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels),len(train_sentences),len(test_labels),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels[:500]\n",
    "train_sentences = train_sentences[:500]\n",
    "test_labels=test_labels[:100]\n",
    "test_sentences = test_sentences[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = len(set(train_labels))\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 100, 100)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels),len(train_sentences),len(test_labels),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(string.punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    # should have used translate but for some reason it breaks on my server\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = [clean_sentence(s) for s in train_sentences]\n",
    "testX = [clean_sentence(s) for s in test_sentences]\n",
    "trainY = np.array(train_labels)\n",
    "testY=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading Goding model.\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_google_word2vec(file_name):\n",
    "    print(\"Loading google news word2vec\")\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_embedding_matrix(model,dim):\n",
    "    #dim = 300 for google word2vec\n",
    "    #dim = 400 for godin\n",
    "    #dim = 100 for fast text\n",
    "    embedding_matrix = np.zeros((vocab_size,dim))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 24\n",
      "Vocabulary size: 2674\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(trainX)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "trainX = encode_text(tokenizer, trainX, max_len)\n",
    "testX = encode_text(tokenizer, testX, max_len)\n",
    "trainY = to_categorical(trainY,num_classes=number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google news word2vec\n"
     ]
    }
   ],
   "source": [
    "# godin_model = load_godin_word_embedding(\"../word_embeddings/word2vec_twitter_model.bin\")\n",
    "word2vec_model= load_google_word2vec('../word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix_word2vec = get_word_embedding_matrix(word2vec_model,300)\n",
    "# embedding_matrix_godin = get_word_embedding_matrix(godin_model,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_parameter = {'batch': 8,\n",
    "                'dropout': 0.6,\n",
    "                'em': 'embedding_matrix_word2vec',\n",
    "                'em_trainable_flag': True,\n",
    "                'epoch': 10,\n",
    "                'filter_size': 6,\n",
    "                'learning_rate': 0.0001,\n",
    "                'n_dense': 200,\n",
    "                'n_filters': 100}\n",
    "\n",
    "lstm_parameter={'batch': 64,\n",
    "                    'dropout': 0.6,\n",
    "                    'em': 'embedding_matrix_word2vec',\n",
    "                    'em_trainable_flag': False,\n",
    "                    'epoch': 20,\n",
    "                    'learning_rate': 0.0034157107277860235,\n",
    "                    'units_out': 128}\n",
    "\n",
    "cnn_lstm_parameter={'batch': 8,\n",
    "                    'conv_dropout': 0.5,\n",
    "                    'em': 'embedding_matrix_word2vec',\n",
    "                    'em_trainable_flag': False,\n",
    "                    'epoch': 10,\n",
    "                    'filter_size': 1,\n",
    "                    'learning_rate': 0.001,\n",
    "                    'lstm_dropout': 0.4,\n",
    "                    'n_filters': 100,\n",
    "                    'units_out': 64}\n",
    "\n",
    "cnn_bi_lstm_parameter={'batch': 8,\n",
    "                    'conv_dropout': 0.5,\n",
    "                    'em': 'embedding_matrix_word2vec',\n",
    "                    'em_trainable_flag': False,\n",
    "                    'epoch': 5,\n",
    "                    'filter_size': 1,\n",
    "                    'learning_rate': 0.001,\n",
    "                    'lstm_dropout': 0.2,\n",
    "                    'n_filters': 100,\n",
    "                    'units_out': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn\n",
    "# 0.4710\n",
    "def init_cnn():\n",
    "    return cnn(length=max_len,\n",
    "               vocab_size=vocab_size,\n",
    "               learning_rate=cnn_parameter['learning_rate'],\n",
    "               n_dense=cnn_parameter['n_dense'],\n",
    "               dropout=cnn_parameter['dropout'],\n",
    "               n_filters=cnn_parameter['n_filters'],\n",
    "               filter_size=cnn_parameter['filter_size'],\n",
    "               em=eval(cnn_parameter['em']),\n",
    "               number_of_classes=number_of_classes,\n",
    "               em_trainable_flag=cnn_parameter['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  lstm\n",
    "# 0.4701\n",
    "def init_lstm():\n",
    "    return lstm(length=max_len,\n",
    "                vocab_size=vocab_size,\n",
    "                learning_rate=lstm_parameter['learning_rate'],\n",
    "                dropout=lstm_parameter['dropout'],\n",
    "                units_out=lstm_parameter['units_out'],\n",
    "                em=eval(lstm_parameter['em']),\n",
    "                number_of_classes=number_of_classes,\n",
    "                em_trainable_flag=lstm_parameter['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_lstm\n",
    "# 0.4529\n",
    "def init_bi_lstm():\n",
    "    bi_lstm_parameter={'batch':8,\n",
    "                 'dropout': 0.6,\n",
    "                 'em': 'embedding_matrix_word2vec',\n",
    "                 'em_trainable_flag': False,\n",
    "                 'epoch': 5,\n",
    "                 'learning_rate': 0.0001,\n",
    "                 'units_out': 256}\n",
    "    return bi_lstm(length=max_len,\n",
    "                vocab_size=vocab_size,\n",
    "                learning_rate=bi_lstm_parameter['learning_rate'],\n",
    "                dropout=bi_lstm_parameter['dropout'],\n",
    "                units_out=bi_lstm_parameter['units_out'],\n",
    "                em=eval(bi_lstm_parameter['em']),\n",
    "                number_of_classes=number_of_classes,\n",
    "                em_trainable_flag=bi_lstm_parameter['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_lstm\n",
    "# 0.4179\n",
    "def init_cnn_lstm():\n",
    "    return cnn_lstm(length=max_len,\n",
    "                    vocab_size=vocab_size,\n",
    "                    learning_rate=cnn_lstm_parameter['learning_rate'],\n",
    "                    n_filters=cnn_lstm_parameter['n_filters'],\n",
    "                    filter_size=cnn_lstm_parameter['filter_size'],\n",
    "                    em=eval(cnn_lstm_parameter['em']),\n",
    "                    number_of_classes=number_of_classes,\n",
    "                    em_trainable_flag=cnn_lstm_parameter['em_trainable_flag'],\n",
    "                    conv_dropout=cnn_lstm_parameter['conv_dropout'],\n",
    "                    l_or_g_dropout=cnn_lstm_parameter['lstm_dropout'],\n",
    "                    units_out=cnn_lstm_parameter['units_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cnn_bi_lstm\n",
    "# 0.4705\n",
    "def init_cnn_bi_lstm():\n",
    "    return cnn_bi_lstm(length=max_len,\n",
    "                    vocab_size=vocab_size,\n",
    "                    learning_rate=cnn_bi_lstm_parameter['learning_rate'],\n",
    "                    n_filters=cnn_bi_lstm_parameter['n_filters'],\n",
    "                    filter_size=cnn_bi_lstm_parameter['filter_size'],\n",
    "                    em=eval(cnn_bi_lstm_parameter['em']),\n",
    "                    number_of_classes=number_of_classes,\n",
    "                    em_trainable_flag=cnn_bi_lstm_parameter['em_trainable_flag'],\n",
    "                    conv_dropout=cnn_bi_lstm_parameter['conv_dropout'],\n",
    "                    l_or_g_dropout=cnn_bi_lstm_parameter['lstm_dropout'],\n",
    "                    units_out=cnn_bi_lstm_parameter['units_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_of_model(m,epoch,batch):\n",
    "    history = m.fit(trainX,trainY,epochs=epoch,batch_size=batch)\n",
    "    pred = m.predict(testX)    \n",
    "    pred_class = np.argmax(pred,axis=1)\n",
    "    pred_class=pred_class.astype(int)\n",
    "    acc = accuracy_score(testY,pred_class)\n",
    "    print(acc)\n",
    "#     print(pred)\n",
    "    return acc,pred_class,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_base = np.zeros((len(testX),number_of_classes,5))\n",
    "pred_class_base = np.zeros((len(testX),5),dtype=np.int32)\n",
    "acc_results={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 24, 300)           802200    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 24, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 19, 100)           180100    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 5)                 1005      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,003,505\n",
      "Trainable params: 1,003,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5116 - acc: 0.7992\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.4998 - acc: 0.7976\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4979 - acc: 0.7984\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4898 - acc: 0.7988\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4943 - acc: 0.7996\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4861 - acc: 0.8008\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4792 - acc: 0.8004\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4813 - acc: 0.8000\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.4778 - acc: 0.7996\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4772 - acc: 0.8012\n",
      "0.38\n"
     ]
    }
   ],
   "source": [
    "acc_results['cnn'],pred_class_base[:,0],pred_prob_base[:,:,0] = get_pred_of_model(init_cnn(),cnn_parameter['epoch'],cnn_parameter['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 24, 300)           802200    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,022,493\n",
      "Trainable params: 220,293\n",
      "Non-trainable params: 802,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4975 - acc: 0.8000\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4901 - acc: 0.8000\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4899 - acc: 0.8000\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4863 - acc: 0.8000\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4777 - acc: 0.7992\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4902 - acc: 0.7968\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4843 - acc: 0.8000\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4813 - acc: 0.8000\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4687 - acc: 0.7968\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4674 - acc: 0.8008\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4721 - acc: 0.7944\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4665 - acc: 0.7984\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4592 - acc: 0.7952\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4664 - acc: 0.7980\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4605 - acc: 0.8004\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4618 - acc: 0.8012\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4681 - acc: 0.7996\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4614 - acc: 0.7976\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4646 - acc: 0.7964\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4577 - acc: 0.7988\n",
      "0.34\n"
     ]
    }
   ],
   "source": [
    "acc_results['lstm'],pred_class_base[:,1],pred_prob_base[:,:,1] = get_pred_of_model(init_lstm(),lstm_parameter['epoch'],lstm_parameter['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 24, 300)           802200    \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 512)               1140736   \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 1,945,501\n",
      "Trainable params: 1,143,301\n",
      "Non-trainable params: 802,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 0.4975 - acc: 0.8000\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.4885 - acc: 0.8000\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.4799 - acc: 0.8000\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.4777 - acc: 0.8004\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.4693 - acc: 0.8024\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "acc_results['bi_lstm'],pred_class_base[:,2],pred_prob_base[:,:,2] = get_pred_of_model(init_bi_lstm(),bi_lstm_parameter['epoch'],bi_lstm_parameter['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 24, 300)           802200    \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 24, 100)           30100     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 24, 100)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 12, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 874,865\n",
      "Trainable params: 72,665\n",
      "Non-trainable params: 802,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4948 - acc: 0.8000\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4885 - acc: 0.7996\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4774 - acc: 0.8028\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4445 - acc: 0.8012\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4089 - acc: 0.8092\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3813 - acc: 0.8252\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3381 - acc: 0.8492\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3174 - acc: 0.8608\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2730 - acc: 0.8864\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2437 - acc: 0.8980\n",
      "0.31\n"
     ]
    }
   ],
   "source": [
    "acc_results['cnn_lstm'],pred_class_base[:,3],pred_prob_base[:,:,3] = get_pred_of_model(init_cnn_lstm(),cnn_lstm_parameter['epoch'],cnn_lstm_parameter['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 24, 300)           802200    \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 24, 100)           30100     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 24, 100)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 12, 100)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 917,425\n",
      "Trainable params: 115,225\n",
      "Non-trainable params: 802,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4900 - acc: 0.8000\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4775 - acc: 0.8000\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4361 - acc: 0.8052\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4061 - acc: 0.8192\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3638 - acc: 0.8364\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "acc_results['cnn_bi_lstm'],pred_class_base[:,4],pred_prob_base[:,:,4] = get_pred_of_model(init_cnn_bi_lstm(),cnn_bi_lstm_parameter['epoch'],cnn_bi_lstm_parameter['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bi_lstm': 0.3,\n",
       " 'cnn': 0.38,\n",
       " 'cnn_bi_lstm': 0.35,\n",
       " 'cnn_lstm': 0.31,\n",
       " 'lstm': 0.34}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 3, 2, 1],\n",
       "       [1, 4, 3, 3, 3],\n",
       "       [3, 1, 3, 2, 2],\n",
       "       [1, 1, 3, 2, 2],\n",
       "       [3, 1, 1, 2, 2],\n",
       "       [3, 1, 3, 3, 1],\n",
       "       [3, 4, 3, 4, 4],\n",
       "       [3, 3, 3, 4, 3],\n",
       "       [3, 1, 3, 2, 1],\n",
       "       [3, 1, 3, 2, 2]], dtype=int32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class_base[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.18757665, 0.1944675 , 0.17717737, 0.15059191, 0.18851279],\n",
       "        [0.22002639, 0.3269155 , 0.21329665, 0.30091268, 0.31880254],\n",
       "        [0.20359597, 0.19803959, 0.19580333, 0.38932371, 0.2950002 ],\n",
       "        [0.21058679, 0.21635148, 0.23862223, 0.11780082, 0.13378669],\n",
       "        [0.17821422, 0.06422588, 0.17510037, 0.04137087, 0.06389773]],\n",
       "\n",
       "       [[0.17611068, 0.01763456, 0.13703465, 0.01000495, 0.02058689],\n",
       "        [0.23251146, 0.12305646, 0.22282554, 0.02342308, 0.08959232],\n",
       "        [0.1931973 , 0.09766381, 0.17273113, 0.03089752, 0.11436544],\n",
       "        [0.23081961, 0.36361203, 0.29697818, 0.76453644, 0.51121509],\n",
       "        [0.16736101, 0.39803314, 0.17043053, 0.17113803, 0.26424026]]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_base[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred_class_base)\n",
    "pred_df.columns = [\"cnn\",\"lstm\",\"bi_lstm\",\"cnn_lstm\",\"cnn_bi_lstm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnn</th>\n",
       "      <th>lstm</th>\n",
       "      <th>bi_lstm</th>\n",
       "      <th>cnn_lstm</th>\n",
       "      <th>cnn_bi_lstm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cnn  lstm  bi_lstm  cnn_lstm  cnn_bi_lstm\n",
       "0    1     1        3         2            1\n",
       "1    1     4        3         3            3\n",
       "2    3     1        3         2            2\n",
       "3    1     1        3         2            2\n",
       "4    3     1        1         2            2"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAINCAYAAAAEDMrcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XecXGW5wPHfs5tASCM9gSRAGkGC\n1BB6rzZQUMSCYMtV4YooFu5VRBTBgoqCEkSUKnoBISoKiAQFBBIgkIKBEAgpkN4bZOe9f+xk2U12\nk504M2cz8/t+PvPZPWfeM+c5MynPPG85kVJCkiRJpVWTdQCSJEnVwKRLkiSpDEy6JEmSysCkS5Ik\nqQxMuiRJksrApEuSJKkMTLokSZLKwKRLkiSpDEy6JEmSysCkS5IkqQzalek83mtIkqS2KbI68YuH\nn1TS/GDYI/dldm3NsdIlSZJUBuWqdEmSJDUV1VX7qa6rlSRJyoiVLkmSlI1oU0OuSs5KlyRJUhlY\n6ZIkSZmIGitdkiRJKjIrXZIkKRvOXpQkSVKxWemSJEnZcPaiJEmSis1KlyRJyoazFyVJklRsVrok\nSVImosrGdJl0SZKkbNRUV4dbdV2tJElSRqx0SZKkbFRZ96KVLkmSpDKw0iVJkrJhpUuSJEnFZqVL\nkiRlIpy9KEmSpGKz0iVJkrJhpUuSJEnFZqVLkiRlw9mLkiRJKjYrXZIkKRPVdsNrK12SJEllYKVL\nkiRlo8ZKlyRJkorMSpckScpGVFftp7quVpIkKSNWuiRJUjYc0yVJkqRis9IlSZIyUW3rdJl0SZKk\nbDiQXpIkScVmpUuSJGXDgfSSJEkqNitdkiQpE1FTXbWf6rpaSZKkjFjpkiRJ2aiyJSOsdEmSJJWB\nlS5JkpQNK12SJEkqNitdkiQpG1U2e7GgpCsiDgV2a3xcSummIsckSZJUcVqddEXEzcAQYCJQl9+d\nAJMuSZJUMG943bKRwJ4ppdSaxhExGhgNMGbMGEaPHr0V4UmSJFWGQpKuyUA/4LXWNE4pXQdct2Gz\nwLgkSVKlq7J7LxaSdPUCpkbEk8C6DTtTSqcUPSpJkqQKU0jSdUmpgpAkSVUonL3YrJTSw6UMRJIk\nqZK1OsWMiNMi4sWIWBYRyyNiRUQsL2VwkiSpgkWU9tHGFNK9+H3gPSml50sVjCRJUqUqpDN1ngmX\nJEkqlqiJkj5aFUPEyRExLSKmR8TXmnl+14h4MCKei4hxETGg0XNn53sBX4yIs7d0rkIqXRMi4nfA\n3TSdvXhXAa8hSZJUL+MuwIioBa4BTgBmA+MjYmxKaWqjZj8Ebkop3RgRxwKXA2dFRA/gm9SvY5qA\np/LHLmnpfIVUuroCq4ETgffkH+8u4HhJkqS2ZBQwPaU0I6X0BnA7cOpGbfYEHsz//lCj508CHkgp\nLc4nWg8AJ2/uZIVUumqA81NKSwEiojtwZQHHS5IkvSX7G173B2Y12p4NHLRRm2eB04GrgPcBXSKi\nZwvH9t/cyQq52r03JFwA+axuvwKOlyRJKpuIGB0RExo9Nr4nYXP9mxvfRedC4KiIeAY4CpgDrG/l\nsU0UVOmKiO4b+irzfZmFHC9JktQgSlzp2uiWhM2ZDQxstD0AmLvRa8wFTgOIiM7A6SmlZRExGzh6\no2PHbS6eQpKmK4HHIuIO6jO5M4DLCjhekiSpLRkPDIuIQdRXsM4EPty4QUT0AhanlHLARcAN+afu\nA76bH24F9WPeL9rcyQpZkf6miJgAHEt9Se20jUb3S5IktV7GsxdTSusj4jzqE6ha4IaU0pSIuBSY\nkFIaS3016/KISMA/gHPzxy6OiG9Tn7gBXJpSWry580VKm+1+LJaynESSJBUss8xn9rkXljQ/GHDN\nD9vUsvSOyZIkSdlog7fqKaXM52pKkiRVAytdkiQpG9mv01VW1XW1kiRJGbHSJUmSMhGO6ZIkSVKx\nWemSJEnZsNIlSZKkYrPSJUmSslFjpUuSJElFZqVLkiRlI6qr9lNdVytJkpQRK12SJCkT4ZguSZIk\nFZuVLkmSlI0qu/eiSZckScqGi6NKkiSp2Kx0SZKkTHjDa0mSJBWdlS5JkpSNKhtIX11XK0mSlBEr\nXZIkKRuO6ZIkSVKxWemSJEnZsNIlSZKkYrPSJUmSMhHOXpQkSVKxWemSJEnZcEyXJEmSis1KlyRJ\nykaNlS5JkiQVmZUuSZKUDcd0SZIkqdjKVum64Ma7y3UqNePHZ7836xAkSWrCdbokSZJUdI7pkiRJ\n2Yjqqv2YdEmSpGy4ZIQkSZKKzUqXJEnKRLhkhCRJkorNSpckScpGlQ2kr66rlSRJyoiVLkmSlA1n\nL0qSJKnYrHRJkqRsOHtRkiRJxWalS5IkZSIc0yVJkqRis9IlSZKy4TpdkiRJKjYrXZIkKRvOXpQk\nSVKxWemSJEnZcPaiJEmSis1KlyRJykTUVFftp7quVpIkKSNWuiRJUjaqbJ0uky5JkpQNB9JLkiSp\n2Kx0SZKkTISLo0qSJKnYrHRJkqRsWOmSJElSsVnpkiRJ2XBxVEmSJBWblS5JkpQNx3RJkiSp2Kx0\nSZKkTLhOlyRJkorOSpckScqGsxclSZJUbFa6JElSNhzTJUmSpGKz0iVJkrLhmC5JkiQVm5UuSZKU\niaiprjFdJl3AHjv34X2j3k5E8MSLM3lw8otNnj909904bI9BpATr3lzP7/81kXnLVgBw3F7DOGjY\nrqSUuOvJSUybOz+LS5AkSW1c1SddEXD6wftw7f2PsnT1Gi5419FMnvV6Q1IF8NTLs3nshVcAGDGw\nH6ceuBfX/e1f9N2xC/sNGsD37vk7O3bswGdPPIzv/uEBUsroYiRJ2pY4e7G67NKrOwuXr2TRytXU\n5RLPvDybvQb2a9Jm3ZvrG37frl0t5JOqvQb245mXZ1OXy7F45WoWLl/JLr26lzN8SZK2XVFT2kcb\nU/WVrm4dd2DpqjUN28tWr2WX3psmTocNH8TRI4ZSWxP8/L5HAdix0w7MXLC4oc3S1Wvp1nEHZrKk\n9IFLkqRtSquTrogYCfwvsGv+uABSSmnvEsWWnWa6Bx+d9jKPTnuZ/QcN4MS9h3Pbo0/TXFHUrkVJ\nklrHgfQtuxX4MjAJyG2pcUSMBkYDjBkzBrbvs1UBltrS1Wvo1mmHhu0dO3Zg2eo1LbZ/5uXZvP/g\nfeBRWLpqDd06vnVst44dWLam5WMlSVLbEhEnA1cBtcD1KaUrNnr+x8Ax+c2OQJ+UUrf8c3XU50UA\nr6aUTtncuQpJuhaklMa2tnFK6Trgug2bF9x4dwGnKp9ZC5fSu2tnenTuyLLVa9hv0ABu+eeEJm16\ndenEwhWrANhzQD8WLl8JwJTZr/PRI0YybupL7NixA727dubVhXYtSpLUKhkPpI+IWuAa4ARgNjA+\nIsamlKZuaJNSuqBR+/8G9mv0EmtSSvu29nyFJF3fjIjrgQeBdY2CuauA12hzcilx5xPP8V/HH0pN\nTf2SEa8vXcHJ++7BrEVLmTLrdY7YYzC779ybulxi9bo3uO3RpwF4fekKJr4yh6+99zhyuRx3PPGs\n3YuSJG07RgHTU0ozACLiduBUYGoL7T8EfHNrT1ZI0vVxYA+gPW91LyZgm066AJ6fM4/n58xrsu+v\nE//d8Psfxk/a+JAGf5v0An+b9ELJYpMkqWJlP8OwPzCr0fZs4KDmGkbErsAg4O+NdneIiAnAeuCK\nlNJmu/UKSbr2SSm9vYD2kiRJmWk8vjzvuvzwp4YmzRzWUp/VmcAdKaW6Rvt2SSnNjYjBwN8jYlJK\n6aWW4ikk6Xo8IvZs3M8pSZK01Uo8e3Gj8eXNmQ0MbLQ9AJjbQtszgXM3ev25+Z8zImIc9eO9Wky6\nCqnrHQ5MjIhpEfFcREyKiOcKOF6SJKktGQ8Mi4hBEbEd9YnVJpMGI2I40B34V6N93SNi+/zvvYDD\naHksGFBYpevkAtpKkiRtVmQ8ezGltD4izgPuo37JiBtSSlMi4lJgQqNVGz4E3J5Sk+lybwPGRESO\n+iLWFVvqDSwk6fpOSumsxjsi4mbgrBbaS5IktWkppXuBezfad/FG25c0c9xjQEFj3QtJukY03siv\nbXFAISeTJElqUGUr0m9xTFdEXBQRK4C9I2J5/rECmA/cU/IIJUmSKsAWK10ppcuByyPi8pTSRWWI\nSZIkVYOazNfpKqtCrvZPEdEJICI+GhE/yi8UJkmSpC0oJOn6BbA6IvYBvgLMBG4qSVSSJKnyRU1p\nH21MIRGtz0+VPBW4KqV0FdClNGFJkiRVlkJmL66IiIuAjwJH5mcvti9NWJIkqdJlvU5XuRVS6fog\nsA74ZErpdepvEvmDkkQlSZJUYVpd6conWj9qtP0qjumSJElbq8rW6dpi0pVfk6u5O24HkFJKXYse\nlSRJUoVpzTpdDpaXJEnFV2VjugoZSC9JklQ8bXBZh1KqrquVJEnKiJUuSZKUiaiygfRWuiRJksrA\nSpckScpGlQ2kt9IlSZJUBla6JElSNmqqq/ZTXVcrSZKUEStdkiQpE97wWpIkSUVnpUuSJGXDMV2S\nJEkqNitdkiQpG47pkiRJUrFZ6ZIkSdnw3ouSJEkqNitdkiQpExHVVfuprquVJEnKiJUuSZKUDWcv\nSpIkqdisdEmSpGxU2exFky5JkpQNB9JLkiSp2Kx0SZKkTESVdS9a6ZIkSSoDK12SJCkbLhkhSZKk\nYrPSJUmSsmGlS5IkScUWKaVynKcsJ5EkSQXLrNy05ulnS5of7LD/Pm2qlFa27sWP/uyWcp1Kzbjl\nvz8KwNGXXJ1xJNVt3CXnZR2CJCkjjumSJEnZqKmuUU7VdbWSJEkZsdIlSZKy4exFSZIkFZuVLkmS\nlA3vvShJkqRis9IlSZIyEVFdtZ/qulpJkqSMWOmSJEnZcPaiJEmSis1KlyRJykaVzV406ZIkSdmw\ne1GSJEnFZqVLkiRlwiUjJEmSVHRWuiRJUjaqbCC9lS5JkqQysNIlSZKyUVNdtZ/qulpJkqSMWOmS\nJEmZCNfpkiRJUrFZ6ZIkSdlwTJckSZKKzUqXJEnKhmO6JEmSVGxWuiRJUjasdEmSJKnYrHRJkqRM\nhPdelCRJUrFZ6ZIkSdmI6qr9VNfVSpIkZcRKlyRJykaVzV406ZIkSdlwIL0kSZKKzUqXJEnKRDiQ\nXpIkScVmpUuSJGXDMV2SJEkqNitdkiQpE2s6bF/S1+9S0lcvnJUuSZJUtSLi5IiYFhHTI+JrLbQ5\nIyKmRsSUiLit0f6zI+LF/OPsLZ3LSpckSapKEVELXAOcAMwGxkfE2JTS1EZthgEXAYellJZERJ/8\n/h7AN4GRQAKeyh+7pKXzWemSJEnVahQwPaU0I6X0BnA7cOpGbT4NXLMhmUopzc/vPwl4IKW0OP/c\nA8DJmzuZlS5g71124qwjD6QmgnFTp/PHp6Y0ef4d+76No0cMoS6XWLFmLdc9+DiLVqwC4KZzP8ys\nRUsBWLRiNT/687hyh18RRg3dhfNOPoLamuDPT0/ltkeebvL83rvuzHknH86Qvr249I77eHjqSw3P\njT7+EA7ZfTcAbnp4PA9NmV7O0CVJ267+wKxG27OBgzZqsztARDwK1AKXpJT+2sKx/Td3sqpPuiKC\ns48exRV3P8jilau59IPv4KkZs5m7ZFlDm1cWLOYbv3uBN9bXcdxew/jQYftx9V8fAeCN9XX87+33\nZhV+RaiJ4Px3HsWFN9/DguUrufbTZ/DotJeZueCtCu38ZSu44u4H+eCh+zU59uBhu7L7Tr351LW3\n0762lqs+fhpPTJ/J6nVvlvsyJEltTESMBkY32nVdSum6xk2aOSxttN0OGAYcDQwA/hkRe7Xy2Caq\nvntxSN+ezFu6ggXLV1KXy/H4C69wwOABTdo8P2ceb6yvA2D66wvp0aljFqFWrD3692XO4mW8tmQ5\n6+ty/H3yixw2fHCTNq8vXcGMeYtIqemf51179+DZmXOpyyXWvrme6a8vZNTQXcsZviSpjUopXZdS\nGtnocd1GTWYDAxttDwDmNtPmnpTSmymll4Fp1CdhrTm2iapPurp36sjilasbthevXE33zi0nVUeN\nGMqzM996T9u3q+XSM97BJR84aZNkTa3Tu2snFixf0bC9YPlKenft1KpjX5pXn2Rt374dO3bswH6D\n+tOna+dShSpJqizjgWERMSgitgPOBMZu1OZu4BiAiOhFfXfjDOA+4MSI6B4R3YET8/ta1OruxYh4\nN/BtYNf8cQGklFLX1r5GWxTNFgebrw4eNnwQg/v04Dt3PtCw7/zf/IGlq9bQu2tn/ud9xzNr4VLm\nL19ZomirRwsfwSYmvDSLPXbuwzWfPJ2lq9YwZdbr1OVypQ1OklQRUkrrI+I86pOlWuCGlNKUiLgU\nmJBSGstbydVUoA74ckppEUBEfJv6xA3g0pTS4s2dr5AxXT8BTgMmpY37eJrRuB91zJgxQNvsklu8\ncjU9GlW2enTuyJJVazZpN2JgP04ZuReX3XU/6xv9p74033bB8pU8P2ceu/buYdJVoAXLV9G761tL\n2PXu2pmF+YkKrXHLP5/iln8+BcDXTz+R2YuXbeEISZLqpZTuBe7daN/FjX5PwBfzj42PvQG4obXn\nKqR7cRYwuTUJVz6Qhn7U0aNHb/mAjMyYt4h+3brQu2snamtqOHj33Xj65dlN2uzaqzufOOYgfvSn\ncSxfs65hf8ftt6NdTf1b2LnD9uy+U2/m+B9+wabNnceAnjvSr1sX2tXWcOxew3hs2sutOrYmgq47\ndABgcN+eDOnbkwkvvVrKcCVJ2iqFVLq+AtwbEQ8DDZlHSulHRY+qjHIpcePD4/nKKcdRUxM8PPUl\n5ixexukH7c3L8xfz9Muz+dDh+9OhfTs+/44jgLeWhujfvSufOOYgctRnr398akqTWY9qnbpc4qp7\n/8EPzjqVmgj+8sxUXlmwmI8fM4ppc+fz2LRXGL5zH75z5jvp3GF7Dtl9EOccPYqP//y3tKut4aef\nOA2A1eve4LK7HqAu18q+SUmSyihaWbgiIu4HVgKTgIb+tZTSt1pxeProz27ZqgBVHLf890cBOPqS\nqzOOpLqNu+S8rEOQpI01N7q5LFasWFHSb8ldunTJ7NqaU0ilq0dK6cSSRSJJklTBChnT9beIMOmS\nJEnaCoUkXecCf42INRGxPCJWRMTyUgUmSZJUSVrdvZhS6rLlVpIkSWpOqytdEfFga/ZJkiRpU1us\ndEVEB+pXNu2VX+Z+w0yArsDOJYxNkiSpYrSme/G/gC9Qn2A9xVtJ13LgmhLFJUmSKtybte2zDqGs\ntph0pZSuAq6KiP9OKf2sDDFJkiRVnEJmL74eEV0AIuLrEXFXROxforgkSVKFS6m0j7amkKTrGyml\nFRFxOHAScCPwi9KEJUmSVFkKSbrq8j/fBfwipXQPsF3xQ5IkSdUgl1JJH21NIUnXnIgYA5xB/Y2v\nty/weEmSpKpVyL0XzwBOBn6YUloaETsBXy5NWJIkqdKlNliNKqXWrNPVo9HmuEb71gETShOWJElS\nZWlNpespIFG/PteGnxskYHAJ4pIkSRXOStdGUkqDWvNCETEipTTlPw9JkiSp8hQypmtLbgZct0uS\nJLVKW5xhWErFnH0YW24iSZJUnYpZ6aqudFWSJP1HqqzQ5TpbkiRJ5VDMStcbRXwtSZJU4Zy9uJGI\n2COl9O+Wbm6dUno6//PgYgcnSZJUKVpT6foiMBq4kqbjtjas23VsCeKSJEkVLldlw8G3OKYrpTQ6\n/+s7gT8Dy4ClwNj8PkmSJG1BIWO6bgSWAz/Nb38IuIn6ezJKkiQVxDFdLRueUtqn0fZDEfFssQOS\nJEnVwcVRW/ZMRDQMlo+Ig4BHix+SJElS5WnN7MVJ1A+Ybw98LCJezW/vCkwtbXiSJKlS5XLVVelq\nTffiu0sehSRJUoXbYtKVUppZjkAkSVJ1qbIhXd4GSJIkqRyKeRsgSZKkVqu2JSOsdEmSJJWBlS5J\nkpQJbwMkSZKkorPSJUmSMuGYLkmSJBWdlS5JkpQJK12SJEkqOitdkiQpE1V260UrXZIkSeVgpUuS\nJGXCMV2SJEkqOitdkiQpE9VW6YoyXXB1vauSJG07IqsTT549r6T5wV4D+mZ2bc2x0iVJkjKRq7JK\nV9mSrrFPTS3XqdSMUw7YE4DHp7+acSTV7eChuwBw3KU/zziS6vbgxZ/LOgRJVF/S5UB6SZKkMrB7\nUZIkZaLaBtJb6ZIkSSoDK12SJCkTjumSJElS0VnpkiRJmaiyQpeVLkmSpHKw0iVJkjLh7EVJkiQV\nnZUuSZKUCWcvSpIkqeisdEmSpEw4pkuSJElFZ6VLkiRlosoKXVa6JEmSysFKlyRJyoSzFyVJklR0\nVrokSVImnL0oSZKkorPSJUmSMlFtY7pMuiRJUiaqLemye1GSJKkMrHRJkqRMOJBekiRJRWelS5Ik\nZcJKlyRJkorOSpckScpErroKXVa6JEmSysFKlyRJyoRjuiRJklR0VrokSVImrHRJkiRViYg4OSKm\nRcT0iPjaZtq9PyJSRIzMb+8WEWsiYmL+ce2WzmWlS5IkZSJHtpWuiKgFrgFOAGYD4yNibEpp6kbt\nugCfB57Y6CVeSint29rzWemSJEnVahQwPaU0I6X0BnA7cGoz7b4NfB9Y+5+czKRLkiRlIqVU0kcr\n9AdmNdqend/XICL2AwamlP7UzPGDIuKZiHg4Io7Y0snsXpQkSRUpIkYDoxvtui6ldF3jJs0c1pCt\nRUQN8GPgnGbavQbsklJaFBEHAHdHxIiU0vKW4jHpkiRJmSj1ivT5BOu6zTSZDQxstD0AmNtouwuw\nFzAuIgD6AWMj4pSU0gRgXf48T0XES8DuwISWTmb3oiRJqlbjgWERMSgitgPOBMZueDKltCyl1Cul\ntFtKaTfgceCUlNKEiOidH4hPRAwGhgEzNncyK12SJCkTuYxvvphSWh8R5wH3AbXADSmlKRFxKTAh\npTR2M4cfCVwaEeuBOuAzKaXFmzufSZckSapaKaV7gXs32ndxC22PbvT7ncCdhZzLpEuSJGXCFekl\nSZJUdFa6gH8/+zRjb/oVuVyOUcccz7GnnN5su+eeeIybr/oBn//ODxg4eGjD/iULF/DDL3+eE07/\nIEe/+73lCruiPDdhPLde93NyuRxHnfgO3n3Gmc22G//IP7j68m9zyU+uZtCw4ax/801+ffVPeOXF\nF4iaGj4y+nO8be99yhx95ThwyEDOPelwampquPeZqdz+6DNNnn//wfvwzv3eRl0usXT1Gn4w9u/M\nX7YSgBP3Hs5HjjgAgFv/+RT3Pzet7PFL2rZY6aoyuVwdf/j1dXzyK9/gwh/8lImPPcK82bM2abd2\nzRoeue/P7DJ0902eG3vzDeyxz37lCLci5erquOkXP+NL3/oul//ieh7/x0PMeXXmJu3WrF7N/WPv\nZsjwPRr2jbuvvhv+sp//kq985wp+e/0Ycrlc2WKvJDURfP4dR3LRbX/mEz//LceOGMauvbo3aTP9\n9QV89pd38Okxv+MfU19i9PGHAtClw/acddRIzvvVnZz7qzs566iRdO6wfRaXIWkbkiOV9NHWVH3S\n9er0F+nVdyd69u1Hu3bt2feQw5ny1JObtLvv/27j6He/l3bt2zfZP3n8E/Ts05e+A3YpV8gVZ8YL\n0+i788702Wkn2rVvz0FHHs3Tjz+2Sbu7bvkN73r/GbTfbruGfXNfncme+YS3a7fudOrciZdffKFs\nsVeSPfr3Yc6SZby2dDnrczkemjKdQ4cPatJm4itzWbd+PQDPz5lH766dABg5ZCBPz5jNirXrWLl2\nHU/PmM2BQwZucg5JqmYFJ10R0TUiemx4lCKoclq+ZDHdevZq2N6xR0+WLV7UpM2cV2awdNFC9tz/\nwCb731i7lof+eBcnnP7BssRaqZYsWkiPXr0btnv06sWSRQubtJn50nQWL1jAvqMObrJ/4KAhPPP4\nY9TV1bHg9dd4ZfqLLF64oCxxV5peXTqxIN9VCLBg+Up6denUYvt37Ps2npz+av2xXTszf/lGx3bt\nXLpgJVWENnAboLJq9ZiuiPgv4FJgDW8tkZ+AwSWIq2ya+1Dyq84CkMvlGHvzDXzwM5/fpN19d97O\nke88he077FDSGCtds58BTT+D2375Cz51wZc3aXfkiSczd9arXHL+5+jZpy9D37YntTW1JY23cm16\nN4zUQnn++Lfvzu479+aLN97dwpFAG/wHT5KyVMhA+guBESmlhVtsSdP7HY0ZM4Z+Bxy+FeGV3o49\nerK0UVVl2eJFdO3+VgFv3do1vD7rVa799tcBWLFsKb/54Xc558L/Ydb0F5j0xGP8+bYbWbN6FRE1\ntG+/HYed9M6yX8e2rEev3k2qU4sXLqRbz54N22vXrGH2zFe44msXArBsyWJ+cunFfOHiSxk0bDgf\nGf3Zhrbf/tL59O3f5F6laqWFK1bSe8e3qlO9u3Zm0YrVm7Tbf9AAPnz4AXzxxrt5s65+/NyC5SvZ\nd7f+TY6d+Mqc0gctaZtWbd/NCkm6XgI2/Re4BRvd7yiNfWpqIXGVzcAhw1j4+mssnj+Prj16MPFf\nj/Dh8y5oeH6Hjp341nU3NWz/4ttf590fOYeBg4fyuW9+t2H//XfcznYdOphwbYVBuw9n3pw5LHj9\nNbr37MUT/xjHZ758UcPzHTt14prfvrX+3OVf+xJnfnI0g4YNZ93atUBi+w47MPmZp6ipraX/Lrtm\ncBXbvn/PmU//HjvSr1sXFi5fxTEjhnLZHx5o0mZov15c8K6j+Nptf2Lp6jUN+ye8NItPHntww+D5\nAwYP5PoHHy9r/JLU1hWSdF0EPBYRT5C/wSNASmnTfrdtSG1tLe8959P88opv1S8ZcfRx9BuwC/f9\n320MGDyUEQeMyjrEildbW8tZnz2PH3zjInK5HEeecBIDdt2Nu27+DbsN2539Dz60xWOXL1vKD79x\nERFB9569+K8Lv1rGyCtLLiV+9pd/8r2PvIeaCP4y8d/MXLCEc44+kGlzF/CvF15h9PGHsMN27bn4\n/ScBMH/ZCr7xu7+wYu06bvnnBH7+qfcDcPM/JrBi7brNnU6SyFVZqStaO9AsIp4EHgEmAQ1z8lNK\nN7bi8DZb6aoWpxywJwCP5weBsMBlAAAY/ElEQVQ+KxsHD62f5XrcpT/POJLq9uDFn8s6BKktaXZY\nZjn83xPPlTTr+sBBe2d2bc0ppNK1PqX0xZJFIkmSqkpbnGFYSoUsGfFQRIyOiJ0qackISZKkciik\n0vXh/M+LGu3b5peMkCRJ2ai2SlchSdfbUkprG++IiA5FjkeSJKkiFdK9uOl9WZrfJ0mStEW5lEr6\naGu2WOmKiH5Af2CHiNiPt2Y5dAU6ljA2SZKkitGa7sWTgHOAAcCVvJV0rQD+pzRhSZKkStcWq1Gl\ntMWkK78O140RcXpK6c4ttZckSdKmChnTNSAiuka96yPi6Yg4sWSRSZKkipZSKumjrSkk6fpESmk5\ncCLQB/g4cEVJopIkSaowhSwZsWEs1zuBX6eUno2INrW8viRJ2nbk2l4xqqQKqXQ9FRH3U5903RcR\nXWh0D0ZJkiS1rJBK1yeBfYEZKaXVEdGT+i5GSZKkgrXFcVel1Jp1uvbfaNdgexUlSdJ/yqRrU1du\n5rkEHFukWCRJkipWa9bpOqY1LxQRJ6SUHvjPQ5IkSdWg2hZHLWQg/ZZ8r4ivJUmSVFEKGUi/JQ70\nkiRJrVZlha6iVrqq7K2TJElqvWJWuiRJklqt2mYvFrPS9UoRX0uSJKmiFFTpiohDgd0aH5dSuin/\n87SiRiZJkipatc1ebHXSFRE3A0OAiUBdfncCbipBXJIkSRWlkErXSGDPVG0dsJIkqSSqLaUoZEzX\nZKBfqQKRJEmqZIVUunoBUyPiSWDdhp0ppVOKHpUkSap4julq2SWlCkKSJKnStTrpSik9XMpAJElS\ndam2Slerx3RFxGkR8WJELIuI5RGxIiKWlzI4SZKkSlFI9+L3gfeklJ4vVTCSJKl6OHuxZfNMuCRJ\nkrZOIZWuCRHxO+Bums5evKvoUUmSpIpXZYWugpKursBq4MRG+xJg0iVJkrQFhSRdNcD5KaWlABHR\nHbiyJFFJkqSKV22zFwtJuvbekHABpJSWRMR+JYhJkiRVAQfSb6ZtvroFQET0oLCkTZIkqWoVkjRd\nCTwWEXdQP5brDOCykkQlSZIqXrVVugpZkf6miJgAHAsEcFpKaWrJIpMkSaogBXUP5pMsEy1JkvQf\nq7aB9IWM6ZIkSdJWciC8JEnKRHXVuax0SZIklYWVLkmSlAnHdEmSJKnookxrZFRXKitJ0rYjsjrx\n98b+vaT5wVdPOTaza2uOlS5JkqQyKNuYrk9de3u5TqVmXP+ZMwFYO+XfGUdS3TqM2AOA0678dcaR\nVLe7vvRxfv/4s1mHUfXOOHifrENQxnK56uoIs9IlSZJUBs5elCRJmai2ey9a6ZIkSSoDK12SJCkT\nrtMlSZKkorPSJUmSMlFddS4rXZIkSWVhpUuSJGWi2mYvmnRJkqRMOJBekiRJRWelS5IkZaLauhet\ndEmSJJWBlS5JkpQJx3RJkiSp6Kx0SZKkTFRZoctKlyRJUjlY6ZIkSZlw9qIkSZKKzkqXJEnKhLMX\nJUmSVHRWuiRJUiasdEmSJKnorHRJkqRMOHtRkiSpSkTEyRExLSKmR8TXmnn+MxExKSImRsQjEbFn\no+cuyh83LSJO2tK5rHRJkqRMZF3pioha4BrgBGA2MD4ixqaUpjZqdltK6dp8+1OAHwEn55OvM4ER\nwM7A3yJi95RSXUvns9IlSZKq1ShgekppRkrpDeB24NTGDVJKyxttdgI2ZIqnArenlNallF4Gpudf\nr0VWuiRJUiZy2Q/p6g/MarQ9Gzho40YRcS7wRWA74NhGxz6+0bH9N3cyK12SJKkiRcToiJjQ6DF6\n4ybNHLZJKphSuialNAT4KvD1Qo5tzEqXJEnKRKnHdKWUrgOu20yT2cDARtsDgLmbaX878IutPNZK\nlyRJqlrjgWERMSgitqN+YPzYxg0iYlijzXcBL+Z/HwucGRHbR8QgYBjw5OZOZqVLkiRlIuvZiyml\n9RFxHnAfUAvckFKaEhGXAhNSSmOB8yLieOBNYAlwdv7YKRHxe2AqsB44d3MzF8GkS5IkZaQt3AYo\npXQvcO9G+y5u9Pv5mzn2MuCy1p7L7kVJkqQysNIlSZIykXX3YrlZ6ZIkSSoDK12SJCkTbWBx1LKy\n0iVJklQGVrokSVImcimXdQhlZaVLkiSpDKx0SZKkTFTZ5EUrXZIkSeVgpUuSJGWi2tbpMukCRgzs\nx4cO25+aCP75/Az+MvH5Js+fsPdwjthjMLmUWLFmHb8e9wSLV65m+M59+OCh+zW026lbV8b87TEm\nvjKn3JewzXv06af53g2/JJfL8b7jT+CTp71/kzb3PfoI1/7utxDB8N0GccUFXwLgtQULuOTnVzNv\n4UIi4OqvX0z/Pn3LfQkVYb/d+vOJYw6iJoK/TX6BPzw5qcnz7zlgBMe/fXfqcjmWr17LNfc9woIV\nq+jdpRNfOfVYaiKoranh3mee5/7npmV0Fdu+F5+byJ9v/TUpl+OAo47jyHe/t9l2k8c/zu+u/hGf\nueRy+g8awvTJz/HA729lfd162tW246Qzz2LwnnuVOXpJLan6pCsi+MjhI/nRnx5iyao1fP20E5g4\ncw6vLVne0ObVhUv4zl3388b6Oo7ecygfOHhfxvztMabNnc+ld9wHQKftt+O7H3oXU2e/ntWlbLPq\n6ur47i/HMOab36Jvz558+CsXcvSBoxgycJeGNjPnzuVXd93Bjd/9Hl07d2bR0qUNz339pz/hU6d/\ngEP23ZfVa9YQNfaab42aCD593MF86477WLRiNd//yHsYP/1VZi9e1tDm5fmL+PItY3ljfR0n7TOc\njx11IFf+aRxLVq3hot/+mfV1OTq0b8dPzn4v4196lSWr1mR4RdumXC7HH2/6Fed85et07dGTay+5\niD32G0mf/gOatFu3Zg2P3/8XBgwZ1rCvY5cufOSCr9K1ew/mzX6VG39wGV+5aky5L0FqtbZw78Vy\nqvr/nQb16cH85StYuGIVdbkcT770Kvvu1r9Jm2lz5/PG+vobh780byHdO++wyescMHggk2a91tBO\nrTd5+osM3KkfA/r1o3379px8+BGMe/LJJm3u+tv9nHnyO+nauTMAPbt1A+ClWa+yvq6OQ/bdF4CO\nO+zADttvX94LqBBD+/XitaUrmLdsJetzOR6ZNoNRQ3dp0mbyrNcb/oy/8NoCenbuCMD6XI71dfVT\nv9vV1hIR5Q2+gsyeMZ2effvRo09f2rVrx9sPOpTnnx6/SbsH7/odR7zrFNq1b9+wb+ddB9G1ew8A\n+vQfyPo332T9m2+WLXZJm1dQpSsiugMDGx+XUnq62EGVU/dOO7Bk5eqG7SUr1zC4b48W2x/xtsFM\nevW1TfYfOHQXHnjW7pStMX/RIvr17NWw3adnTya9+EKTNjPnzgXg7Iu+Sl0ux2c/+CEO239/Zs6d\nS5dOnbjge5czZ/48Dt57H87/6Meora0t6zVUgp6dO7JoxaqG7UUrVjNsp94ttj9ur915+uW3utJ7\ndunE/77veHbq1pUb/zHeKtdWWr5kMTv26NmwvWOPnsx+6cUmbebOfJllixcyfN8DeOQvf2z2daZM\neIKddh3UJCmT2ppqG9PV6kpXRHwbeA74KXBl/vHDEsVVRpt+I2/pz8DBw3Zl1949uG/iv5vs37Fj\nBwb02JEpszdNxrRlzb3dsdHnsr6ujplz53L9ty/jii9eyCU/v5rlq1ZSV1fHM89P5Utnf5zbvn8l\ns+fN456H/l6ewCtNs9Wp5v8yHPm2wQzt25O7J7w15mvRilV88aZ7+Nyv7uCYPYeyY8cOJQq0wjX3\nD1CjzyaXy/GX227k5DM/1uJLzJs9i/t/dyunnvPpUkQoaSsVUuk6AxiSUnqjNY0jYjQwGmDMmDFA\n18KjK4Mlq1bTPd9FAtC98w4sXb3pN/S39e/Lu/bfk+/f83fW55quoDtyyC48/fIc6qrtJlJF0rdn\nT15ftLBhe/6iRfTp0WOTNnvvPpz27doxoG9fduvfn1fnvkbfnr3YY9BgBvTrB8Axow5i0gvTgBPK\neQkVYdGKVfTs0qlhu2eXjixuVAXeYO9dduL9B+3DN373l4YuxcaWrFrDrEVL2bN/X/714sySxlyJ\nuvboybLFixq2ly1eRJdu3Ru231i7lvmzZ3HDFd8CYOWypdz6k+/zkS98hf6DhrBs8SJ++9Mfcvro\nc+nRt1/Z45cKYaWrZZOBbq1tnFK6LqU0MqU0cvTo0YVHViavzF9M3x270KtLJ2prahg1ZBee3Wj2\n4cCe3TjryAP52V//yYq16zZ5jVFDd+HJ6f7nsrVGDB3Gq6+9xux583jzzTf56yP/5KgDRzVpc+yo\ngxk/ub6qsmT5cmbOncOAfn0ZMXQoy1euZPGy+sHeT056jsEDB5b9GirB9NcXslO3rvTp2pl2NTUc\nPnww41+a1aTNoD49+MwJh3L53Q+ybM3ahv09O3dku3b1Xbqdtt+OPXbuw5xGk1HUev0HDWHRvNdY\nsmA+69evZ9ITj7HHfiMbnu/QsSMXXfMrvnTlNXzpymsYMGRYQ8K1ZtUqbv7RFZzwgQ+x6+57ZHgV\nkppTSKXrcuCZiJgMNGQeKaVTih5VGeVS4rZHnuIL7zqKmqjh0WkzmLtkOaeO3ItXFizm2Zlz+cAh\n+9KhfTs+c8JhACxeuZqr//pPoH4cS4/OHXlh7vwsL2Ob1q62los+NZrPXnoJuVyO9x53HEN32YVr\nfnsrI4YM5ehRB3Hofvvx2LPP8L7Pn0tNTS0XnH0O3brUV0+/ePbHGX3JN0gJ9hwyhNOPPzHjK9o2\n5VLi+r8/zsWnn0hNTfDg5BeZtWgpZx66Hy/NW8j4l2bxsSMPpEP79lz4nqMBWLhiFZff/SADenbj\n7KMOrO+NDLhnwmReXbgk0+vZVtXW1vLusz7BjT+4jFwux/5HHkPfAQN58K7fsfNuQ3jb/iNbPPaJ\nv/2VxfNeZ9zYOxk39k4Azv7y1+ncdcdyhS8VpNo6iKK1pb2ImAKMASYBDX0KKaWHW3F4+tS1t29V\ngCqO6z9zJgBrp/x7Cy1VSh1G1FcfTrvy1xlHUt3u+tLH+f3jz2YdRtU74+B9sg5B9TKbbvyJX9xe\n0rTrhs+e2aamUhdS6VqYUvppySKRJElVpdrGdBWSdD0VEZcDY2navbhNLxkhSZKykWthhnSlKiTp\n2nC/m4Mb7UvAscULR5IkqTIVknR9MqU0o/GOiBhc5HgkSVKVqLbuxUKWjLijmX3/V6xAJEmSKtkW\nK10RsQcwAtgxIk5r9FRXwCWnJUnSVslV2ZoRreleHA68m/qFUd/TaP8KwHtMSJIktcIWk66U0j3A\nPRFxSErpX2WISZIkVQHHdLXsfRHRNSLaR8SDEbEwIj5assgkSZIqSCFJ14kppeXUdzXOBnYHvlyS\nqCRJUsXLpdI+2ppCkq72+Z/vBH6bUlpcgngkSZIqUiHrdP0xIv4NrAE+FxG9gbWlCUuSJFU6x3S1\nIKX0NeAQYGRK6U1gFXBqqQKTJEmqJK1Zp+u0ZvY13ryrmAFJkqTqkLz34ibes5nnEiZdkiRJW9Sa\ndbo+3poXioizU0o3/uchSZKkapBzTNdWO7+IryVJklRRCpm9uCWx5SaSJEn1nL249arrnZMkSSqA\nlS5JkpSJtrhqfCkVs9L1aBFfS5IkqaK0Zp2uj6aUbomILzb3fErpR/mf5xU7OEmSVLmqbUxXa7oX\nO+V/dillIJIkqbqYdG0kpTQm//NbpQ9HkiSpMrV6TFdEDI6IP0bEgoiYHxH3RMTgUgYnSZIqVy6l\nkj7amkIG0t8G/B7YCdgZ+D/gt6UISpIkqdIUknRFSunmlNL6/OMWXJtLkiRtpWqrdLVm9mKP/K8P\nRcTXgNupT7Y+CPy5hLFJkiRVjNbMXnyK+iRrw+Kn/9XouQR8u9hBSZKkyufsxY2klAa15oUi4oSU\n0gP/eUiSJEmVp5gr0n+viK8lSZIqXEqlfbQ1xUy6vPeiJElSC4p5w+s2mFNKkqS2qi3OMCylYla6\nJEmS1IJiVrpeKeJrSZKkCufsxc2IiEOB3Rofl1K6Kf/ztKJGJkmSVEFanXRFxM3AEGAiUJffnYCb\nShCXJEmqcNU2pquQStdIYM9UbbVASZKkIigk6ZoM9ANeK1EskiSpilRbHaeQpKsXMDUingTWbdiZ\nUjql6FFJkiRVmEKSrktKFYQkSao+VVboan3SlVJ6uJSBSJIkVbJCZi+eRv39FftQf8ufAFJKqWuJ\nYpMkSRXM2Yst+z7wnpTS86UKRpIkVY9qG0gfrb3giHg0pXTYVp6nut5VSZK2HZHViY++5OqS5gfj\nLjkvs2trTiFJ11XULxlxN01nL95VmtDalogYnVK6Lus4qp2fQ9vg59A2+Dlkz89AhSgk6fp1M7tT\nSukTxQ2pbYqICSmlkVnHUe38HNoGP4e2wc8he34GKkQhY7pqgPNTSksBIqI7cGVJopIkSaowNQW0\n3XtDwgWQUloC7Ff8kCRJkipPIUlXTb66BUBE9KCwStm2zj77tsHPoW3wc2gb/Byy52egVitkTNfH\ngIuAO6ifjXgGcFlK6ebShSdJklQZWp10AUTEnsCx1E8vfTClNLVUgUmSJFWSgpIuqVQiYmVKqfNm\nnv+flNJ3yxmTJEnFVMiYLilL/5N1AJUiInaLiMnN7L8+X81u6bhXIqLXZp7/QkR0LFacap2IGBcR\nLS5ZEBHnRMTO5YypErX05z8iPpMfftPScb+JiPdv5vn3bu7vnSqLSVdeRHwsIp6LiGcj4ub8X5Sf\nRsRjETFjw1+aiDg6/4/cHRHx74i4NSLa1Iq327KI2Cki/hEREyNickQcERFXADvk992aTxr+nU8S\nJuf3HR8Rj0bEixExKuvr2BallD71Hw4Z+AJg0tX2nAOYdJVISunalNJN/8FLvBcw6aoSJl1ARIwA\n/hc4NqW0D3B+/qmdgMOBdwNXNDpkP+r/g9kTGAxs7e2RtKkPA/ellPYF9gEmppS+BqxJKe2bUvpI\nvt1Q4Cpgb2CP/HGHAxdiVaw12kXEjfkvGndERMctVUw2iIhOEfHn/BeUyRHxwYj4PPX/sT8UEQ/l\n262MiO9FxFMR8beIGJU/x4yIOKXUF9jWlPqLXUTU5l9zckRMiogL8q85Erg1/6Vlh3zF5rsR8a+I\nmBAR+0fEfRHxUkR8ptTvQ6mV+H3+ckQ8mX8Mzb/OJRFxYStjuyIipubj+2FEHAqcAvwg//kMycf0\n4/yXz+cj4sCIuCv/hfI7/9Gbo8xV05IPm3MscEdKaSFASmlx/u/e3SmlHDA1Ivo2av9kSmk2QERM\nBHYDHilvyBVrPHBDRLSn/v2f2EK7l1NKkwAiYgr1EztSREyi/vPQ5g0HPplSejQibgA+V8CxJwNz\nU0rvAoiIHVNKyyLii8AxG/4eAZ2AcSmlr0bEH4DvACdQ/2XlRmBssS6mrWv0xe6wlNLCqF9y50e8\n9cVuD+rfjzvyh+wHjADmAo9S/8VuS//G7Av0TyntlT9nt5TS0og4D7gwpTQhvx9gVkrpkIj4MfCb\n/Ot3AKYA1xblojNQhvd5eUppVNR3J/6E+i/krY2tB/A+YI/8v1UbPp+xwJ9SSnfk2wG8kVI6MiLO\nB+4BDgAWAy9FxI9TSotae161LVa66gXN35R73UZtmttfh8lr0aSU/gEcCcwBbo6Wx0o0/gxyjbZz\n+Hm0xqyU0qP532+h/j+k1poEHJ+vYh2RUlrWQrs3gL82OubhlNKb+d9324qYt2WbfLHL7787pZTL\nd+tu8sUu/6Vvwxe7LZkBDI6In0XEycDyzbTdkPBOAp5IKa1IKS0A1kZEt9ZfVptT6vf5t41+HlJg\nbMuBtcD1EXEasHozbRt/PlNSSq+llNZR/xkPLPC8akNMuuo9CJwRET2h4RuJMhARuwLzU0q/BH4F\n7J9/6s189UvFsfGXjFZPY04pvUD9N+9JwOURcXELTd9Mb02PbkiM8//BVVtiXPIvdvm7hOwDjAPO\nBa7fTPPGX1I2/gKzLX82pX6fUwu/b1FKaT0wCriT+nFcf91M80r9fKqeSReQUpoCXAY8HBHPUl+O\nVjaOBiZGxDPA6dSP24L6VZ+fi4hbswqswuwSERu+qX+IArrHo34m3OqU0i3AD3krMV4BdClqlJWj\n5F/son5mXU1K6U7gG1Tn51Lq9/mDjX7+q5ADI6IzsGNK6V7qxwTvm3+qmj6fqmfGnJdSupH6cSYt\nPd85/3Mc9d8kN+w/r9SxVYNG72+zn0NK6avAVxvt2qvRc+c0+v2Vxs+pRc8DZ0fEGOBF4BfAe1p5\n7NupH/ibA94EPpvffx3wl4h4LaV0TLED3pallKZExIYvdnXAMyU4TX/g1xGx4cv0RfmfvwGujYg1\nFN4ltk0pw/u8fUQ8QX3B4kMFHtsFuCciOlBfbbsgv/924JdRPxmlxaUlVBlcHFWSJKkM7F6UJEkq\nA7sXJTWR7z7ZfqPdZ21YokPZyC+7MWij3V9NKd2XRTyVamvf54i4hk3XbLwqpfTrYsanbZvdi5Ik\nSWVg96IkSVIZmHRJkiSVgUmXJElSGZh0SZIklYFJlyRJUhn8P2LEHcZ/hl+tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f321181a438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat(pred_df.corr(), inflate=False,show=False)\n",
    "plt.savefig('results/corr_matrix.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_pred_prob = pred_prob_base.mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_pred_class = np.argmax(avg_pred_prob,axis=1)\n",
    "avg_pred_class=avg_pred_class.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(testY,avg_pred_class)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_results['average'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average': 0.34,\n",
       " 'bi_lstm': 0.3,\n",
       " 'cnn': 0.38,\n",
       " 'cnn_bi_lstm': 0.35,\n",
       " 'cnn_lstm': 0.31,\n",
       " 'lstm': 0.34}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "majority_pred_class = [int(np.argmax(np.bincount(x))) for x in pred_class_base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(testY,majority_pred_class)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_results['majority'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average': 0.34,\n",
       " 'bi_lstm': 0.3,\n",
       " 'cnn': 0.38,\n",
       " 'cnn_bi_lstm': 0.35,\n",
       " 'cnn_lstm': 0.31,\n",
       " 'lstm': 0.34,\n",
       " 'majority': 0.33}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('results/ens_result.json','w') as fout:\n",
    "    json.dump(acc_results,fout,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
