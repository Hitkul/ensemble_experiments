{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from gensim.models import KeyedVectors\n",
    "import word2vecReader as godin_embedding\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [12,10]\n",
    "from mlens.visualization import corrmat\n",
    "from base_learners import cnn,bi_lstm,cnn_bi_lstm,cnn_lstm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(filename,test_flag = False):\n",
    "    data = pd.read_csv(filename, sep=\"\\t\", header=None)\n",
    "    if not test_flag:\n",
    "        data.columns = [\"tweet_id\", \"username\", \"database_id\", \"class\",\"tweet\"]\n",
    "    else:\n",
    "        data.columns = [\"a\", \"b\", \"med\",\"med\", \"tweet\",\"class\",]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = load_data_from_file('dataset/personal_intake_tweets.txt')\n",
    "dev_data = load_data_from_file('dataset/personal_intake_tweets_dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = train_data['tweet'].tolist()+dev_data['tweet'].tolist()\n",
    "train_labels = train_data['class'].tolist()+dev_data['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = load_data_from_file('dataset/task_2_test_full_form.txt',test_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = test_data['class'].tolist()\n",
    "test_sentences = test_data['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9107, 9107, 7419, 7419)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels),len(train_sentences),len(test_labels),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = [x-1 for x in test_labels]\n",
    "train_labels = [x-1 for x in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = len(set(train_labels))\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(string.punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    # should have used translate but for some reason it breaks on my server\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = [clean_sentence(s) for s in train_sentences]\n",
    "testX = [clean_sentence(s) for s in test_sentences]\n",
    "trainY = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading Goding model.\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_embedding_matrix(model,dim):\n",
    "    #dim = 300 for google word2vec\n",
    "    #dim = 400 for godin\n",
    "    #dim = 100 for fast text\n",
    "    embedding_matrix = np.zeros((vocab_size,dim))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(test_labels,pred_class):\n",
    "    f1 = f1_score(test_labels,pred_class,labels=[0,1],average='micro')\n",
    "    p = precision_score(test_labels,pred_class,labels=[0,1],average='micro')\n",
    "    r = recall_score(test_labels,pred_class,labels=[0,1],average='micro')\n",
    "    acc = accuracy_score(test_labels,pred_class)\n",
    "    return [f1,p,r,acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pred_class(model):\n",
    "    pred = model.predict(testX)\n",
    "    return [int(np.argmax(x)) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 20\n",
      "Vocabulary size: 10940\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(trainX)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "trainX = encode_text(tokenizer, trainX, max_len)\n",
    "testX = encode_text(tokenizer, testX, max_len)\n",
    "trainY = to_categorical(trainY,num_classes=number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Goding model.\n"
     ]
    }
   ],
   "source": [
    "godin_model = load_godin_word_embedding(\"../word_embeddings/word2vec_twitter_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix_godin = get_word_embedding_matrix(godin_model,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cnn = load_model('models/cnn.h5')\n",
    "model_bi_lstm = load_model('models/bi_lstm.h5')\n",
    "model_cnn_bi_lstm = load_model('models/cnn_bi_lstm.h5')\n",
    "model_cnn_lstm = load_model('models/cnn_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_models = [('cnn',model_cnn),('bi_lstm',model_bi_lstm),('cnn_bi_lstm',model_cnn_bi_lstm),('cnn_lstm',model_cnn_lstm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class_base = [(name,get_pred_class(m)) for name,m in base_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_mat = np.zeros((len(pred_class_base[0][1]),len(pred_class_base)),dtype = np.int64)\n",
    "for i,p in enumerate(pred_class_base):\n",
    "    pred_mat[:,i] = p[1]\n",
    "\n",
    "pred_df = pd.DataFrame(pred_mat)\n",
    "pred_df.columns = [\"cnn\", \"bi_lstm\",\"cnn_bi_lstm\",\"cnn_lstm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_base = [(name,get_results(test_labels,pred_class)) for name,pred_class in pred_class_base]\n",
    "result_base_f = []\n",
    "for t in result_base:\n",
    "    temp = [t[0]]\n",
    "    for x in t[1]:\n",
    "        temp.append(x)\n",
    "    result_base_f.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance = pd.DataFrame(columns=['model','f1', 'precision', 'recall','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,result in enumerate(result_base_f):\n",
    "    model_performance.loc[i] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.637957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi_lstm</td>\n",
       "      <td>0.617651</td>\n",
       "      <td>0.654555</td>\n",
       "      <td>0.584686</td>\n",
       "      <td>0.662758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_bi_lstm</td>\n",
       "      <td>0.632167</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.607314</td>\n",
       "      <td>0.672058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.642971</td>\n",
       "      <td>0.669902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model        f1  precision    recall  accuracy\n",
       "0          cnn  0.623187   0.587997  0.662857  0.637957\n",
       "1      bi_lstm  0.617651   0.654555  0.584686  0.662758\n",
       "2  cnn_bi_lstm  0.632167   0.659142  0.607314  0.672058\n",
       "3     cnn_lstm  0.637507   0.632135  0.642971  0.669902"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error prediction Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAIaCAYAAAAa3/j/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElqApMuSZKkJjDpkiRJaoL/Dzs+ld1GupaeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff19e0fce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff19e36f080>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat(pred_df.corr(), inflate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation values are moderately low, there is scope of improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_models = np.zeros((len(testX),number_of_classes,len(base_models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,p in enumerate(base_models):\n",
    "    pred_prob_models[:,:,i] = p[1].predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_pred_prob = pred_prob_models.mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_pred_class = [int(np.argmax(x)) for x in avg_pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_ensemble_result = get_results(test_labels,avg_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_ensemble_result.insert(0,'avg_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance.loc[4] = avg_ensemble_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.637957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi_lstm</td>\n",
       "      <td>0.617651</td>\n",
       "      <td>0.654555</td>\n",
       "      <td>0.584686</td>\n",
       "      <td>0.662758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_bi_lstm</td>\n",
       "      <td>0.632167</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.607314</td>\n",
       "      <td>0.672058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.642971</td>\n",
       "      <td>0.669902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_ensemble</td>\n",
       "      <td>0.646064</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>0.682572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model        f1  precision    recall  accuracy\n",
       "0           cnn  0.623187   0.587997  0.662857  0.637957\n",
       "1       bi_lstm  0.617651   0.654555  0.584686  0.662758\n",
       "2   cnn_bi_lstm  0.632167   0.659142  0.607314  0.672058\n",
       "3      cnn_lstm  0.637507   0.632135  0.642971  0.669902\n",
       "4  avg_ensemble  0.646064   0.659524  0.633143  0.682572"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_pred_class = np.zeros((len(testX),len(pred_class_base)),dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,p in enumerate(base_models):\n",
    "    base_pred_class[:,i] = get_pred_class(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2],\n",
       "       [1, 2, 2, 2],\n",
       "       [1, 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, 1],\n",
       "       [2, 2, 2, 2],\n",
       "       [1, 2, 2, 2]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "majority_pred_class = [int(np.argmax(np.bincount(x))) for x in base_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "majority_ensemble_result = get_results(test_labels,majority_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "majority_ensemble_result.insert(0,'majority_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance.loc[5] = majority_ensemble_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.637957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi_lstm</td>\n",
       "      <td>0.617651</td>\n",
       "      <td>0.654555</td>\n",
       "      <td>0.584686</td>\n",
       "      <td>0.662758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_bi_lstm</td>\n",
       "      <td>0.632167</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.607314</td>\n",
       "      <td>0.672058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.642971</td>\n",
       "      <td>0.669902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_ensemble</td>\n",
       "      <td>0.646064</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>0.682572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>majority_ensemble</td>\n",
       "      <td>0.653894</td>\n",
       "      <td>0.644953</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.682437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model        f1  precision    recall  accuracy\n",
       "0                cnn  0.623187   0.587997  0.662857  0.637957\n",
       "1            bi_lstm  0.617651   0.654555  0.584686  0.662758\n",
       "2        cnn_bi_lstm  0.632167   0.659142  0.607314  0.672058\n",
       "3           cnn_lstm  0.637507   0.632135  0.642971  0.669902\n",
       "4       avg_ensemble  0.646064   0.659524  0.633143  0.682572\n",
       "5  majority_ensemble  0.653894   0.644953  0.663086  0.682437"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super learner - blending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_cnn = {\n",
    "            \"n_dense\": 100,\n",
    "            \"dropout\": 0.7,\n",
    "            \"n_filters\": 100,\n",
    "            \"filter_size\": 2,\n",
    "            \"em\": 'embedding_matrix_godin',\n",
    "            \"batch\": 16,\n",
    "            \"epoch\": 7\n",
    "        }\n",
    "\n",
    "\n",
    "parameters_bi_lstm = {\n",
    "            \"dropout\": 0.7,\n",
    "            \"units_out\": 128,\n",
    "            \"em\": 'embedding_matrix_godin',\n",
    "            \"batch\": 8,\n",
    "            \"epoch\": 9\n",
    "        }\n",
    "\n",
    "parameters_bi_lstm_cnn = {\n",
    "            \"n_filters\":400,\n",
    "            \"filter_size\":4,\n",
    "            \"em\": 'embedding_matrix_godin',\n",
    "            \"conv_dropout\":0.7,\n",
    "            \"l_or_g_dropout\":0.2,\n",
    "            \"units_out\":16,\n",
    "            \"batch\": 8,\n",
    "            \"epoch\": 12\n",
    "        }\n",
    "\n",
    "parameters_lstm_cnn = {\n",
    "            \"n_filters\":300,\n",
    "            \"filter_size\":2,\n",
    "            \"em\": 'embedding_matrix_godin',\n",
    "            \"conv_dropout\":0.8,\n",
    "            \"l_or_g_dropout\":0.2,\n",
    "            \"units_out\":128,\n",
    "            \"batch\": 8,\n",
    "            \"epoch\": 15\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 20, 400)           4376000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,466,503\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,376,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 20, 400)           4376000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,918,467\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,376,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 20, 400)           4376000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 5,069,875\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,376,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 20, 400)           4376000   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 5,043,139\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,376,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "blend_base_cnn = cnn(length=max_len,\n",
    "                vocab_size=vocab_size,\n",
    "                n_dense=parameters_cnn['n_dense'],\n",
    "                dropout=parameters_cnn['dropout'],\n",
    "                n_filters=parameters_cnn['n_filters'],\n",
    "                filter_size=int(parameters_cnn['filter_size']),\n",
    "                em = eval(parameters_cnn['em']),\n",
    "                number_of_classes=number_of_classes)\n",
    "\n",
    "blend_base_bi_lstm = bi_lstm(length=max_len,\n",
    "                        vocab_size=vocab_size,\n",
    "                        dropout=parameters_bi_lstm['dropout'],\n",
    "                        units_out=parameters_bi_lstm['units_out'],\n",
    "                        em=eval(parameters_bi_lstm['em']),\n",
    "                        number_of_classes=number_of_classes)\n",
    "\n",
    "\n",
    "blend_base_cnn_bi_lstm = cnn_bi_lstm(length=max_len,\n",
    "                                vocab_size=vocab_size,\n",
    "                                n_filters=parameters_bi_lstm_cnn['n_filters'],\n",
    "                                filter_size=parameters_bi_lstm_cnn['filter_size'],\n",
    "                                em=eval(parameters_bi_lstm_cnn['em']),\n",
    "                                number_of_classes=number_of_classes,\n",
    "                                conv_dropout=parameters_bi_lstm_cnn['conv_dropout'],\n",
    "                                l_or_g_dropout=parameters_bi_lstm_cnn['l_or_g_dropout'],\n",
    "                                units_out=parameters_bi_lstm_cnn['units_out'])\n",
    "\n",
    "\n",
    "blend_base_cnn_lstm = cnn_lstm(length=max_len,\n",
    "                                vocab_size=vocab_size,\n",
    "                                n_filters=parameters_bi_lstm_cnn['n_filters'],\n",
    "                                filter_size=parameters_bi_lstm_cnn['filter_size'],\n",
    "                                em=eval(parameters_bi_lstm_cnn['em']),\n",
    "                                number_of_classes=number_of_classes,\n",
    "                                conv_dropout=parameters_bi_lstm_cnn['conv_dropout'],\n",
    "                                l_or_g_dropout=parameters_bi_lstm_cnn['l_or_g_dropout'],\n",
    "                                units_out=parameters_bi_lstm_cnn['units_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend_base_models = [(parameters_cnn,blend_base_cnn),(parameters_bi_lstm,blend_base_bi_lstm),(parameters_bi_lstm_cnn,blend_base_cnn_bi_lstm),(parameters_lstm_cnn,blend_base_cnn_lstm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend_trainX, blend_testX, blend_trainY, blend_testY = train_test_split(trainX, trainY, test_size=0.10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8196, 8196, 911, 911)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blend_trainX),len(blend_trainY),len(blend_testX),len(blend_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metalearner_trainX = np.zeros((len(blend_testX),len(blend_base_models)),dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/7\n",
      "8196/8196 [==============================] - 7s 801us/step - loss: 0.5680 - acc: 0.7110\n",
      "Epoch 2/7\n",
      "8196/8196 [==============================] - 5s 631us/step - loss: 0.5079 - acc: 0.7524\n",
      "Epoch 3/7\n",
      "8196/8196 [==============================] - 5s 612us/step - loss: 0.4845 - acc: 0.7693\n",
      "Epoch 4/7\n",
      "8196/8196 [==============================] - 6s 684us/step - loss: 0.4615 - acc: 0.7813\n",
      "Epoch 5/7\n",
      "8196/8196 [==============================] - 6s 696us/step - loss: 0.4557 - acc: 0.7875\n",
      "Epoch 6/7\n",
      "8196/8196 [==============================] - 6s 697us/step - loss: 0.4399 - acc: 0.7961\n",
      "Epoch 7/7\n",
      "8196/8196 [==============================] - 6s 699us/step - loss: 0.4306 - acc: 0.8020\n",
      "1\n",
      "Epoch 1/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.4992 - acc: 0.7594\n",
      "Epoch 2/9\n",
      "8196/8196 [==============================] - 45s 5ms/step - loss: 0.4308 - acc: 0.8020\n",
      "Epoch 3/9\n",
      "8196/8196 [==============================] - 44s 5ms/step - loss: 0.4073 - acc: 0.8160\n",
      "Epoch 4/9\n",
      "8196/8196 [==============================] - 44s 5ms/step - loss: 0.3829 - acc: 0.8303\n",
      "Epoch 5/9\n",
      "8196/8196 [==============================] - 49s 6ms/step - loss: 0.3712 - acc: 0.8351\n",
      "Epoch 6/9\n",
      "8196/8196 [==============================] - 44s 5ms/step - loss: 0.3547 - acc: 0.8452\n",
      "Epoch 7/9\n",
      "8196/8196 [==============================] - 46s 6ms/step - loss: 0.3361 - acc: 0.8506\n",
      "Epoch 8/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.3189 - acc: 0.8605\n",
      "Epoch 9/9\n",
      "8196/8196 [==============================] - 46s 6ms/step - loss: 0.3013 - acc: 0.8694\n",
      "2\n",
      "Epoch 1/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.4921 - acc: 0.7607\n",
      "Epoch 2/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.4169 - acc: 0.8094\n",
      "Epoch 3/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.3855 - acc: 0.8278\n",
      "Epoch 4/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.3569 - acc: 0.8424: 0s - loss: 0.3566 - acc:\n",
      "Epoch 5/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.3310 - acc: 0.8566\n",
      "Epoch 6/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.3088 - acc: 0.8672\n",
      "Epoch 7/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.2866 - acc: 0.8781\n",
      "Epoch 8/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.2634 - acc: 0.8910\n",
      "Epoch 9/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.2397 - acc: 0.9047\n",
      "Epoch 10/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.2201 - acc: 0.9124\n",
      "Epoch 11/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.2037 - acc: 0.9207\n",
      "Epoch 12/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.1958 - acc: 0.9243\n",
      "3\n",
      "Epoch 1/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.5221 - acc: 0.7440\n",
      "Epoch 2/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.4468 - acc: 0.7930\n",
      "Epoch 3/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.4097 - acc: 0.8172\n",
      "Epoch 4/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.3850 - acc: 0.8315\n",
      "Epoch 5/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.3561 - acc: 0.8466\n",
      "Epoch 6/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.3332 - acc: 0.8611\n",
      "Epoch 7/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.3142 - acc: 0.8703\n",
      "Epoch 8/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2899 - acc: 0.8840\n",
      "Epoch 9/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.2639 - acc: 0.8962\n",
      "Epoch 10/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2547 - acc: 0.8980\n",
      "Epoch 11/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2346 - acc: 0.9080\n",
      "Epoch 12/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2315 - acc: 0.9101\n",
      "Epoch 13/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2192 - acc: 0.9138\n",
      "Epoch 14/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2009 - acc: 0.9232\n",
      "Epoch 15/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.1978 - acc: 0.9252\n"
     ]
    }
   ],
   "source": [
    "for i,m in enumerate(blend_base_models):\n",
    "    print(i)\n",
    "    history = m[1].fit(blend_trainX,blend_trainY,epochs=m[0][\"epoch\"],batch_size=m[0][\"batch\"])\n",
    "    pred = m[1].predict(blend_testX)\n",
    "    metalearner_trainX[:,i] = [int(np.argmax(x)) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_meta_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_testY = np.array([int(np.argmax(x)) for x in blend_testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_meta_model.fit(metalearner_trainX, blend_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_class = np.zeros((len(testX),len(blend_base_models)),dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,p in enumerate(base_models):\n",
    "    test_pred_class[:,i] = get_pred_class(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_ensemble_pred_class = blend_meta_model.predict(test_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_ensemble_pred_class = list(blend_ensemble_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_ensemble_result = get_results(test_labels,blend_ensemble_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend_ensemble_result.insert(0,'blend_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance.loc[6] = blend_ensemble_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.637957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi_lstm</td>\n",
       "      <td>0.617651</td>\n",
       "      <td>0.654555</td>\n",
       "      <td>0.584686</td>\n",
       "      <td>0.662758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_bi_lstm</td>\n",
       "      <td>0.632167</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.607314</td>\n",
       "      <td>0.672058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.642971</td>\n",
       "      <td>0.669902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_ensemble</td>\n",
       "      <td>0.646064</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>0.682572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>majority_ensemble</td>\n",
       "      <td>0.653894</td>\n",
       "      <td>0.644953</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.682437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blend_ensemble</td>\n",
       "      <td>0.613343</td>\n",
       "      <td>0.677919</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.668149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model        f1  precision    recall  accuracy\n",
       "0                cnn  0.623187   0.587997  0.662857  0.637957\n",
       "1            bi_lstm  0.617651   0.654555  0.584686  0.662758\n",
       "2        cnn_bi_lstm  0.632167   0.659142  0.607314  0.672058\n",
       "3           cnn_lstm  0.637507   0.632135  0.642971  0.669902\n",
       "4       avg_ensemble  0.646064   0.659524  0.633143  0.682572\n",
       "5  majority_ensemble  0.653894   0.644953  0.663086  0.682437\n",
       "6     blend_ensemble  0.613343   0.677919  0.560000  0.668149"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super learner - stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = np.asarray([clean_sentence(s) for s in train_sentences])\n",
    "testX = np.asarray([clean_sentence(s) for s in test_sentences])\n",
    "trainY = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_metalearner_trainX = np.array([[0, 0, 0, 0]],dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_metalearner_trainY = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------itr = 1--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_62 (Embedding)     (None, 20, 400)           189600    \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_16 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 280,103\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 189,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_63 (Embedding)     (None, 20, 400)           189600    \n",
      "_________________________________________________________________\n",
      "bidirectional_31 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 732,067\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 189,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_64 (Embedding)     (None, 20, 400)           189600    \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_32 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 883,475\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 189,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_65 (Embedding)     (None, 20, 400)           189600    \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_48 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 856,739\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 189,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n",
      "Epoch 1/7\n",
      "88/88 [==============================] - 6s 69ms/step - loss: 0.6437 - acc: 0.6553\n",
      "Epoch 2/7\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.6365 - acc: 0.6629\n",
      "Epoch 3/7\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.6147 - acc: 0.6894\n",
      "Epoch 4/7\n",
      "88/88 [==============================] - 0s 969us/step - loss: 0.6126 - acc: 0.6629\n",
      "Epoch 5/7\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.6310 - acc: 0.6553\n",
      "Epoch 6/7\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.6019 - acc: 0.7121\n",
      "Epoch 7/7\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.6079 - acc: 0.6856\n",
      "1\n",
      "Epoch 1/9\n",
      "88/88 [==============================] - 7s 78ms/step - loss: 0.6351 - acc: 0.6667\n",
      "Epoch 2/9\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6115 - acc: 0.6705\n",
      "Epoch 3/9\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5992 - acc: 0.6856\n",
      "Epoch 4/9\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5846 - acc: 0.6970\n",
      "Epoch 5/9\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5708 - acc: 0.7008\n",
      "Epoch 6/9\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5324 - acc: 0.7386\n",
      "Epoch 7/9\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4604 - acc: 0.7538\n",
      "Epoch 8/9\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.4172 - acc: 0.8220\n",
      "Epoch 9/9\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.3437 - acc: 0.8485\n",
      "2\n",
      "Epoch 1/12\n",
      "88/88 [==============================] - 7s 80ms/step - loss: 0.6358 - acc: 0.6629\n",
      "Epoch 2/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.6003 - acc: 0.6818\n",
      "Epoch 3/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.5787 - acc: 0.7045\n",
      "Epoch 4/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.5353 - acc: 0.7273\n",
      "Epoch 5/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.4852 - acc: 0.7689\n",
      "Epoch 6/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.4100 - acc: 0.8144\n",
      "Epoch 7/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3131 - acc: 0.8902\n",
      "Epoch 8/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.2888 - acc: 0.8826\n",
      "Epoch 9/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.1795 - acc: 0.9659\n",
      "Epoch 10/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.1281 - acc: 0.9773\n",
      "Epoch 11/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.0975 - acc: 0.9773\n",
      "Epoch 12/12\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.0611 - acc: 0.9886\n",
      "3\n",
      "Epoch 1/15\n",
      "88/88 [==============================] - 7s 79ms/step - loss: 0.6373 - acc: 0.6515\n",
      "Epoch 2/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6194 - acc: 0.6742\n",
      "Epoch 3/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5998 - acc: 0.6970\n",
      "Epoch 4/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5909 - acc: 0.7008\n",
      "Epoch 5/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5657 - acc: 0.7083\n",
      "Epoch 6/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5288 - acc: 0.7311\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5104 - acc: 0.7576\n",
      "Epoch 8/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4154 - acc: 0.8295\n",
      "Epoch 9/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3159 - acc: 0.8750\n",
      "Epoch 10/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.2459 - acc: 0.9242\n",
      "Epoch 11/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.1928 - acc: 0.9470\n",
      "Epoch 12/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.1478 - acc: 0.9470\n",
      "Epoch 13/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.1805 - acc: 0.9508\n",
      "Epoch 14/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.0945 - acc: 0.9735\n",
      "Epoch 15/15\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.1814 - acc: 0.9205\n",
      "----------------------itr = 2--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_66 (Embedding)     (None, 20, 400)           190400    \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_17 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 280,903\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 190,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_67 (Embedding)     (None, 20, 400)           190400    \n",
      "_________________________________________________________________\n",
      "bidirectional_33 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 732,867\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 190,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_68 (Embedding)     (None, 20, 400)           190400    \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_34 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 884,275\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 190,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_69 (Embedding)     (None, 20, 400)           190400    \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 857,539\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 190,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n",
      "Epoch 1/7\n",
      "89/89 [==============================] - 6s 71ms/step - loss: 0.6524 - acc: 0.6517\n",
      "Epoch 2/7\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6210 - acc: 0.6742\n",
      "Epoch 3/7\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6189 - acc: 0.6704\n",
      "Epoch 4/7\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6211 - acc: 0.6816\n",
      "Epoch 5/7\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6190 - acc: 0.6704\n",
      "Epoch 6/7\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6341 - acc: 0.6442\n",
      "Epoch 7/7\n",
      "89/89 [==============================] - 0s 994us/step - loss: 0.6186 - acc: 0.6704\n",
      "1\n",
      "Epoch 1/9\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.6331 - acc: 0.6667\n",
      "Epoch 2/9\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.6241 - acc: 0.6442\n",
      "Epoch 3/9\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.6040 - acc: 0.6779\n",
      "Epoch 4/9\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.5986 - acc: 0.6742\n",
      "Epoch 5/9\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.5688 - acc: 0.7191\n",
      "Epoch 6/9\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.5413 - acc: 0.7191\n",
      "Epoch 7/9\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.4714 - acc: 0.7753\n",
      "Epoch 8/9\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.3817 - acc: 0.8202\n",
      "Epoch 9/9\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.5160 - acc: 0.7566\n",
      "2\n",
      "Epoch 1/12\n",
      "89/89 [==============================] - 8s 84ms/step - loss: 0.6230 - acc: 0.6779\n",
      "Epoch 2/12\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5985 - acc: 0.6816\n",
      "Epoch 3/12\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5570 - acc: 0.7004\n",
      "Epoch 4/12\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5087 - acc: 0.7566\n",
      "Epoch 5/12\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.4396 - acc: 0.7903\n",
      "Epoch 6/12\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.4696 - acc: 0.7753\n",
      "Epoch 7/12\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.3718 - acc: 0.8652\n",
      "Epoch 8/12\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.2826 - acc: 0.9251\n",
      "Epoch 9/12\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.2285 - acc: 0.9213\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1634 - acc: 0.9738\n",
      "Epoch 11/12\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1324 - acc: 0.9775\n",
      "Epoch 12/12\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.0973 - acc: 0.9813\n",
      "3\n",
      "Epoch 1/15\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.6422 - acc: 0.6667\n",
      "Epoch 2/15\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.6211 - acc: 0.670 - 0s 6ms/step - loss: 0.6213 - acc: 0.6704\n",
      "Epoch 3/15\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.6145 - acc: 0.6779\n",
      "Epoch 4/15\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.6130 - acc: 0.6816\n",
      "Epoch 5/15\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.5994 - acc: 0.6854\n",
      "Epoch 6/15\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.5875 - acc: 0.7004\n",
      "Epoch 7/15\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.5728 - acc: 0.7116\n",
      "Epoch 8/15\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.5404 - acc: 0.7416A: 0s - loss: 0.5386 - acc: 0\n",
      "Epoch 9/15\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.5014 - acc: 0.7640\n",
      "Epoch 10/15\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.4432 - acc: 0.8052\n",
      "Epoch 11/15\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 0.3654 - acc: 0.8614\n",
      "Epoch 12/15\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 0.2949 - acc: 0.8914\n",
      "Epoch 13/15\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.2169 - acc: 0.9401\n",
      "Epoch 14/15\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.2429 - acc: 0.9251\n",
      "Epoch 15/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.2541 - acc: 0.8989\n",
      "----------------------itr = 3--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_70 (Embedding)     (None, 20, 400)           187200    \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_18 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 277,703\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 187,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_71 (Embedding)     (None, 20, 400)           187200    \n",
      "_________________________________________________________________\n",
      "bidirectional_35 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 729,667\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 187,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_72 (Embedding)     (None, 20, 400)           187200    \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_36 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 881,075\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 187,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_73 (Embedding)     (None, 20, 400)           187200    \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 854,339\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 187,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n",
      "Epoch 1/7\n",
      "89/89 [==============================] - 7s 77ms/step - loss: 0.6452 - acc: 0.6704\n",
      "Epoch 2/7\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6344 - acc: 0.6554\n",
      "Epoch 3/7\n",
      "89/89 [==============================] - 0s 931us/step - loss: 0.6116 - acc: 0.6704\n",
      "Epoch 4/7\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6508 - acc: 0.6292\n",
      "Epoch 5/7\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6084 - acc: 0.6742\n",
      "Epoch 6/7\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.5912 - acc: 0.6891\n",
      "Epoch 7/7\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.5991 - acc: 0.6704\n",
      "1\n",
      "Epoch 1/9\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.6340 - acc: 0.6667\n",
      "Epoch 2/9\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.6109 - acc: 0.6742\n",
      "Epoch 3/9\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.6106 - acc: 0.6554\n",
      "Epoch 4/9\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 0.5921 - acc: 0.6966\n",
      "Epoch 5/9\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.5730 - acc: 0.7041\n",
      "Epoch 6/9\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.5070 - acc: 0.7453\n",
      "Epoch 7/9\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.6098 - acc: 0.7116\n",
      "Epoch 8/9\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.5981 - acc: 0.7079\n",
      "Epoch 9/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 1s 7ms/step - loss: 0.4669 - acc: 0.7528\n",
      "2\n",
      "Epoch 1/12\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.6431 - acc: 0.6629\n",
      "Epoch 2/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.5987 - acc: 0.6742\n",
      "Epoch 3/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.5702 - acc: 0.7154\n",
      "Epoch 4/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.5356 - acc: 0.7303\n",
      "Epoch 5/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.4682 - acc: 0.7865\n",
      "Epoch 6/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.3734 - acc: 0.8464\n",
      "Epoch 7/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.3045 - acc: 0.8839\n",
      "Epoch 8/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.2920 - acc: 0.8727\n",
      "Epoch 9/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.2784 - acc: 0.8876\n",
      "Epoch 10/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.1774 - acc: 0.9438\n",
      "Epoch 11/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.1335 - acc: 0.9700\n",
      "Epoch 12/12\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0775 - acc: 0.9925\n",
      "3\n",
      "Epoch 1/15\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.6340 - acc: 0.6667\n",
      "Epoch 2/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6090 - acc: 0.6742\n",
      "Epoch 3/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5962 - acc: 0.6891\n",
      "Epoch 4/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5958 - acc: 0.6779\n",
      "Epoch 5/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5708 - acc: 0.7004\n",
      "Epoch 6/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5203 - acc: 0.7640\n",
      "Epoch 7/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.4594 - acc: 0.7903\n",
      "Epoch 8/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.4014 - acc: 0.8052\n",
      "Epoch 9/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.3537 - acc: 0.8464\n",
      "Epoch 10/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.3065 - acc: 0.8951\n",
      "Epoch 11/15\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.2188 - acc: 0.9513\n",
      "Epoch 12/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1997 - acc: 0.9438\n",
      "Epoch 13/15\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.1726 - acc: 0.9251\n",
      "Epoch 14/15\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.1557 - acc: 0.9625\n",
      "Epoch 15/15\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1637 - acc: 0.9513\n",
      "----------------------itr = 4--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_74 (Embedding)     (None, 20, 400)           192000    \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_19 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 282,503\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 192,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_75 (Embedding)     (None, 20, 400)           192000    \n",
      "_________________________________________________________________\n",
      "bidirectional_37 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 734,467\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 192,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_76 (Embedding)     (None, 20, 400)           192000    \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_38 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 885,875\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 192,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_77 (Embedding)     (None, 20, 400)           192000    \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 859,139\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 192,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n",
      "Epoch 1/7\n",
      "90/90 [==============================] - 7s 83ms/step - loss: 0.6368 - acc: 0.6630\n",
      "Epoch 2/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6236 - acc: 0.6815\n",
      "Epoch 3/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6322 - acc: 0.6444\n",
      "Epoch 4/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6264 - acc: 0.6741\n",
      "Epoch 5/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6401 - acc: 0.6481\n",
      "Epoch 6/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6182 - acc: 0.6815\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6290 - acc: 0.6667\n",
      "1\n",
      "Epoch 1/9\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.6250 - acc: 0.6667\n",
      "Epoch 2/9\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6082 - acc: 0.6778\n",
      "Epoch 3/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6035 - acc: 0.6926\n",
      "Epoch 4/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5778 - acc: 0.7259\n",
      "Epoch 5/9\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5252 - acc: 0.7333\n",
      "Epoch 6/9\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4865 - acc: 0.7667\n",
      "Epoch 7/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4015 - acc: 0.8222\n",
      "Epoch 8/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.3522 - acc: 0.8222\n",
      "Epoch 9/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4087 - acc: 0.8074\n",
      "2\n",
      "Epoch 1/12\n",
      "90/90 [==============================] - 9s 95ms/step - loss: 0.6424 - acc: 0.6481\n",
      "Epoch 2/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6017 - acc: 0.6778\n",
      "Epoch 3/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5749 - acc: 0.7148\n",
      "Epoch 4/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5364 - acc: 0.7519\n",
      "Epoch 5/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4843 - acc: 0.7778\n",
      "Epoch 6/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4111 - acc: 0.8259\n",
      "Epoch 7/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3333 - acc: 0.8889\n",
      "Epoch 8/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2488 - acc: 0.9296\n",
      "Epoch 9/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1924 - acc: 0.9370\n",
      "Epoch 10/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1571 - acc: 0.9519\n",
      "Epoch 11/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1268 - acc: 0.9704\n",
      "Epoch 12/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.0832 - acc: 0.9852\n",
      "3\n",
      "Epoch 1/15\n",
      "90/90 [==============================] - 8s 91ms/step - loss: 0.6347 - acc: 0.6630\n",
      "Epoch 2/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6123 - acc: 0.6852\n",
      "Epoch 3/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6030 - acc: 0.6926\n",
      "Epoch 4/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5967 - acc: 0.7037\n",
      "Epoch 5/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5845 - acc: 0.7074\n",
      "Epoch 6/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5549 - acc: 0.7333\n",
      "Epoch 7/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5098 - acc: 0.7481\n",
      "Epoch 8/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4616 - acc: 0.7704\n",
      "Epoch 9/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3973 - acc: 0.8111\n",
      "Epoch 10/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3331 - acc: 0.8556\n",
      "Epoch 11/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3068 - acc: 0.8815\n",
      "Epoch 12/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2492 - acc: 0.9148\n",
      "Epoch 13/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1989 - acc: 0.9259\n",
      "Epoch 14/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2593 - acc: 0.9000\n",
      "Epoch 15/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1841 - acc: 0.9296\n",
      "----------------------itr = 5--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_78 (Embedding)     (None, 20, 400)           195200    \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_20 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 285,703\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 195,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_79 (Embedding)     (None, 20, 400)           195200    \n",
      "_________________________________________________________________\n",
      "bidirectional_39 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 737,667\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 195,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_80 (Embedding)     (None, 20, 400)           195200    \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_40 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 889,075\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 195,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_81 (Embedding)     (None, 20, 400)           195200    \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 862,339\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 195,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "90/90 [==============================] - 9s 96ms/step - loss: 0.6383 - acc: 0.6407\n",
      "Epoch 2/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6436 - acc: 0.6481\n",
      "Epoch 3/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6157 - acc: 0.6556\n",
      "Epoch 4/7\n",
      "90/90 [==============================] - 0s 985us/step - loss: 0.6243 - acc: 0.6556\n",
      "Epoch 5/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6371 - acc: 0.6481\n",
      "Epoch 6/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6320 - acc: 0.6704\n",
      "Epoch 7/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6339 - acc: 0.6593\n",
      "1\n",
      "Epoch 1/9\n",
      "90/90 [==============================] - 9s 99ms/step - loss: 0.6358 - acc: 0.6667\n",
      "Epoch 2/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6056 - acc: 0.6778\n",
      "Epoch 3/9\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5981 - acc: 0.6926\n",
      "Epoch 4/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5775 - acc: 0.7259\n",
      "Epoch 5/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5510 - acc: 0.7148\n",
      "Epoch 6/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4629 - acc: 0.7704\n",
      "Epoch 7/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.3775 - acc: 0.8037\n",
      "Epoch 8/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.3525 - acc: 0.8148\n",
      "Epoch 9/9\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4500 - acc: 0.7556\n",
      "2\n",
      "Epoch 1/12\n",
      "90/90 [==============================] - 9s 98ms/step - loss: 0.6436 - acc: 0.6556\n",
      "Epoch 2/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5955 - acc: 0.7037\n",
      "Epoch 3/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5661 - acc: 0.7222\n",
      "Epoch 4/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5284 - acc: 0.7444\n",
      "Epoch 5/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4663 - acc: 0.7667\n",
      "Epoch 6/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3901 - acc: 0.8296\n",
      "Epoch 7/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3089 - acc: 0.8778\n",
      "Epoch 8/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3105 - acc: 0.9000\n",
      "Epoch 9/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2186 - acc: 0.9444\n",
      "Epoch 10/12\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.2087 - acc: 0.9296\n",
      "Epoch 11/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1339 - acc: 0.9741\n",
      "Epoch 12/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1297 - acc: 0.9630\n",
      "3\n",
      "Epoch 1/15\n",
      "90/90 [==============================] - 9s 96ms/step - loss: 0.6206 - acc: 0.6778\n",
      "Epoch 2/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6181 - acc: 0.6704\n",
      "Epoch 3/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5940 - acc: 0.7222\n",
      "Epoch 4/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5666 - acc: 0.7259\n",
      "Epoch 5/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5143 - acc: 0.7481\n",
      "Epoch 6/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4582 - acc: 0.7704\n",
      "Epoch 7/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3661 - acc: 0.8519\n",
      "Epoch 8/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4516 - acc: 0.7630\n",
      "Epoch 9/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3714 - acc: 0.8111\n",
      "Epoch 10/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3418 - acc: 0.8222\n",
      "Epoch 11/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2819 - acc: 0.8815\n",
      "Epoch 12/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2430 - acc: 0.9148\n",
      "Epoch 13/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2120 - acc: 0.9259\n",
      "Epoch 14/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1788 - acc: 0.9481\n",
      "Epoch 15/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2010 - acc: 0.9333\n",
      "----------------------itr = 6--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_82 (Embedding)     (None, 20, 400)           196800    \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_21 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 287,303\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 196,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_83 (Embedding)     (None, 20, 400)           196800    \n",
      "_________________________________________________________________\n",
      "bidirectional_41 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 739,267\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 196,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_84 (Embedding)     (None, 20, 400)           196800    \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_42 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 890,675\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 196,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_85 (Embedding)     (None, 20, 400)           196800    \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 863,939\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 196,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "90/90 [==============================] - 8s 93ms/step - loss: 0.6331 - acc: 0.6556\n",
      "Epoch 2/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6379 - acc: 0.6593\n",
      "Epoch 3/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6275 - acc: 0.6593\n",
      "Epoch 4/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6172 - acc: 0.6741\n",
      "Epoch 5/7\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6152 - acc: 0.6741\n",
      "Epoch 6/7\n",
      "90/90 [==============================] - 0s 990us/step - loss: 0.6222 - acc: 0.6630\n",
      "Epoch 7/7\n",
      "90/90 [==============================] - 0s 966us/step - loss: 0.6024 - acc: 0.6815\n",
      "1\n",
      "Epoch 1/9\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 0.6304 - acc: 0.6667\n",
      "Epoch 2/9\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6198 - acc: 0.6667\n",
      "Epoch 3/9\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5986 - acc: 0.6926\n",
      "Epoch 4/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5915 - acc: 0.6778\n",
      "Epoch 5/9\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5617 - acc: 0.7148\n",
      "Epoch 6/9\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5179 - acc: 0.7407\n",
      "Epoch 7/9\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4230 - acc: 0.7926\n",
      "Epoch 8/9\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.3486 - acc: 0.8259\n",
      "Epoch 9/9\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.3223 - acc: 0.8444\n",
      "2\n",
      "Epoch 1/12\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.6257 - acc: 0.6704\n",
      "Epoch 2/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5903 - acc: 0.7000\n",
      "Epoch 3/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5669 - acc: 0.7037\n",
      "Epoch 4/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5118 - acc: 0.7667\n",
      "Epoch 5/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4551 - acc: 0.7852\n",
      "Epoch 6/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3593 - acc: 0.8519\n",
      "Epoch 7/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2918 - acc: 0.8963\n",
      "Epoch 8/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2205 - acc: 0.9111\n",
      "Epoch 9/12\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.1740 - acc: 0.9519\n",
      "Epoch 10/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1288 - acc: 0.9741\n",
      "Epoch 11/12\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.0835 - acc: 0.9815\n",
      "Epoch 12/12\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.0577 - acc: 1.0000\n",
      "3\n",
      "Epoch 1/15\n",
      "90/90 [==============================] - 9s 103ms/step - loss: 0.6335 - acc: 0.6667\n",
      "Epoch 2/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6172 - acc: 0.6852\n",
      "Epoch 3/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6012 - acc: 0.6889\n",
      "Epoch 4/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5855 - acc: 0.7111\n",
      "Epoch 5/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5523 - acc: 0.7259\n",
      "Epoch 6/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.5204 - acc: 0.7259\n",
      "Epoch 7/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4600 - acc: 0.7667\n",
      "Epoch 8/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4082 - acc: 0.8185\n",
      "Epoch 9/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3645 - acc: 0.8444\n",
      "Epoch 10/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3248 - acc: 0.8667\n",
      "Epoch 11/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2391 - acc: 0.9296\n",
      "Epoch 12/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2029 - acc: 0.9259\n",
      "Epoch 13/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1903 - acc: 0.9481\n",
      "Epoch 14/15\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1449 - acc: 0.9481\n",
      "Epoch 15/15\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1570 - acc: 0.9481\n",
      "----------------------itr = 7--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_86 (Embedding)     (None, 20, 400)           190400    \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_22 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 280,903\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 190,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_87 (Embedding)     (None, 20, 400)           190400    \n",
      "_________________________________________________________________\n",
      "bidirectional_43 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 732,867\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 190,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_88 (Embedding)     (None, 20, 400)           190400    \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_44 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 884,275\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 190,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_89 (Embedding)     (None, 20, 400)           190400    \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_153 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_66 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_154 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 857,539\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 190,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "91/91 [==============================] - 11s 119ms/step - loss: 0.6128 - acc: 0.6703\n",
      "Epoch 2/7\n",
      "91/91 [==============================] - 0s 897us/step - loss: 0.6306 - acc: 0.6557\n",
      "Epoch 3/7\n",
      "91/91 [==============================] - 0s 774us/step - loss: 0.5971 - acc: 0.6777\n",
      "Epoch 4/7\n",
      "91/91 [==============================] - 0s 895us/step - loss: 0.6039 - acc: 0.6850\n",
      "Epoch 5/7\n",
      "91/91 [==============================] - 0s 916us/step - loss: 0.6209 - acc: 0.6740\n",
      "Epoch 6/7\n",
      "91/91 [==============================] - 0s 775us/step - loss: 0.6230 - acc: 0.6667\n",
      "Epoch 7/7\n",
      "91/91 [==============================] - 0s 755us/step - loss: 0.6173 - acc: 0.6777\n",
      "1\n",
      "Epoch 1/9\n",
      "91/91 [==============================] - 13s 138ms/step - loss: 0.6279 - acc: 0.6667\n",
      "Epoch 2/9\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 0.6051 - acc: 0.6923\n",
      "Epoch 3/9\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 0.6037 - acc: 0.6886\n",
      "Epoch 4/9\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.5911 - acc: 0.6960\n",
      "Epoch 5/9\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.5507 - acc: 0.7289\n",
      "Epoch 6/9\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.5323 - acc: 0.7289\n",
      "Epoch 7/9\n",
      "91/91 [==============================] - 1s 9ms/step - loss: 0.5388 - acc: 0.7253\n",
      "Epoch 8/9\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.4271 - acc: 0.7839\n",
      "Epoch 9/9\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 0.3274 - acc: 0.8352\n",
      "2\n",
      "Epoch 1/12\n",
      "91/91 [==============================] - 12s 131ms/step - loss: 0.6137 - acc: 0.6740\n",
      "Epoch 2/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.5839 - acc: 0.6923\n",
      "Epoch 3/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.5497 - acc: 0.7289\n",
      "Epoch 4/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.4809 - acc: 0.7839\n",
      "Epoch 5/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.4045 - acc: 0.8498\n",
      "Epoch 6/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.2943 - acc: 0.9084\n",
      "Epoch 7/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.2225 - acc: 0.9267\n",
      "Epoch 8/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.2240 - acc: 0.9194\n",
      "Epoch 9/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.2178 - acc: 0.9451\n",
      "Epoch 10/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.1260 - acc: 0.9634\n",
      "Epoch 11/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0951 - acc: 0.9817\n",
      "Epoch 12/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0716 - acc: 0.9890\n",
      "3\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 12s 133ms/step - loss: 0.6260 - acc: 0.6593\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.6077 - acc: 0.6850\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5922 - acc: 0.7106\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5604 - acc: 0.7179\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5101 - acc: 0.7399\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.4672 - acc: 0.7729\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.4140 - acc: 0.8022\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.3489 - acc: 0.8828\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.2507 - acc: 0.9121\n",
      "Epoch 10/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.2320 - acc: 0.9304\n",
      "Epoch 11/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.2553 - acc: 0.8791\n",
      "Epoch 12/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.2170 - acc: 0.9267\n",
      "Epoch 13/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.2059 - acc: 0.9341\n",
      "Epoch 14/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.0930 - acc: 0.9963\n",
      "Epoch 15/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0745 - acc: 0.9890\n",
      "----------------------itr = 8--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_90 (Embedding)     (None, 20, 400)           192800    \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_23 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 283,303\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 192,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_91 (Embedding)     (None, 20, 400)           192800    \n",
      "_________________________________________________________________\n",
      "bidirectional_45 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 735,267\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 192,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_92 (Embedding)     (None, 20, 400)           192800    \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_46 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 886,675\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 192,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_93 (Embedding)     (None, 20, 400)           192800    \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_69 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 859,939\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 192,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "91/91 [==============================] - 11s 124ms/step - loss: 0.6528 - acc: 0.6557\n",
      "Epoch 2/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6156 - acc: 0.6777\n",
      "Epoch 3/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6243 - acc: 0.6484\n",
      "Epoch 4/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6140 - acc: 0.6557\n",
      "Epoch 5/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6048 - acc: 0.6923\n",
      "Epoch 6/7\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.6175 - acc: 0.6740\n",
      "Epoch 7/7\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 0.6085 - acc: 0.6667\n",
      "1\n",
      "Epoch 1/9\n",
      "91/91 [==============================] - 12s 130ms/step - loss: 0.6330 - acc: 0.6667\n",
      "Epoch 2/9\n",
      "91/91 [==============================] - 1s 9ms/step - loss: 0.6116 - acc: 0.6740\n",
      "Epoch 3/9\n",
      "91/91 [==============================] - 1s 13ms/step - loss: 0.6038 - acc: 0.6777\n",
      "Epoch 4/9\n",
      "91/91 [==============================] - 1s 12ms/step - loss: 0.5963 - acc: 0.6777\n",
      "Epoch 5/9\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.5610 - acc: 0.7106\n",
      "Epoch 6/9\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.5135 - acc: 0.7253\n",
      "Epoch 7/9\n",
      "91/91 [==============================] - 1s 10ms/step - loss: 0.4525 - acc: 0.7656\n",
      "Epoch 8/9\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.4032 - acc: 0.7912\n",
      "Epoch 9/9\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.3530 - acc: 0.8059\n",
      "2\n",
      "Epoch 1/12\n",
      "91/91 [==============================] - 13s 145ms/step - loss: 0.6371 - acc: 0.6630\n",
      "Epoch 2/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.6029 - acc: 0.6813\n",
      "Epoch 3/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5763 - acc: 0.7216\n",
      "Epoch 4/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5363 - acc: 0.7179\n",
      "Epoch 5/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.4890 - acc: 0.7619\n",
      "Epoch 6/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.4285 - acc: 0.7985\n",
      "Epoch 7/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.3560 - acc: 0.8681\n",
      "Epoch 8/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.2733 - acc: 0.9121\n",
      "Epoch 9/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.1929 - acc: 0.9451\n",
      "Epoch 10/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.1692 - acc: 0.9487\n",
      "Epoch 11/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.1137 - acc: 0.9744\n",
      "Epoch 12/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.0822 - acc: 0.9817\n",
      "3\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 11s 121ms/step - loss: 0.6286 - acc: 0.6740\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 0.6083 - acc: 0.6886\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 0.5959 - acc: 0.7033\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 0.5684 - acc: 0.7106\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5393 - acc: 0.7253\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 0.4800 - acc: 0.7619\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.4463 - acc: 0.8168\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.3767 - acc: 0.8535\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.3045 - acc: 0.8974\n",
      "Epoch 10/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.2517 - acc: 0.9084\n",
      "Epoch 11/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.1956 - acc: 0.9341\n",
      "Epoch 12/15\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 0.1730 - acc: 0.9341\n",
      "Epoch 13/15\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 0.1332 - acc: 0.9597\n",
      "Epoch 14/15\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 0.0921 - acc: 0.9817\n",
      "Epoch 15/15\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 0.0516 - acc: 0.9927\n",
      "----------------------itr = 9--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_94 (Embedding)     (None, 20, 400)           191600    \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_24 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 282,103\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 191,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_95 (Embedding)     (None, 20, 400)           191600    \n",
      "_________________________________________________________________\n",
      "bidirectional_47 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_164 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 734,067\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 191,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_96 (Embedding)     (None, 20, 400)           191600    \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_165 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_48 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_166 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 885,475\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 191,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_97 (Embedding)     (None, 20, 400)           191600    \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_72 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 858,739\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 191,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "91/91 [==============================] - 11s 123ms/step - loss: 0.6533 - acc: 0.6593\n",
      "Epoch 2/7\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.6305 - acc: 0.6667\n",
      "Epoch 3/7\n",
      "91/91 [==============================] - 0s 741us/step - loss: 0.6249 - acc: 0.6557\n",
      "Epoch 4/7\n",
      "91/91 [==============================] - 0s 744us/step - loss: 0.6190 - acc: 0.6520\n",
      "Epoch 5/7\n",
      "91/91 [==============================] - 0s 762us/step - loss: 0.6280 - acc: 0.6447\n",
      "Epoch 6/7\n",
      "91/91 [==============================] - 0s 796us/step - loss: 0.6243 - acc: 0.6667\n",
      "Epoch 7/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6140 - acc: 0.6923\n",
      "1\n",
      "Epoch 1/9\n",
      "91/91 [==============================] - 14s 159ms/step - loss: 0.6337 - acc: 0.6667\n",
      "Epoch 2/9\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.6127 - acc: 0.6667\n",
      "Epoch 3/9\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.6001 - acc: 0.6777\n",
      "Epoch 4/9\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.5819 - acc: 0.6923\n",
      "Epoch 5/9\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.5129 - acc: 0.7363\n",
      "Epoch 6/9\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.4205 - acc: 0.7985\n",
      "Epoch 7/9\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.3571 - acc: 0.8278\n",
      "Epoch 8/9\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.3930 - acc: 0.8132\n",
      "Epoch 9/9\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.3229 - acc: 0.8755\n",
      "2\n",
      "Epoch 1/12\n",
      "91/91 [==============================] - 12s 136ms/step - loss: 0.6357 - acc: 0.6593\n",
      "Epoch 2/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5822 - acc: 0.7070\n",
      "Epoch 3/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5576 - acc: 0.7216\n",
      "Epoch 4/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5059 - acc: 0.7509\n",
      "Epoch 5/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.4109 - acc: 0.8132\n",
      "Epoch 6/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.3342 - acc: 0.8645\n",
      "Epoch 7/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.2486 - acc: 0.9084\n",
      "Epoch 8/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.1782 - acc: 0.9597\n",
      "Epoch 9/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.1445 - acc: 0.9634\n",
      "Epoch 10/12\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.1083 - acc: 0.9817\n",
      "Epoch 11/12\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.0636 - acc: 0.9853\n",
      "Epoch 12/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0608 - acc: 0.9890\n",
      "3\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 12s 136ms/step - loss: 0.6329 - acc: 0.6667\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.6100 - acc: 0.6923\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.6015 - acc: 0.6886\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5757 - acc: 0.7143\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.5263 - acc: 0.7399\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.4786 - acc: 0.7875\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.4116 - acc: 0.8425\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.3450 - acc: 0.8681\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.2882 - acc: 0.9084\n",
      "Epoch 10/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.1857 - acc: 0.9634\n",
      "Epoch 11/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.1461 - acc: 0.9707\n",
      "Epoch 12/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.4392 - acc: 0.7985\n",
      "Epoch 13/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.1820 - acc: 0.9560\n",
      "Epoch 14/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.1065 - acc: 0.9853\n",
      "Epoch 15/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.0576 - acc: 0.9963\n",
      "----------------------itr = 10--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_98 (Embedding)     (None, 20, 400)           187200    \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_25 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 277,703\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 187,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_99 (Embedding)     (None, 20, 400)           187200    \n",
      "_________________________________________________________________\n",
      "bidirectional_49 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_171 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 729,667\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 187,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_100 (Embedding)    (None, 20, 400)           187200    \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_172 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_50 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 881,075\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 187,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_101 (Embedding)    (None, 20, 400)           187200    \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_75 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 854,339\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 187,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "91/91 [==============================] - 13s 139ms/step - loss: 0.6483 - acc: 0.6557\n",
      "Epoch 2/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6418 - acc: 0.6667\n",
      "Epoch 3/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6246 - acc: 0.6813\n",
      "Epoch 4/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6105 - acc: 0.6630\n",
      "Epoch 5/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6301 - acc: 0.6374\n",
      "Epoch 6/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6189 - acc: 0.6630\n",
      "Epoch 7/7\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.6120 - acc: 0.6630\n",
      "1\n",
      "Epoch 1/9\n",
      "91/91 [==============================] - 13s 148ms/step - loss: 0.6330 - acc: 0.6667\n",
      "Epoch 2/9\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.6063 - acc: 0.6886\n",
      "Epoch 3/9\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.6049 - acc: 0.6703\n",
      "Epoch 4/9\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.5854 - acc: 0.7143\n",
      "Epoch 5/9\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 0.5548 - acc: 0.7253\n",
      "Epoch 6/9\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 0.5289 - acc: 0.7289\n",
      "Epoch 7/9\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 0.4720 - acc: 0.7619\n",
      "Epoch 8/9\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.4368 - acc: 0.7766\n",
      "Epoch 9/9\n",
      "91/91 [==============================] - 1s 8ms/step - loss: 0.4407 - acc: 0.7985\n",
      "2\n",
      "Epoch 1/12\n",
      "91/91 [==============================] - 14s 151ms/step - loss: 0.6386 - acc: 0.6520\n",
      "Epoch 2/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.5976 - acc: 0.7070\n",
      "Epoch 3/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.5713 - acc: 0.7216\n",
      "Epoch 4/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.5207 - acc: 0.7399\n",
      "Epoch 5/12\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.4638 - acc: 0.7802\n",
      "Epoch 6/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.3925 - acc: 0.8095\n",
      "Epoch 7/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.2880 - acc: 0.9084\n",
      "Epoch 8/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.2192 - acc: 0.9048\n",
      "Epoch 9/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.1663 - acc: 0.9487\n",
      "Epoch 10/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.1640 - acc: 0.9634\n",
      "Epoch 11/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.1306 - acc: 0.9597\n",
      "Epoch 12/12\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.1394 - acc: 0.9560\n",
      "3\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 14s 149ms/step - loss: 0.6305 - acc: 0.6630\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.6156 - acc: 0.6703\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.6033 - acc: 0.7033\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.5837 - acc: 0.6923\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.5501 - acc: 0.7106\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.5121 - acc: 0.7473\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.4135 - acc: 0.8168\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 0.3355 - acc: 0.8791\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 1s 7ms/step - loss: 0.3047 - acc: 0.8571\n",
      "Epoch 10/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.2731 - acc: 0.8828\n",
      "Epoch 11/15\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.2101 - acc: 0.9414\n",
      "Epoch 12/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.1660 - acc: 0.9487\n",
      "Epoch 13/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.1195 - acc: 0.9634\n",
      "Epoch 14/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.0744 - acc: 0.9927\n",
      "Epoch 15/15\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 0.0895 - acc: 0.9817\n"
     ]
    }
   ],
   "source": [
    "for train,test in kfold.split(trainX[:100],trainY[:100]):\n",
    "    print(\"----------------------itr = {}--------------\".format(count))\n",
    "    stacked_trainX = list(trainX[train])\n",
    "    stacked_trainY = list(trainY[train])\n",
    "    stacked_testX = list(trainX[test])\n",
    "    stacked_testY = list(trainY[test])\n",
    "    \n",
    "    tokenizer = create_tokenizer(stacked_trainX)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    stacked_trainX = encode_text(tokenizer, stacked_trainX, max_len)\n",
    "    stacked_testX = encode_text(tokenizer, stacked_testX, max_len)\n",
    "    stacked_trainY = to_categorical(stacked_trainY,num_classes=number_of_classes)\n",
    "    \n",
    "    embedding_matrix_godin = get_word_embedding_matrix(godin_model,400)\n",
    "    \n",
    "    for i in stacked_testY:\n",
    "        stacked_metalearner_trainY.append(i)\n",
    "    \n",
    "    \n",
    "    base_cnn = cnn(length=max_len,\n",
    "                vocab_size=vocab_size,\n",
    "                n_dense=parameters_cnn['n_dense'],\n",
    "                dropout=parameters_cnn['dropout'],\n",
    "                n_filters=parameters_cnn['n_filters'],\n",
    "                filter_size=int(parameters_cnn['filter_size']),\n",
    "                em = eval(parameters_cnn['em']),\n",
    "                number_of_classes=number_of_classes)\n",
    "\n",
    "    base_bi_lstm = bi_lstm(length=max_len,\n",
    "                            vocab_size=vocab_size,\n",
    "                            dropout=parameters_bi_lstm['dropout'],\n",
    "                            units_out=parameters_bi_lstm['units_out'],\n",
    "                            em=eval(parameters_bi_lstm['em']),\n",
    "                            number_of_classes=number_of_classes)\n",
    "\n",
    "\n",
    "    base_cnn_bi_lstm = cnn_bi_lstm(length=max_len,\n",
    "                                    vocab_size=vocab_size,\n",
    "                                    n_filters=parameters_bi_lstm_cnn['n_filters'],\n",
    "                                    filter_size=parameters_bi_lstm_cnn['filter_size'],\n",
    "                                    em=eval(parameters_bi_lstm_cnn['em']),\n",
    "                                    number_of_classes=number_of_classes,\n",
    "                                    conv_dropout=parameters_bi_lstm_cnn['conv_dropout'],\n",
    "                                    l_or_g_dropout=parameters_bi_lstm_cnn['l_or_g_dropout'],\n",
    "                                    units_out=parameters_bi_lstm_cnn['units_out'])\n",
    "\n",
    "\n",
    "    base_cnn_lstm = cnn_lstm(length=max_len,\n",
    "                                    vocab_size=vocab_size,\n",
    "                                    n_filters=parameters_bi_lstm_cnn['n_filters'],\n",
    "                                    filter_size=parameters_bi_lstm_cnn['filter_size'],\n",
    "                                    em=eval(parameters_bi_lstm_cnn['em']),\n",
    "                                    number_of_classes=number_of_classes,\n",
    "                                    conv_dropout=parameters_bi_lstm_cnn['conv_dropout'],\n",
    "                                    l_or_g_dropout=parameters_bi_lstm_cnn['l_or_g_dropout'],\n",
    "                                    units_out=parameters_bi_lstm_cnn['units_out'])\n",
    "    \n",
    "    stacked_base_models = [(parameters_cnn,base_cnn),(parameters_bi_lstm,base_bi_lstm),(parameters_bi_lstm_cnn,base_cnn_bi_lstm),(parameters_lstm_cnn,base_cnn_lstm)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    temp = np.zeros((len(stacked_testX),len(stacked_base_models)),dtype=np.int64)\n",
    "    for i,m in enumerate(stacked_base_models):\n",
    "        print(i)\n",
    "        history = m[1].fit(stacked_trainX,stacked_trainY,epochs=m[0][\"epoch\"],batch_size=m[0][\"batch\"])\n",
    "        pred = m[1].predict(stacked_testX)\n",
    "        temp[:,i] = [int(np.argmax(x)) for x in pred]\n",
    "    stacked_metalearner_trainX = np.concatenate((stacked_metalearner_trainX, temp), axis=0)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stacked_metalearner_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
