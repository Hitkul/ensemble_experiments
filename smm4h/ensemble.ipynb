{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from gensim.models import KeyedVectors\n",
    "import word2vecReader as godin_embedding\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [12,10]\n",
    "from mlens.visualization import corrmat\n",
    "from base_learners import cnn,bi_lstm,cnn_bi_lstm,cnn_lstm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(filename,test_flag = False):\n",
    "    data = pd.read_csv(filename, sep=\"\\t\", header=None)\n",
    "    if not test_flag:\n",
    "        data.columns = [\"tweet_id\", \"username\", \"database_id\", \"class\",\"tweet\"]\n",
    "    else:\n",
    "        data.columns = [\"a\", \"b\", \"med\",\"med\", \"tweet\",\"class\",]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = load_data_from_file('dataset/personal_intake_tweets.txt')\n",
    "dev_data = load_data_from_file('dataset/personal_intake_tweets_dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = train_data['tweet'].tolist()+dev_data['tweet'].tolist()\n",
    "train_labels = train_data['class'].tolist()+dev_data['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = load_data_from_file('dataset/task_2_test_full_form.txt',test_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = test_data['class'].tolist()\n",
    "test_sentences = test_data['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9107, 9107, 7419, 7419)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels),len(train_sentences),len(test_labels),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = [x-1 for x in test_labels]\n",
    "train_labels = [x-1 for x in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = len(set(train_labels))\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(string.punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    # should have used translate but for some reason it breaks on my server\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = [clean_sentence(s) for s in train_sentences]\n",
    "testX = [clean_sentence(s) for s in test_sentences]\n",
    "trainY = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading Goding model.\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_embedding_matrix(model,dim):\n",
    "    #dim = 300 for google word2vec\n",
    "    #dim = 400 for godin\n",
    "    #dim = 100 for fast text\n",
    "    embedding_matrix = np.zeros((vocab_size,dim))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(test_labels,pred_class):\n",
    "    f1 = f1_score(test_labels,pred_class,labels=[0,1],average='micro')\n",
    "    p = precision_score(test_labels,pred_class,labels=[0,1],average='micro')\n",
    "    r = recall_score(test_labels,pred_class,labels=[0,1],average='micro')\n",
    "    acc = accuracy_score(test_labels,pred_class)\n",
    "    return [f1,p,r,acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pred_class(model):\n",
    "    pred = model.predict(testX)\n",
    "    return [int(np.argmax(x)) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 20\n",
      "Vocabulary size: 10940\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(trainX)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "trainX = encode_text(tokenizer, trainX, max_len)\n",
    "testX = encode_text(tokenizer, testX, max_len)\n",
    "trainY = to_categorical(trainY,num_classes=number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Goding model.\n"
     ]
    }
   ],
   "source": [
    "godin_model = load_godin_word_embedding(\"../word_embeddings/word2vec_twitter_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix_godin = get_word_embedding_matrix(godin_model,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cnn = load_model('models/cnn.h5')\n",
    "model_bi_lstm = load_model('models/bi_lstm.h5')\n",
    "model_cnn_bi_lstm = load_model('models/cnn_bi_lstm.h5')\n",
    "model_cnn_lstm = load_model('models/cnn_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_models = [('cnn',model_cnn),('bi_lstm',model_bi_lstm),('cnn_bi_lstm',model_cnn_bi_lstm),('cnn_lstm',model_cnn_lstm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class_base = [(name,get_pred_class(m)) for name,m in base_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_mat = np.zeros((len(pred_class_base[0][1]),len(pred_class_base)),dtype = np.int64)\n",
    "for i,p in enumerate(pred_class_base):\n",
    "    pred_mat[:,i] = p[1]\n",
    "\n",
    "pred_df = pd.DataFrame(pred_mat)\n",
    "pred_df.columns = [\"cnn\", \"bi_lstm\",\"cnn_bi_lstm\",\"cnn_lstm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_base = [(name,get_results(test_labels,pred_class)) for name,pred_class in pred_class_base]\n",
    "result_base_f = []\n",
    "for t in result_base:\n",
    "    temp = [t[0]]\n",
    "    for x in t[1]:\n",
    "        temp.append(x)\n",
    "    result_base_f.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance = pd.DataFrame(columns=['model','f1', 'precision', 'recall','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,result in enumerate(result_base_f):\n",
    "    model_performance.loc[i] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.637957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi_lstm</td>\n",
       "      <td>0.617651</td>\n",
       "      <td>0.654555</td>\n",
       "      <td>0.584686</td>\n",
       "      <td>0.662758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_bi_lstm</td>\n",
       "      <td>0.632167</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.607314</td>\n",
       "      <td>0.672058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.642971</td>\n",
       "      <td>0.669902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model        f1  precision    recall  accuracy\n",
       "0          cnn  0.623187   0.587997  0.662857  0.637957\n",
       "1      bi_lstm  0.617651   0.654555  0.584686  0.662758\n",
       "2  cnn_bi_lstm  0.632167   0.659142  0.607314  0.672058\n",
       "3     cnn_lstm  0.637507   0.632135  0.642971  0.669902"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error prediction Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAIaCAYAAAAa3/j/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElqApMuSZKkJjDpkiRJaoL/Dzs+ld1GupaeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff19e0fce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff19e36f080>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat(pred_df.corr(), inflate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation values are moderately low, there is scope of improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_models = np.zeros((len(testX),number_of_classes,len(base_models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,p in enumerate(base_models):\n",
    "    pred_prob_models[:,:,i] = p[1].predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_pred_prob = pred_prob_models.mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_pred_class = [int(np.argmax(x)) for x in avg_pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_ensemble_result = get_results(test_labels,avg_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_ensemble_result.insert(0,'avg_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance.loc[4] = avg_ensemble_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.637957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi_lstm</td>\n",
       "      <td>0.617651</td>\n",
       "      <td>0.654555</td>\n",
       "      <td>0.584686</td>\n",
       "      <td>0.662758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_bi_lstm</td>\n",
       "      <td>0.632167</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.607314</td>\n",
       "      <td>0.672058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.642971</td>\n",
       "      <td>0.669902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_ensemble</td>\n",
       "      <td>0.646064</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>0.682572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model        f1  precision    recall  accuracy\n",
       "0           cnn  0.623187   0.587997  0.662857  0.637957\n",
       "1       bi_lstm  0.617651   0.654555  0.584686  0.662758\n",
       "2   cnn_bi_lstm  0.632167   0.659142  0.607314  0.672058\n",
       "3      cnn_lstm  0.637507   0.632135  0.642971  0.669902\n",
       "4  avg_ensemble  0.646064   0.659524  0.633143  0.682572"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_pred_class = np.zeros((len(testX),len(pred_class_base)),dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,p in enumerate(base_models):\n",
    "    base_pred_class[:,i] = get_pred_class(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2],\n",
       "       [1, 2, 2, 2],\n",
       "       [1, 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, 1],\n",
       "       [2, 2, 2, 2],\n",
       "       [1, 2, 2, 2]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "majority_pred_class = [int(np.argmax(np.bincount(x))) for x in base_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "majority_ensemble_result = get_results(test_labels,majority_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "majority_ensemble_result.insert(0,'majority_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance.loc[5] = majority_ensemble_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.637957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi_lstm</td>\n",
       "      <td>0.617651</td>\n",
       "      <td>0.654555</td>\n",
       "      <td>0.584686</td>\n",
       "      <td>0.662758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_bi_lstm</td>\n",
       "      <td>0.632167</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.607314</td>\n",
       "      <td>0.672058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.642971</td>\n",
       "      <td>0.669902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_ensemble</td>\n",
       "      <td>0.646064</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>0.682572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>majority_ensemble</td>\n",
       "      <td>0.653894</td>\n",
       "      <td>0.644953</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.682437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model        f1  precision    recall  accuracy\n",
       "0                cnn  0.623187   0.587997  0.662857  0.637957\n",
       "1            bi_lstm  0.617651   0.654555  0.584686  0.662758\n",
       "2        cnn_bi_lstm  0.632167   0.659142  0.607314  0.672058\n",
       "3           cnn_lstm  0.637507   0.632135  0.642971  0.669902\n",
       "4       avg_ensemble  0.646064   0.659524  0.633143  0.682572\n",
       "5  majority_ensemble  0.653894   0.644953  0.663086  0.682437"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super learner - blending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_cnn = {\n",
    "            \"n_dense\": 100,\n",
    "            \"dropout\": 0.7,\n",
    "            \"n_filters\": 100,\n",
    "            \"filter_size\": 2,\n",
    "            \"em\": 'embedding_matrix_godin',\n",
    "            \"batch\": 16,\n",
    "            \"epoch\": 7\n",
    "        }\n",
    "\n",
    "\n",
    "parameters_bi_lstm = {\n",
    "            \"dropout\": 0.7,\n",
    "            \"units_out\": 128,\n",
    "            \"em\": 'embedding_matrix_godin',\n",
    "            \"batch\": 8,\n",
    "            \"epoch\": 9\n",
    "        }\n",
    "\n",
    "parameters_bi_lstm_cnn = {\n",
    "            \"n_filters\":400,\n",
    "            \"filter_size\":4,\n",
    "            \"em\": 'embedding_matrix_godin',\n",
    "            \"conv_dropout\":0.7,\n",
    "            \"l_or_g_dropout\":0.2,\n",
    "            \"units_out\":16,\n",
    "            \"batch\": 8,\n",
    "            \"epoch\": 12\n",
    "        }\n",
    "\n",
    "parameters_lstm_cnn = {\n",
    "            \"n_filters\":300,\n",
    "            \"filter_size\":2,\n",
    "            \"em\": 'embedding_matrix_godin',\n",
    "            \"conv_dropout\":0.8,\n",
    "            \"l_or_g_dropout\":0.2,\n",
    "            \"units_out\":128,\n",
    "            \"batch\": 8,\n",
    "            \"epoch\": 15\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 20, 400)           4376000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,466,503\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,376,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 20, 400)           4376000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,918,467\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,376,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 20, 400)           4376000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 5,069,875\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,376,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 20, 400)           4376000   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 5,043,139\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,376,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "blend_base_cnn = cnn(length=max_len,\n",
    "                vocab_size=vocab_size,\n",
    "                n_dense=parameters_cnn['n_dense'],\n",
    "                dropout=parameters_cnn['dropout'],\n",
    "                n_filters=parameters_cnn['n_filters'],\n",
    "                filter_size=int(parameters_cnn['filter_size']),\n",
    "                em = eval(parameters_cnn['em']),\n",
    "                number_of_classes=number_of_classes)\n",
    "\n",
    "blend_base_bi_lstm = bi_lstm(length=max_len,\n",
    "                        vocab_size=vocab_size,\n",
    "                        dropout=parameters_bi_lstm['dropout'],\n",
    "                        units_out=parameters_bi_lstm['units_out'],\n",
    "                        em=eval(parameters_bi_lstm['em']),\n",
    "                        number_of_classes=number_of_classes)\n",
    "\n",
    "\n",
    "blend_base_cnn_bi_lstm = cnn_bi_lstm(length=max_len,\n",
    "                                vocab_size=vocab_size,\n",
    "                                n_filters=parameters_bi_lstm_cnn['n_filters'],\n",
    "                                filter_size=parameters_bi_lstm_cnn['filter_size'],\n",
    "                                em=eval(parameters_bi_lstm_cnn['em']),\n",
    "                                number_of_classes=number_of_classes,\n",
    "                                conv_dropout=parameters_bi_lstm_cnn['conv_dropout'],\n",
    "                                l_or_g_dropout=parameters_bi_lstm_cnn['l_or_g_dropout'],\n",
    "                                units_out=parameters_bi_lstm_cnn['units_out'])\n",
    "\n",
    "\n",
    "blend_base_cnn_lstm = cnn_lstm(length=max_len,\n",
    "                                vocab_size=vocab_size,\n",
    "                                n_filters=parameters_bi_lstm_cnn['n_filters'],\n",
    "                                filter_size=parameters_bi_lstm_cnn['filter_size'],\n",
    "                                em=eval(parameters_bi_lstm_cnn['em']),\n",
    "                                number_of_classes=number_of_classes,\n",
    "                                conv_dropout=parameters_bi_lstm_cnn['conv_dropout'],\n",
    "                                l_or_g_dropout=parameters_bi_lstm_cnn['l_or_g_dropout'],\n",
    "                                units_out=parameters_bi_lstm_cnn['units_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend_base_models = [(parameters_cnn,blend_base_cnn),(parameters_bi_lstm,blend_base_bi_lstm),(parameters_bi_lstm_cnn,blend_base_cnn_bi_lstm),(parameters_lstm_cnn,blend_base_cnn_lstm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend_trainX, blend_testX, blend_trainY, blend_testY = train_test_split(trainX, trainY, test_size=0.10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8196, 8196, 911, 911)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blend_trainX),len(blend_trainY),len(blend_testX),len(blend_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metalearner_trainX = np.zeros((len(blend_testX),len(blend_base_models)),dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/7\n",
      "8196/8196 [==============================] - 7s 801us/step - loss: 0.5680 - acc: 0.7110\n",
      "Epoch 2/7\n",
      "8196/8196 [==============================] - 5s 631us/step - loss: 0.5079 - acc: 0.7524\n",
      "Epoch 3/7\n",
      "8196/8196 [==============================] - 5s 612us/step - loss: 0.4845 - acc: 0.7693\n",
      "Epoch 4/7\n",
      "8196/8196 [==============================] - 6s 684us/step - loss: 0.4615 - acc: 0.7813\n",
      "Epoch 5/7\n",
      "8196/8196 [==============================] - 6s 696us/step - loss: 0.4557 - acc: 0.7875\n",
      "Epoch 6/7\n",
      "8196/8196 [==============================] - 6s 697us/step - loss: 0.4399 - acc: 0.7961\n",
      "Epoch 7/7\n",
      "8196/8196 [==============================] - 6s 699us/step - loss: 0.4306 - acc: 0.8020\n",
      "1\n",
      "Epoch 1/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.4992 - acc: 0.7594\n",
      "Epoch 2/9\n",
      "8196/8196 [==============================] - 45s 5ms/step - loss: 0.4308 - acc: 0.8020\n",
      "Epoch 3/9\n",
      "8196/8196 [==============================] - 44s 5ms/step - loss: 0.4073 - acc: 0.8160\n",
      "Epoch 4/9\n",
      "8196/8196 [==============================] - 44s 5ms/step - loss: 0.3829 - acc: 0.8303\n",
      "Epoch 5/9\n",
      "8196/8196 [==============================] - 49s 6ms/step - loss: 0.3712 - acc: 0.8351\n",
      "Epoch 6/9\n",
      "8196/8196 [==============================] - 44s 5ms/step - loss: 0.3547 - acc: 0.8452\n",
      "Epoch 7/9\n",
      "8196/8196 [==============================] - 46s 6ms/step - loss: 0.3361 - acc: 0.8506\n",
      "Epoch 8/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.3189 - acc: 0.8605\n",
      "Epoch 9/9\n",
      "8196/8196 [==============================] - 46s 6ms/step - loss: 0.3013 - acc: 0.8694\n",
      "2\n",
      "Epoch 1/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.4921 - acc: 0.7607\n",
      "Epoch 2/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.4169 - acc: 0.8094\n",
      "Epoch 3/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.3855 - acc: 0.8278\n",
      "Epoch 4/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.3569 - acc: 0.8424: 0s - loss: 0.3566 - acc:\n",
      "Epoch 5/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.3310 - acc: 0.8566\n",
      "Epoch 6/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.3088 - acc: 0.8672\n",
      "Epoch 7/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.2866 - acc: 0.8781\n",
      "Epoch 8/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.2634 - acc: 0.8910\n",
      "Epoch 9/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.2397 - acc: 0.9047\n",
      "Epoch 10/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.2201 - acc: 0.9124\n",
      "Epoch 11/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.2037 - acc: 0.9207\n",
      "Epoch 12/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.1958 - acc: 0.9243\n",
      "3\n",
      "Epoch 1/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.5221 - acc: 0.7440\n",
      "Epoch 2/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.4468 - acc: 0.7930\n",
      "Epoch 3/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.4097 - acc: 0.8172\n",
      "Epoch 4/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.3850 - acc: 0.8315\n",
      "Epoch 5/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.3561 - acc: 0.8466\n",
      "Epoch 6/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.3332 - acc: 0.8611\n",
      "Epoch 7/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.3142 - acc: 0.8703\n",
      "Epoch 8/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2899 - acc: 0.8840\n",
      "Epoch 9/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.2639 - acc: 0.8962\n",
      "Epoch 10/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2547 - acc: 0.8980\n",
      "Epoch 11/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2346 - acc: 0.9080\n",
      "Epoch 12/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2315 - acc: 0.9101\n",
      "Epoch 13/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2192 - acc: 0.9138\n",
      "Epoch 14/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2009 - acc: 0.9232\n",
      "Epoch 15/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.1978 - acc: 0.9252\n"
     ]
    }
   ],
   "source": [
    "for i,m in enumerate(blend_base_models):\n",
    "    print(i)\n",
    "    history = m[1].fit(blend_trainX,blend_trainY,epochs=m[0][\"epoch\"],batch_size=m[0][\"batch\"])\n",
    "    pred = m[1].predict(blend_testX)\n",
    "    metalearner_trainX[:,i] = [int(np.argmax(x)) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_meta_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_testY = np.array([int(np.argmax(x)) for x in blend_testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blend_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_meta_model.fit(metalearner_trainX, blend_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_class = np.zeros((len(testX),len(blend_base_models)),dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,p in enumerate(base_models):\n",
    "    test_pred_class[:,i] = get_pred_class(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_ensemble_pred_class = blend_meta_model.predict(test_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_ensemble_pred_class = list(blend_ensemble_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_ensemble_result = get_results(test_labels,blend_ensemble_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend_ensemble_result.insert(0,'blend_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance.loc[6] = blend_ensemble_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.637957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi_lstm</td>\n",
       "      <td>0.617651</td>\n",
       "      <td>0.654555</td>\n",
       "      <td>0.584686</td>\n",
       "      <td>0.662758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_bi_lstm</td>\n",
       "      <td>0.632167</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.607314</td>\n",
       "      <td>0.672058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.642971</td>\n",
       "      <td>0.669902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_ensemble</td>\n",
       "      <td>0.646064</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>0.682572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>majority_ensemble</td>\n",
       "      <td>0.653894</td>\n",
       "      <td>0.644953</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.682437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blend_ensemble</td>\n",
       "      <td>0.613343</td>\n",
       "      <td>0.677919</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.668149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stacked_ensemble</td>\n",
       "      <td>0.613960</td>\n",
       "      <td>0.678088</td>\n",
       "      <td>0.560914</td>\n",
       "      <td>0.668823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model        f1  precision    recall  accuracy\n",
       "0                cnn  0.623187   0.587997  0.662857  0.637957\n",
       "1            bi_lstm  0.617651   0.654555  0.584686  0.662758\n",
       "2        cnn_bi_lstm  0.632167   0.659142  0.607314  0.672058\n",
       "3           cnn_lstm  0.637507   0.632135  0.642971  0.669902\n",
       "4       avg_ensemble  0.646064   0.659524  0.633143  0.682572\n",
       "5  majority_ensemble  0.653894   0.644953  0.663086  0.682437\n",
       "6     blend_ensemble  0.613343   0.677919  0.560000  0.668149\n",
       "7   stacked_ensemble  0.613960   0.678088  0.560914  0.668823"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super learner - stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = np.asarray([clean_sentence(s) for s in train_sentences])\n",
    "testX = np.asarray([clean_sentence(s) for s in test_sentences])\n",
    "trainY = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_metalearner_trainX = np.array([[0, 0, 0, 0]],dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_metalearner_trainY = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------itr = 1--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_102 (Embedding)    (None, 20, 400)           4134800   \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_26 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,225,303\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,134,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_103 (Embedding)    (None, 20, 400)           4134800   \n",
      "_________________________________________________________________\n",
      "bidirectional_51 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,677,267\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,134,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_104 (Embedding)    (None, 20, 400)           4134800   \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_52 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,828,675\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,134,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_105 (Embedding)    (None, 20, 400)           4134800   \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_78 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,801,939\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,134,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n",
      "Epoch 1/7\n",
      "8195/8195 [==============================] - 19s 2ms/step - loss: 0.5751 - acc: 0.7040\n",
      "Epoch 2/7\n",
      "8195/8195 [==============================] - 8s 926us/step - loss: 0.5088 - acc: 0.7526\n",
      "Epoch 3/7\n",
      "8195/8195 [==============================] - 8s 969us/step - loss: 0.4811 - acc: 0.7686\n",
      "Epoch 4/7\n",
      "8195/8195 [==============================] - 8s 940us/step - loss: 0.4672 - acc: 0.7766\n",
      "Epoch 5/7\n",
      "8195/8195 [==============================] - 8s 924us/step - loss: 0.4546 - acc: 0.7857\n",
      "Epoch 6/7\n",
      "8195/8195 [==============================] - 8s 925us/step - loss: 0.4434 - acc: 0.7947\n",
      "Epoch 7/7\n",
      "8195/8195 [==============================] - 8s 932us/step - loss: 0.4410 - acc: 0.7948\n",
      "1\n",
      "Epoch 1/9\n",
      "8195/8195 [==============================] - 68s 8ms/step - loss: 0.5021 - acc: 0.7548\n",
      "Epoch 2/9\n",
      "8195/8195 [==============================] - 61s 7ms/step - loss: 0.4298 - acc: 0.8027\n",
      "Epoch 3/9\n",
      "8195/8195 [==============================] - 56s 7ms/step - loss: 0.4017 - acc: 0.8179\n",
      "Epoch 4/9\n",
      "8195/8195 [==============================] - 63s 8ms/step - loss: 0.3856 - acc: 0.8251\n",
      "Epoch 5/9\n",
      "8195/8195 [==============================] - 64s 8ms/step - loss: 0.3695 - acc: 0.8359\n",
      "Epoch 6/9\n",
      "8195/8195 [==============================] - 60s 7ms/step - loss: 0.3522 - acc: 0.8435\n",
      "Epoch 7/9\n",
      "8195/8195 [==============================] - 43s 5ms/step - loss: 0.3352 - acc: 0.8523\n",
      "Epoch 8/9\n",
      "8195/8195 [==============================] - 44s 5ms/step - loss: 0.3170 - acc: 0.8613\n",
      "Epoch 9/9\n",
      "8195/8195 [==============================] - 47s 6ms/step - loss: 0.2981 - acc: 0.8726\n",
      "2\n",
      "Epoch 1/12\n",
      "8195/8195 [==============================] - 52s 6ms/step - loss: 0.4926 - acc: 0.7619\n",
      "Epoch 2/12\n",
      "8195/8195 [==============================] - 39s 5ms/step - loss: 0.4184 - acc: 0.8081\n",
      "Epoch 3/12\n",
      "8195/8195 [==============================] - 40s 5ms/step - loss: 0.3898 - acc: 0.8258\n",
      "Epoch 4/12\n",
      "8195/8195 [==============================] - 40s 5ms/step - loss: 0.3612 - acc: 0.8419\n",
      "Epoch 5/12\n",
      "8195/8195 [==============================] - 33s 4ms/step - loss: 0.3340 - acc: 0.8574\n",
      "Epoch 6/12\n",
      "8195/8195 [==============================] - 32s 4ms/step - loss: 0.3092 - acc: 0.8688\n",
      "Epoch 7/12\n",
      "8195/8195 [==============================] - 39s 5ms/step - loss: 0.2876 - acc: 0.8772\n",
      "Epoch 8/12\n",
      "8195/8195 [==============================] - 39s 5ms/step - loss: 0.2650 - acc: 0.8903\n",
      "Epoch 9/12\n",
      "8195/8195 [==============================] - 39s 5ms/step - loss: 0.2415 - acc: 0.9003\n",
      "Epoch 10/12\n",
      "8195/8195 [==============================] - 36s 4ms/step - loss: 0.2220 - acc: 0.9099\n",
      "Epoch 11/12\n",
      "8195/8195 [==============================] - 31s 4ms/step - loss: 0.2046 - acc: 0.9181\n",
      "Epoch 12/12\n",
      "8195/8195 [==============================] - 40s 5ms/step - loss: 0.1846 - acc: 0.9265\n",
      "3\n",
      "Epoch 1/15\n",
      "8195/8195 [==============================] - 47s 6ms/step - loss: 0.5142 - acc: 0.7501\n",
      "Epoch 2/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.4401 - acc: 0.8015\n",
      "Epoch 3/15\n",
      "8195/8195 [==============================] - 36s 4ms/step - loss: 0.4043 - acc: 0.8195\n",
      "Epoch 4/15\n",
      "8195/8195 [==============================] - 36s 4ms/step - loss: 0.3782 - acc: 0.8362\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.3559 - acc: 0.8487\n",
      "Epoch 6/15\n",
      "8195/8195 [==============================] - 33s 4ms/step - loss: 0.3346 - acc: 0.8575: 0s - loss: 0.334\n",
      "Epoch 7/15\n",
      "8195/8195 [==============================] - 33s 4ms/step - loss: 0.3099 - acc: 0.8706\n",
      "Epoch 8/15\n",
      "8195/8195 [==============================] - 33s 4ms/step - loss: 0.2902 - acc: 0.8788\n",
      "Epoch 9/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2706 - acc: 0.8910\n",
      "Epoch 10/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2544 - acc: 0.8989\n",
      "Epoch 11/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2422 - acc: 0.9007\n",
      "Epoch 12/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2272 - acc: 0.9110\n",
      "Epoch 13/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2122 - acc: 0.9188\n",
      "Epoch 14/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2021 - acc: 0.9232\n",
      "Epoch 15/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.1915 - acc: 0.9280\n",
      "----------------------itr = 2--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_106 (Embedding)    (None, 20, 400)           4116800   \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_27 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,207,303\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,116,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_107 (Embedding)    (None, 20, 400)           4116800   \n",
      "_________________________________________________________________\n",
      "bidirectional_53 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,659,267\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,116,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_108 (Embedding)    (None, 20, 400)           4116800   \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_186 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_54 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_187 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,810,675\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,116,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_109 (Embedding)    (None, 20, 400)           4116800   \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_188 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_81 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_189 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,783,939\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,116,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n",
      "Epoch 1/7\n",
      "8195/8195 [==============================] - 20s 2ms/step - loss: 0.5755 - acc: 0.7032\n",
      "Epoch 2/7\n",
      "8195/8195 [==============================] - 8s 963us/step - loss: 0.5087 - acc: 0.7495\n",
      "Epoch 3/7\n",
      "8195/8195 [==============================] - 8s 976us/step - loss: 0.4774 - acc: 0.7710\n",
      "Epoch 4/7\n",
      "8195/8195 [==============================] - 8s 1ms/step - loss: 0.4640 - acc: 0.7799\n",
      "Epoch 5/7\n",
      "8195/8195 [==============================] - 8s 980us/step - loss: 0.4513 - acc: 0.7914\n",
      "Epoch 6/7\n",
      "8195/8195 [==============================] - 8s 966us/step - loss: 0.4469 - acc: 0.7941\n",
      "Epoch 7/7\n",
      "8195/8195 [==============================] - 8s 970us/step - loss: 0.4404 - acc: 0.7972\n",
      "1\n",
      "Epoch 1/9\n",
      "8195/8195 [==============================] - 76s 9ms/step - loss: 0.4957 - acc: 0.7612\n",
      "Epoch 2/9\n",
      "8195/8195 [==============================] - 64s 8ms/step - loss: 0.4308 - acc: 0.8013\n",
      "Epoch 3/9\n",
      "8195/8195 [==============================] - 64s 8ms/step - loss: 0.4084 - acc: 0.8172\n",
      "Epoch 4/9\n",
      "8195/8195 [==============================] - 64s 8ms/step - loss: 0.3901 - acc: 0.8281\n",
      "Epoch 5/9\n",
      "8195/8195 [==============================] - 64s 8ms/step - loss: 0.3712 - acc: 0.8352\n",
      "Epoch 6/9\n",
      "8195/8195 [==============================] - 64s 8ms/step - loss: 0.3534 - acc: 0.8454\n",
      "Epoch 7/9\n",
      "8195/8195 [==============================] - 64s 8ms/step - loss: 0.3350 - acc: 0.8528\n",
      "Epoch 8/9\n",
      "8195/8195 [==============================] - 64s 8ms/step - loss: 0.3165 - acc: 0.8626\n",
      "Epoch 9/9\n",
      "8195/8195 [==============================] - 64s 8ms/step - loss: 0.2968 - acc: 0.8733\n",
      "2\n",
      "Epoch 1/12\n",
      "8195/8195 [==============================] - 51s 6ms/step - loss: 0.4866 - acc: 0.7644\n",
      "Epoch 2/12\n",
      "8195/8195 [==============================] - 40s 5ms/step - loss: 0.4206 - acc: 0.8065\n",
      "Epoch 3/12\n",
      "8195/8195 [==============================] - 39s 5ms/step - loss: 0.3864 - acc: 0.8245\n",
      "Epoch 4/12\n",
      "8195/8195 [==============================] - 39s 5ms/step - loss: 0.3602 - acc: 0.8407\n",
      "Epoch 5/12\n",
      "8195/8195 [==============================] - 40s 5ms/step - loss: 0.3340 - acc: 0.8576\n",
      "Epoch 6/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8195/8195 [==============================] - 36s 4ms/step - loss: 0.3089 - acc: 0.8673\n",
      "Epoch 7/12\n",
      "8195/8195 [==============================] - 37s 4ms/step - loss: 0.2827 - acc: 0.8828\n",
      "Epoch 8/12\n",
      "8195/8195 [==============================] - 37s 5ms/step - loss: 0.2551 - acc: 0.8931\n",
      "Epoch 9/12\n",
      "8195/8195 [==============================] - 37s 4ms/step - loss: 0.2375 - acc: 0.9031\n",
      "Epoch 10/12\n",
      "8195/8195 [==============================] - 37s 5ms/step - loss: 0.2159 - acc: 0.9135\n",
      "Epoch 11/12\n",
      "8195/8195 [==============================] - 38s 5ms/step - loss: 0.1974 - acc: 0.9219\n",
      "Epoch 12/12\n",
      "8195/8195 [==============================] - 37s 5ms/step - loss: 0.1918 - acc: 0.9262\n",
      "3\n",
      "Epoch 1/15\n",
      "8195/8195 [==============================] - 46s 6ms/step - loss: 0.5223 - acc: 0.7421\n",
      "Epoch 2/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.4428 - acc: 0.7952\n",
      "Epoch 3/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.4081 - acc: 0.8166\n",
      "Epoch 4/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.3809 - acc: 0.8321\n",
      "Epoch 5/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.3519 - acc: 0.8486\n",
      "Epoch 6/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.3351 - acc: 0.8549\n",
      "Epoch 7/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.3123 - acc: 0.8681\n",
      "Epoch 8/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2901 - acc: 0.8807\n",
      "Epoch 9/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2722 - acc: 0.8865\n",
      "Epoch 10/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2508 - acc: 0.8992\n",
      "Epoch 11/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2430 - acc: 0.9036\n",
      "Epoch 12/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2229 - acc: 0.9118: 1s - los\n",
      "Epoch 13/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2167 - acc: 0.9159: 1s - loss: 0\n",
      "Epoch 14/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.1978 - acc: 0.9242\n",
      "Epoch 15/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.1996 - acc: 0.9245\n",
      "----------------------itr = 3--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_110 (Embedding)    (None, 20, 400)           4102000   \n",
      "_________________________________________________________________\n",
      "dropout_190 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_28 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_191 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,192,503\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,102,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_111 (Embedding)    (None, 20, 400)           4102000   \n",
      "_________________________________________________________________\n",
      "bidirectional_55 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_192 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,644,467\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,102,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_112 (Embedding)    (None, 20, 400)           4102000   \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_193 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_56 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_194 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,795,875\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,102,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_113 (Embedding)    (None, 20, 400)           4102000   \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_195 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_84 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_196 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,769,139\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,102,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n",
      "Epoch 1/7\n",
      "8195/8195 [==============================] - 20s 2ms/step - loss: 0.5753 - acc: 0.7030\n",
      "Epoch 2/7\n",
      "8195/8195 [==============================] - 8s 1ms/step - loss: 0.5066 - acc: 0.7549\n",
      "Epoch 3/7\n",
      "8195/8195 [==============================] - 8s 976us/step - loss: 0.4819 - acc: 0.7691\n",
      "Epoch 4/7\n",
      "8195/8195 [==============================] - 8s 990us/step - loss: 0.4657 - acc: 0.7784\n",
      "Epoch 5/7\n",
      "8195/8195 [==============================] - 8s 998us/step - loss: 0.4506 - acc: 0.7906\n",
      "Epoch 6/7\n",
      "8195/8195 [==============================] - 8s 986us/step - loss: 0.4385 - acc: 0.7987\n",
      "Epoch 7/7\n",
      "8195/8195 [==============================] - 8s 985us/step - loss: 0.4321 - acc: 0.8037\n",
      "1\n",
      "Epoch 1/9\n",
      "8195/8195 [==============================] - 77s 9ms/step - loss: 0.5000 - acc: 0.7579\n",
      "Epoch 2/9\n",
      "8195/8195 [==============================] - 64s 8ms/step - loss: 0.4359 - acc: 0.7995\n",
      "Epoch 3/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8195/8195 [==============================] - 58s 7ms/step - loss: 0.4088 - acc: 0.8147\n",
      "Epoch 4/9\n",
      "8195/8195 [==============================] - 57s 7ms/step - loss: 0.3865 - acc: 0.8265\n",
      "Epoch 5/9\n",
      "8195/8195 [==============================] - 57s 7ms/step - loss: 0.3715 - acc: 0.8356\n",
      "Epoch 6/9\n",
      "8195/8195 [==============================] - 58s 7ms/step - loss: 0.3489 - acc: 0.8450\n",
      "Epoch 7/9\n",
      "8195/8195 [==============================] - 59s 7ms/step - loss: 0.3316 - acc: 0.8571\n",
      "Epoch 8/9\n",
      "8195/8195 [==============================] - 59s 7ms/step - loss: 0.3147 - acc: 0.8639\n",
      "Epoch 9/9\n",
      "8195/8195 [==============================] - 59s 7ms/step - loss: 0.2999 - acc: 0.8703\n",
      "2\n",
      "Epoch 1/12\n",
      "8195/8195 [==============================] - 50s 6ms/step - loss: 0.4928 - acc: 0.7658\n",
      "Epoch 2/12\n",
      "8195/8195 [==============================] - 39s 5ms/step - loss: 0.4204 - acc: 0.8083\n",
      "Epoch 3/12\n",
      "8195/8195 [==============================] - 38s 5ms/step - loss: 0.3859 - acc: 0.8281\n",
      "Epoch 4/12\n",
      "8195/8195 [==============================] - 38s 5ms/step - loss: 0.3615 - acc: 0.8396\n",
      "Epoch 5/12\n",
      "8195/8195 [==============================] - 37s 4ms/step - loss: 0.3357 - acc: 0.8533\n",
      "Epoch 6/12\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.3091 - acc: 0.8681\n",
      "Epoch 7/12\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2847 - acc: 0.8824\n",
      "Epoch 8/12\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2607 - acc: 0.8894\n",
      "Epoch 9/12\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2452 - acc: 0.8981\n",
      "Epoch 10/12\n",
      "8195/8195 [==============================] - 36s 4ms/step - loss: 0.2199 - acc: 0.9116\n",
      "Epoch 11/12\n",
      "8195/8195 [==============================] - 38s 5ms/step - loss: 0.2056 - acc: 0.9169\n",
      "Epoch 12/12\n",
      "8195/8195 [==============================] - 39s 5ms/step - loss: 0.1929 - acc: 0.9228\n",
      "3\n",
      "Epoch 1/15\n",
      "8195/8195 [==============================] - 47s 6ms/step - loss: 0.5238 - acc: 0.7383\n",
      "Epoch 2/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.4435 - acc: 0.7981\n",
      "Epoch 3/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.4135 - acc: 0.8143\n",
      "Epoch 4/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.3827 - acc: 0.8298\n",
      "Epoch 5/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.3598 - acc: 0.8462\n",
      "Epoch 6/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.3351 - acc: 0.8573\n",
      "Epoch 7/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.3162 - acc: 0.8662\n",
      "Epoch 8/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2944 - acc: 0.8800\n",
      "Epoch 9/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2738 - acc: 0.8892\n",
      "Epoch 10/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2607 - acc: 0.8967\n",
      "Epoch 11/15\n",
      "8195/8195 [==============================] - 34s 4ms/step - loss: 0.2425 - acc: 0.9032\n",
      "Epoch 12/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2303 - acc: 0.9102\n",
      "Epoch 13/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2210 - acc: 0.9121\n",
      "Epoch 14/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.2012 - acc: 0.9224\n",
      "Epoch 15/15\n",
      "8195/8195 [==============================] - 35s 4ms/step - loss: 0.1932 - acc: 0.9287\n",
      "----------------------itr = 4--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_114 (Embedding)    (None, 20, 400)           4107200   \n",
      "_________________________________________________________________\n",
      "dropout_197 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_29 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_198 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,197,703\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,107,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_115 (Embedding)    (None, 20, 400)           4107200   \n",
      "_________________________________________________________________\n",
      "bidirectional_57 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,649,667\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,107,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_116 (Embedding)    (None, 20, 400)           4107200   \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_200 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_58 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_201 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,801,075\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,107,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_117 (Embedding)    (None, 20, 400)           4107200   \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_202 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_87 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_203 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,774,339\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,107,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "8196/8196 [==============================] - 20s 2ms/step - loss: 0.5683 - acc: 0.7071\n",
      "Epoch 2/7\n",
      "8196/8196 [==============================] - 7s 877us/step - loss: 0.5082 - acc: 0.7543\n",
      "Epoch 3/7\n",
      "8196/8196 [==============================] - 7s 878us/step - loss: 0.4804 - acc: 0.7695\n",
      "Epoch 4/7\n",
      "8196/8196 [==============================] - 7s 879us/step - loss: 0.4631 - acc: 0.7811\n",
      "Epoch 5/7\n",
      "8196/8196 [==============================] - 7s 888us/step - loss: 0.4495 - acc: 0.7908\n",
      "Epoch 6/7\n",
      "8196/8196 [==============================] - 7s 882us/step - loss: 0.4413 - acc: 0.7943\n",
      "Epoch 7/7\n",
      "8196/8196 [==============================] - 7s 883us/step - loss: 0.4342 - acc: 0.7966\n",
      "1\n",
      "Epoch 1/9\n",
      "8196/8196 [==============================] - 73s 9ms/step - loss: 0.4936 - acc: 0.7642\n",
      "Epoch 2/9\n",
      "8196/8196 [==============================] - 61s 7ms/step - loss: 0.4272 - acc: 0.8040\n",
      "Epoch 3/9\n",
      "8196/8196 [==============================] - 63s 8ms/step - loss: 0.4035 - acc: 0.8167\n",
      "Epoch 4/9\n",
      "8196/8196 [==============================] - 54s 7ms/step - loss: 0.3837 - acc: 0.8283\n",
      "Epoch 5/9\n",
      "8196/8196 [==============================] - 54s 7ms/step - loss: 0.3688 - acc: 0.8361\n",
      "Epoch 6/9\n",
      "8196/8196 [==============================] - 54s 7ms/step - loss: 0.3473 - acc: 0.8459\n",
      "Epoch 7/9\n",
      "8196/8196 [==============================] - 54s 7ms/step - loss: 0.3325 - acc: 0.8531\n",
      "Epoch 8/9\n",
      "8196/8196 [==============================] - 54s 7ms/step - loss: 0.3116 - acc: 0.8639\n",
      "Epoch 9/9\n",
      "8196/8196 [==============================] - 54s 7ms/step - loss: 0.2942 - acc: 0.8713\n",
      "2\n",
      "Epoch 1/12\n",
      "8196/8196 [==============================] - 48s 6ms/step - loss: 0.4973 - acc: 0.7591\n",
      "Epoch 2/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.4212 - acc: 0.8071\n",
      "Epoch 3/12\n",
      "8196/8196 [==============================] - 36s 4ms/step - loss: 0.3874 - acc: 0.8245\n",
      "Epoch 4/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.3589 - acc: 0.8417\n",
      "Epoch 5/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.3357 - acc: 0.8543\n",
      "Epoch 6/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.3106 - acc: 0.8669\n",
      "Epoch 7/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.2881 - acc: 0.8786: 4s -\n",
      "Epoch 8/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.2631 - acc: 0.8925\n",
      "Epoch 9/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.2397 - acc: 0.9021\n",
      "Epoch 10/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.2237 - acc: 0.9096\n",
      "Epoch 11/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.2061 - acc: 0.9159\n",
      "Epoch 12/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.1925 - acc: 0.9224\n",
      "3\n",
      "Epoch 1/15\n",
      "8196/8196 [==============================] - 44s 5ms/step - loss: 0.5205 - acc: 0.7422\n",
      "Epoch 2/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.4411 - acc: 0.7997\n",
      "Epoch 3/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.4064 - acc: 0.8192\n",
      "Epoch 4/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.3797 - acc: 0.8339\n",
      "Epoch 5/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.3538 - acc: 0.8473\n",
      "Epoch 6/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.3294 - acc: 0.8587\n",
      "Epoch 7/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.3078 - acc: 0.8716\n",
      "Epoch 8/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.2922 - acc: 0.8795\n",
      "Epoch 9/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.2733 - acc: 0.8882\n",
      "Epoch 10/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.2537 - acc: 0.8980\n",
      "Epoch 11/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.2418 - acc: 0.9053\n",
      "Epoch 12/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.2238 - acc: 0.9144\n",
      "Epoch 13/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.2130 - acc: 0.9167\n",
      "Epoch 14/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.2065 - acc: 0.9180\n",
      "Epoch 15/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.1938 - acc: 0.9270\n",
      "----------------------itr = 5--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_118 (Embedding)    (None, 20, 400)           4076400   \n",
      "_________________________________________________________________\n",
      "dropout_204 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_30 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_205 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,166,903\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,076,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_119 (Embedding)    (None, 20, 400)           4076400   \n",
      "_________________________________________________________________\n",
      "bidirectional_59 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_206 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,618,867\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,076,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_120 (Embedding)    (None, 20, 400)           4076400   \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_207 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_60 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_208 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,770,275\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,076,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_121 (Embedding)    (None, 20, 400)           4076400   \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_209 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_90 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_210 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,743,539\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,076,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "8196/8196 [==============================] - 19s 2ms/step - loss: 0.5703 - acc: 0.7080\n",
      "Epoch 2/7\n",
      "8196/8196 [==============================] - 7s 815us/step - loss: 0.5082 - acc: 0.7548\n",
      "Epoch 3/7\n",
      "8196/8196 [==============================] - 7s 819us/step - loss: 0.4813 - acc: 0.7718\n",
      "Epoch 4/7\n",
      "8196/8196 [==============================] - 7s 816us/step - loss: 0.4667 - acc: 0.7814\n",
      "Epoch 5/7\n",
      "8196/8196 [==============================] - 7s 818us/step - loss: 0.4500 - acc: 0.7891\n",
      "Epoch 6/7\n",
      "8196/8196 [==============================] - 7s 818us/step - loss: 0.4449 - acc: 0.7962\n",
      "Epoch 7/7\n",
      "8196/8196 [==============================] - 7s 820us/step - loss: 0.4361 - acc: 0.8003\n",
      "1\n",
      "Epoch 1/9\n",
      "8196/8196 [==============================] - 59s 7ms/step - loss: 0.4968 - acc: 0.7594\n",
      "Epoch 2/9\n",
      "8196/8196 [==============================] - 46s 6ms/step - loss: 0.4302 - acc: 0.8025\n",
      "Epoch 3/9\n",
      "8196/8196 [==============================] - 48s 6ms/step - loss: 0.4067 - acc: 0.8142\n",
      "Epoch 4/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.3896 - acc: 0.8260\n",
      "Epoch 5/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.3706 - acc: 0.8335\n",
      "Epoch 6/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.3556 - acc: 0.8442\n",
      "Epoch 7/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.3375 - acc: 0.8521\n",
      "Epoch 8/9\n",
      "8196/8196 [==============================] - 49s 6ms/step - loss: 0.3191 - acc: 0.8599\n",
      "Epoch 9/9\n",
      "8196/8196 [==============================] - 58s 7ms/step - loss: 0.2975 - acc: 0.8702\n",
      "2\n",
      "Epoch 1/12\n",
      "8196/8196 [==============================] - 53s 6ms/step - loss: 0.4959 - acc: 0.7607\n",
      "Epoch 2/12\n",
      "8196/8196 [==============================] - 39s 5ms/step - loss: 0.4268 - acc: 0.8057\n",
      "Epoch 3/12\n",
      "8196/8196 [==============================] - 39s 5ms/step - loss: 0.3903 - acc: 0.8262\n",
      "Epoch 4/12\n",
      "8196/8196 [==============================] - 39s 5ms/step - loss: 0.3631 - acc: 0.8374\n",
      "Epoch 5/12\n",
      "8196/8196 [==============================] - 38s 5ms/step - loss: 0.3385 - acc: 0.8511\n",
      "Epoch 6/12\n",
      "8196/8196 [==============================] - 38s 5ms/step - loss: 0.3166 - acc: 0.8639\n",
      "Epoch 7/12\n",
      "8196/8196 [==============================] - 38s 5ms/step - loss: 0.2914 - acc: 0.8783\n",
      "Epoch 8/12\n",
      "8196/8196 [==============================] - 38s 5ms/step - loss: 0.2731 - acc: 0.8884\n",
      "Epoch 9/12\n",
      "8196/8196 [==============================] - 38s 5ms/step - loss: 0.2484 - acc: 0.8993\n",
      "Epoch 10/12\n",
      "8196/8196 [==============================] - 40s 5ms/step - loss: 0.2297 - acc: 0.9063\n",
      "Epoch 11/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.2063 - acc: 0.9170\n",
      "Epoch 12/12\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.1995 - acc: 0.9214\n",
      "3\n",
      "Epoch 1/15\n",
      "8196/8196 [==============================] - 44s 5ms/step - loss: 0.5270 - acc: 0.7348\n",
      "Epoch 2/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.4496 - acc: 0.7946\n",
      "Epoch 3/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.4131 - acc: 0.8127\n",
      "Epoch 4/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.3835 - acc: 0.8332\n",
      "Epoch 5/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.3626 - acc: 0.8423\n",
      "Epoch 6/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.3335 - acc: 0.8596\n",
      "Epoch 7/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.3177 - acc: 0.8644\n",
      "Epoch 8/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.2913 - acc: 0.8804\n",
      "Epoch 9/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.2711 - acc: 0.8897\n",
      "Epoch 10/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.2536 - acc: 0.8984\n",
      "Epoch 11/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.2396 - acc: 0.9044\n",
      "Epoch 12/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.2217 - acc: 0.9119\n",
      "Epoch 13/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2171 - acc: 0.9158\n",
      "Epoch 14/15\n",
      "8196/8196 [==============================] - 29s 4ms/step - loss: 0.1994 - acc: 0.9220\n",
      "Epoch 15/15\n",
      "8196/8196 [==============================] - 29s 3ms/step - loss: 0.1945 - acc: 0.9263\n",
      "----------------------itr = 6--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_122 (Embedding)    (None, 20, 400)           4124800   \n",
      "_________________________________________________________________\n",
      "dropout_211 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_31 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_212 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,215,303\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,124,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_123 (Embedding)    (None, 20, 400)           4124800   \n",
      "_________________________________________________________________\n",
      "bidirectional_61 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_213 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,667,267\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,124,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_124 (Embedding)    (None, 20, 400)           4124800   \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_214 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_62 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_215 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,818,675\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,124,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_125 (Embedding)    (None, 20, 400)           4124800   \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_216 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_93 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_217 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,791,939\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,124,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "8196/8196 [==============================] - 22s 3ms/step - loss: 0.5753 - acc: 0.7032\n",
      "Epoch 2/7\n",
      "8196/8196 [==============================] - 7s 901us/step - loss: 0.5091 - acc: 0.7539\n",
      "Epoch 3/7\n",
      "8196/8196 [==============================] - 7s 906us/step - loss: 0.4775 - acc: 0.7738\n",
      "Epoch 4/7\n",
      "8196/8196 [==============================] - 7s 913us/step - loss: 0.4658 - acc: 0.7825\n",
      "Epoch 5/7\n",
      "8196/8196 [==============================] - 7s 911us/step - loss: 0.4477 - acc: 0.7917\n",
      "Epoch 6/7\n",
      "8196/8196 [==============================] - 8s 968us/step - loss: 0.4424 - acc: 0.7936\n",
      "Epoch 7/7\n",
      "8196/8196 [==============================] - 7s 872us/step - loss: 0.4411 - acc: 0.7978\n",
      "1\n",
      "Epoch 1/9\n",
      "8196/8196 [==============================] - 64s 8ms/step - loss: 0.4995 - acc: 0.7594\n",
      "Epoch 2/9\n",
      "8196/8196 [==============================] - 48s 6ms/step - loss: 0.4344 - acc: 0.8011\n",
      "Epoch 3/9\n",
      "8196/8196 [==============================] - 48s 6ms/step - loss: 0.4119 - acc: 0.8132\n",
      "Epoch 4/9\n",
      "8196/8196 [==============================] - 50s 6ms/step - loss: 0.3932 - acc: 0.8265\n",
      "Epoch 5/9\n",
      "8196/8196 [==============================] - 42s 5ms/step - loss: 0.3788 - acc: 0.8314\n",
      "Epoch 6/9\n",
      "8196/8196 [==============================] - 42s 5ms/step - loss: 0.3585 - acc: 0.8406\n",
      "Epoch 7/9\n",
      "8196/8196 [==============================] - 46s 6ms/step - loss: 0.3415 - acc: 0.8501\n",
      "Epoch 8/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.3185 - acc: 0.8624\n",
      "Epoch 9/9\n",
      "8196/8196 [==============================] - 50s 6ms/step - loss: 0.3032 - acc: 0.8724\n",
      "2\n",
      "Epoch 1/12\n",
      "8196/8196 [==============================] - 48s 6ms/step - loss: 0.4950 - acc: 0.7630\n",
      "Epoch 2/12\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.4203 - acc: 0.8091\n",
      "Epoch 3/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.3936 - acc: 0.8227\n",
      "Epoch 4/12\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.3630 - acc: 0.8394\n",
      "Epoch 5/12\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.3415 - acc: 0.8516\n",
      "Epoch 6/12\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.3165 - acc: 0.8656\n",
      "Epoch 7/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.2873 - acc: 0.8802\n",
      "Epoch 8/12\n",
      "8196/8196 [==============================] - 39s 5ms/step - loss: 0.2728 - acc: 0.8858\n",
      "Epoch 9/12\n",
      "8196/8196 [==============================] - 38s 5ms/step - loss: 0.2484 - acc: 0.8998\n",
      "Epoch 10/12\n",
      "8196/8196 [==============================] - 37s 5ms/step - loss: 0.2291 - acc: 0.9064\n",
      "Epoch 11/12\n",
      "8196/8196 [==============================] - 36s 4ms/step - loss: 0.2076 - acc: 0.9176\n",
      "Epoch 12/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.1946 - acc: 0.9203: 1s - loss: 0\n",
      "3\n",
      "Epoch 1/15\n",
      "8196/8196 [==============================] - 49s 6ms/step - loss: 0.5188 - acc: 0.7456\n",
      "Epoch 2/15\n",
      "8196/8196 [==============================] - 33s 4ms/step - loss: 0.4376 - acc: 0.7993\n",
      "Epoch 3/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.4063 - acc: 0.8190\n",
      "Epoch 4/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.3820 - acc: 0.8324\n",
      "Epoch 5/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.3547 - acc: 0.8461\n",
      "Epoch 6/15\n",
      "8196/8196 [==============================] - 28s 3ms/step - loss: 0.3350 - acc: 0.8595\n",
      "Epoch 7/15\n",
      "8196/8196 [==============================] - 28s 3ms/step - loss: 0.3111 - acc: 0.8698\n",
      "Epoch 8/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.2904 - acc: 0.8812\n",
      "Epoch 9/15\n",
      "8196/8196 [==============================] - 29s 4ms/step - loss: 0.2756 - acc: 0.8872\n",
      "Epoch 10/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2543 - acc: 0.8983\n",
      "Epoch 11/15\n",
      "8196/8196 [==============================] - 29s 4ms/step - loss: 0.2387 - acc: 0.9043\n",
      "Epoch 12/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2313 - acc: 0.9074\n",
      "Epoch 13/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2141 - acc: 0.9146\n",
      "Epoch 14/15\n",
      "8196/8196 [==============================] - 29s 4ms/step - loss: 0.2073 - acc: 0.9180\n",
      "Epoch 15/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.1948 - acc: 0.9229\n",
      "----------------------itr = 7--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_126 (Embedding)    (None, 20, 400)           4105200   \n",
      "_________________________________________________________________\n",
      "dropout_218 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_32 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_219 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,195,703\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,105,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_127 (Embedding)    (None, 20, 400)           4105200   \n",
      "_________________________________________________________________\n",
      "bidirectional_63 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_220 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,647,667\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,105,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_128 (Embedding)    (None, 20, 400)           4105200   \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_221 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_64 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_222 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,799,075\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,105,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_129 (Embedding)    (None, 20, 400)           4105200   \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_223 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_96 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_224 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,772,339\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,105,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "8196/8196 [==============================] - 23s 3ms/step - loss: 0.5714 - acc: 0.7075\n",
      "Epoch 2/7\n",
      "8196/8196 [==============================] - 7s 856us/step - loss: 0.5084 - acc: 0.7580\n",
      "Epoch 3/7\n",
      "8196/8196 [==============================] - 7s 852us/step - loss: 0.4807 - acc: 0.7694\n",
      "Epoch 4/7\n",
      "8196/8196 [==============================] - 7s 861us/step - loss: 0.4638 - acc: 0.7817\n",
      "Epoch 5/7\n",
      "8196/8196 [==============================] - 7s 814us/step - loss: 0.4475 - acc: 0.7925\n",
      "Epoch 6/7\n",
      "8196/8196 [==============================] - 7s 858us/step - loss: 0.4445 - acc: 0.7947\n",
      "Epoch 7/7\n",
      "8196/8196 [==============================] - 8s 925us/step - loss: 0.4279 - acc: 0.8022\n",
      "1\n",
      "Epoch 1/9\n",
      "8196/8196 [==============================] - 67s 8ms/step - loss: 0.4965 - acc: 0.7615\n",
      "Epoch 2/9\n",
      "8196/8196 [==============================] - 48s 6ms/step - loss: 0.4314 - acc: 0.8030\n",
      "Epoch 3/9\n",
      "8196/8196 [==============================] - 49s 6ms/step - loss: 0.4071 - acc: 0.8154\n",
      "Epoch 4/9\n",
      "8196/8196 [==============================] - 48s 6ms/step - loss: 0.3948 - acc: 0.8214\n",
      "Epoch 5/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.3728 - acc: 0.8333\n",
      "Epoch 6/9\n",
      "8196/8196 [==============================] - 47s 6ms/step - loss: 0.3587 - acc: 0.8426\n",
      "Epoch 7/9\n",
      "8196/8196 [==============================] - 51s 6ms/step - loss: 0.3370 - acc: 0.8526\n",
      "Epoch 8/9\n",
      "8196/8196 [==============================] - 50s 6ms/step - loss: 0.3227 - acc: 0.8582\n",
      "Epoch 9/9\n",
      "8196/8196 [==============================] - 52s 6ms/step - loss: 0.3020 - acc: 0.8690\n",
      "2\n",
      "Epoch 1/12\n",
      "8196/8196 [==============================] - 54s 7ms/step - loss: 0.4987 - acc: 0.7601\n",
      "Epoch 2/12\n",
      "8196/8196 [==============================] - 37s 4ms/step - loss: 0.4227 - acc: 0.8070: 1\n",
      "Epoch 3/12\n",
      "8196/8196 [==============================] - 37s 5ms/step - loss: 0.3920 - acc: 0.8231\n",
      "Epoch 4/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.3653 - acc: 0.8387\n",
      "Epoch 5/12\n",
      "8196/8196 [==============================] - 37s 4ms/step - loss: 0.3394 - acc: 0.8516\n",
      "Epoch 6/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.3106 - acc: 0.8683\n",
      "Epoch 7/12\n",
      "8196/8196 [==============================] - 34s 4ms/step - loss: 0.2862 - acc: 0.8811\n",
      "Epoch 8/12\n",
      "8196/8196 [==============================] - 35s 4ms/step - loss: 0.2605 - acc: 0.8906\n",
      "Epoch 9/12\n",
      "8196/8196 [==============================] - 36s 4ms/step - loss: 0.2379 - acc: 0.9027\n",
      "Epoch 10/12\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.2226 - acc: 0.9077\n",
      "Epoch 11/12\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.2075 - acc: 0.9169\n",
      "Epoch 12/12\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.1944 - acc: 0.9222\n",
      "3\n",
      "Epoch 1/15\n",
      "8196/8196 [==============================] - 42s 5ms/step - loss: 0.5231 - acc: 0.7423\n",
      "Epoch 2/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.4443 - acc: 0.7969\n",
      "Epoch 3/15\n",
      "8196/8196 [==============================] - 28s 3ms/step - loss: 0.4141 - acc: 0.8144\n",
      "Epoch 4/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.3841 - acc: 0.8300\n",
      "Epoch 5/15\n",
      "8196/8196 [==============================] - 27s 3ms/step - loss: 0.3601 - acc: 0.8447\n",
      "Epoch 6/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.3382 - acc: 0.8534\n",
      "Epoch 7/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.3122 - acc: 0.8657\n",
      "Epoch 8/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2916 - acc: 0.8762\n",
      "Epoch 9/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2765 - acc: 0.8866\n",
      "Epoch 10/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2586 - acc: 0.8954\n",
      "Epoch 11/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2451 - acc: 0.9008\n",
      "Epoch 12/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2285 - acc: 0.9085\n",
      "Epoch 13/15\n",
      "8196/8196 [==============================] - 30s 4ms/step - loss: 0.2178 - acc: 0.9134\n",
      "Epoch 14/15\n",
      "8196/8196 [==============================] - 31s 4ms/step - loss: 0.2066 - acc: 0.9187\n",
      "Epoch 15/15\n",
      "8196/8196 [==============================] - 32s 4ms/step - loss: 0.1951 - acc: 0.9242\n",
      "----------------------itr = 8--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_130 (Embedding)    (None, 20, 400)           4090000   \n",
      "_________________________________________________________________\n",
      "dropout_225 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_33 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_226 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,180,503\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,090,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_131 (Embedding)    (None, 20, 400)           4090000   \n",
      "_________________________________________________________________\n",
      "bidirectional_65 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_227 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,632,467\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,090,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_132 (Embedding)    (None, 20, 400)           4090000   \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_228 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_66 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_229 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,783,875\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,090,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_133 (Embedding)    (None, 20, 400)           4090000   \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_230 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_99 (LSTM)               (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_231 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,757,139\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,090,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "8198/8198 [==============================] - 23s 3ms/step - loss: 0.5724 - acc: 0.7064\n",
      "Epoch 2/7\n",
      "8198/8198 [==============================] - 7s 879us/step - loss: 0.5056 - acc: 0.7583\n",
      "Epoch 3/7\n",
      "8198/8198 [==============================] - 8s 926us/step - loss: 0.4835 - acc: 0.7690\n",
      "Epoch 4/7\n",
      "8198/8198 [==============================] - 7s 834us/step - loss: 0.4640 - acc: 0.7804\n",
      "Epoch 5/7\n",
      "8198/8198 [==============================] - 7s 853us/step - loss: 0.4496 - acc: 0.7916\n",
      "Epoch 6/7\n",
      "8198/8198 [==============================] - 7s 888us/step - loss: 0.4402 - acc: 0.7937\n",
      "Epoch 7/7\n",
      "8198/8198 [==============================] - 8s 937us/step - loss: 0.4340 - acc: 0.8005\n",
      "1\n",
      "Epoch 1/9\n",
      "8198/8198 [==============================] - 69s 8ms/step - loss: 0.4994 - acc: 0.7594\n",
      "Epoch 2/9\n",
      "8198/8198 [==============================] - 52s 6ms/step - loss: 0.4316 - acc: 0.8039\n",
      "Epoch 3/9\n",
      "8198/8198 [==============================] - 46s 6ms/step - loss: 0.4072 - acc: 0.8169\n",
      "Epoch 4/9\n",
      "8198/8198 [==============================] - 58s 7ms/step - loss: 0.3880 - acc: 0.8248\n",
      "Epoch 5/9\n",
      "8198/8198 [==============================] - 56s 7ms/step - loss: 0.3713 - acc: 0.8348\n",
      "Epoch 6/9\n",
      "8198/8198 [==============================] - 52s 6ms/step - loss: 0.3570 - acc: 0.8443\n",
      "Epoch 7/9\n",
      "8198/8198 [==============================] - 50s 6ms/step - loss: 0.3343 - acc: 0.8542\n",
      "Epoch 8/9\n",
      "8198/8198 [==============================] - 50s 6ms/step - loss: 0.3203 - acc: 0.8606\n",
      "Epoch 9/9\n",
      "8198/8198 [==============================] - 51s 6ms/step - loss: 0.2996 - acc: 0.8703\n",
      "2\n",
      "Epoch 1/12\n",
      "8198/8198 [==============================] - 57s 7ms/step - loss: 0.4939 - acc: 0.7606\n",
      "Epoch 2/12\n",
      "8198/8198 [==============================] - 37s 4ms/step - loss: 0.4220 - acc: 0.8087\n",
      "Epoch 3/12\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.3903 - acc: 0.8254\n",
      "Epoch 4/12\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.3622 - acc: 0.8377\n",
      "Epoch 5/12\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.3371 - acc: 0.8553\n",
      "Epoch 6/12\n",
      "8198/8198 [==============================] - 34s 4ms/step - loss: 0.3108 - acc: 0.8668\n",
      "Epoch 7/12\n",
      "8198/8198 [==============================] - 34s 4ms/step - loss: 0.2876 - acc: 0.8805\n",
      "Epoch 8/12\n",
      "8198/8198 [==============================] - 34s 4ms/step - loss: 0.2650 - acc: 0.8901\n",
      "Epoch 9/12\n",
      "8198/8198 [==============================] - 34s 4ms/step - loss: 0.2436 - acc: 0.9010\n",
      "Epoch 10/12\n",
      "8198/8198 [==============================] - 34s 4ms/step - loss: 0.2270 - acc: 0.9080\n",
      "Epoch 11/12\n",
      "8198/8198 [==============================] - 34s 4ms/step - loss: 0.2051 - acc: 0.9180\n",
      "Epoch 12/12\n",
      "8198/8198 [==============================] - 34s 4ms/step - loss: 0.1895 - acc: 0.9251\n",
      "3\n",
      "Epoch 1/15\n",
      "8198/8198 [==============================] - 46s 6ms/step - loss: 0.5206 - acc: 0.7420\n",
      "Epoch 2/15\n",
      "8198/8198 [==============================] - 30s 4ms/step - loss: 0.4471 - acc: 0.7938\n",
      "Epoch 3/15\n",
      "8198/8198 [==============================] - 29s 4ms/step - loss: 0.4078 - acc: 0.8198\n",
      "Epoch 4/15\n",
      "8198/8198 [==============================] - 27s 3ms/step - loss: 0.3799 - acc: 0.8301\n",
      "Epoch 5/15\n",
      "8198/8198 [==============================] - 27s 3ms/step - loss: 0.3582 - acc: 0.8450\n",
      "Epoch 6/15\n",
      "8198/8198 [==============================] - 27s 3ms/step - loss: 0.3265 - acc: 0.8621\n",
      "Epoch 7/15\n",
      "8198/8198 [==============================] - 27s 3ms/step - loss: 0.3139 - acc: 0.8684\n",
      "Epoch 8/15\n",
      "8198/8198 [==============================] - 27s 3ms/step - loss: 0.2832 - acc: 0.8851\n",
      "Epoch 9/15\n",
      "8198/8198 [==============================] - 27s 3ms/step - loss: 0.2686 - acc: 0.8925\n",
      "Epoch 10/15\n",
      "8198/8198 [==============================] - 27s 3ms/step - loss: 0.2545 - acc: 0.8992\n",
      "Epoch 11/15\n",
      "8198/8198 [==============================] - 27s 3ms/step - loss: 0.2384 - acc: 0.9071\n",
      "Epoch 12/15\n",
      "8198/8198 [==============================] - 27s 3ms/step - loss: 0.2249 - acc: 0.9123\n",
      "Epoch 13/15\n",
      "8198/8198 [==============================] - 27s 3ms/step - loss: 0.2119 - acc: 0.9161\n",
      "Epoch 14/15\n",
      "8198/8198 [==============================] - 28s 3ms/step - loss: 0.2015 - acc: 0.9208\n",
      "Epoch 15/15\n",
      "8198/8198 [==============================] - 28s 3ms/step - loss: 0.1862 - acc: 0.9289\n",
      "----------------------itr = 9--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_134 (Embedding)    (None, 20, 400)           4092000   \n",
      "_________________________________________________________________\n",
      "dropout_232 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_34 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_233 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,182,503\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,092,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_135 (Embedding)    (None, 20, 400)           4092000   \n",
      "_________________________________________________________________\n",
      "bidirectional_67 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_234 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,634,467\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,092,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_136 (Embedding)    (None, 20, 400)           4092000   \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_235 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_68 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_236 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,785,875\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,092,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_137 (Embedding)    (None, 20, 400)           4092000   \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_237 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_102 (LSTM)              (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_238 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,759,139\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,092,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "8198/8198 [==============================] - 25s 3ms/step - loss: 0.5749 - acc: 0.7048\n",
      "Epoch 2/7\n",
      "8198/8198 [==============================] - 7s 855us/step - loss: 0.5081 - acc: 0.7534\n",
      "Epoch 3/7\n",
      "8198/8198 [==============================] - 7s 834us/step - loss: 0.4844 - acc: 0.7685\n",
      "Epoch 4/7\n",
      "8198/8198 [==============================] - 7s 856us/step - loss: 0.4671 - acc: 0.7789\n",
      "Epoch 5/7\n",
      "8198/8198 [==============================] - 7s 883us/step - loss: 0.4586 - acc: 0.7830\n",
      "Epoch 6/7\n",
      "8198/8198 [==============================] - 8s 944us/step - loss: 0.4469 - acc: 0.7913\n",
      "Epoch 7/7\n",
      "8198/8198 [==============================] - 8s 932us/step - loss: 0.4370 - acc: 0.7971\n",
      "1\n",
      "Epoch 1/9\n",
      "8198/8198 [==============================] - 69s 8ms/step - loss: 0.4974 - acc: 0.7573\n",
      "Epoch 2/9\n",
      "8198/8198 [==============================] - 50s 6ms/step - loss: 0.4370 - acc: 0.7984\n",
      "Epoch 3/9\n",
      "8198/8198 [==============================] - 52s 6ms/step - loss: 0.4087 - acc: 0.8136\n",
      "Epoch 4/9\n",
      "8198/8198 [==============================] - 53s 6ms/step - loss: 0.3925 - acc: 0.8233\n",
      "Epoch 5/9\n",
      "8198/8198 [==============================] - 52s 6ms/step - loss: 0.3744 - acc: 0.8317\n",
      "Epoch 6/9\n",
      "8198/8198 [==============================] - 51s 6ms/step - loss: 0.3566 - acc: 0.8399\n",
      "Epoch 7/9\n",
      "8198/8198 [==============================] - 55s 7ms/step - loss: 0.3355 - acc: 0.8523\n",
      "Epoch 8/9\n",
      "8198/8198 [==============================] - 55s 7ms/step - loss: 0.3198 - acc: 0.8607\n",
      "Epoch 9/9\n",
      "8198/8198 [==============================] - 56s 7ms/step - loss: 0.3008 - acc: 0.8683\n",
      "2\n",
      "Epoch 1/12\n",
      "8198/8198 [==============================] - 54s 7ms/step - loss: 0.4942 - acc: 0.7595\n",
      "Epoch 2/12\n",
      "8198/8198 [==============================] - 37s 4ms/step - loss: 0.4225 - acc: 0.8060\n",
      "Epoch 3/12\n",
      "8198/8198 [==============================] - 36s 4ms/step - loss: 0.3903 - acc: 0.8248\n",
      "Epoch 4/12\n",
      "8198/8198 [==============================] - 36s 4ms/step - loss: 0.3603 - acc: 0.8421\n",
      "Epoch 5/12\n",
      "8198/8198 [==============================] - 36s 4ms/step - loss: 0.3380 - acc: 0.8510\n",
      "Epoch 6/12\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.3131 - acc: 0.8660\n",
      "Epoch 7/12\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.2842 - acc: 0.8790\n",
      "Epoch 8/12\n",
      "8198/8198 [==============================] - 36s 4ms/step - loss: 0.2699 - acc: 0.8871\n",
      "Epoch 9/12\n",
      "8198/8198 [==============================] - 38s 5ms/step - loss: 0.2404 - acc: 0.9017\n",
      "Epoch 10/12\n",
      "8198/8198 [==============================] - 34s 4ms/step - loss: 0.2223 - acc: 0.9103\n",
      "Epoch 11/12\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.2027 - acc: 0.9166\n",
      "Epoch 12/12\n",
      "8198/8198 [==============================] - 36s 4ms/step - loss: 0.1870 - acc: 0.9259\n",
      "3\n",
      "Epoch 1/15\n",
      "8198/8198 [==============================] - 47s 6ms/step - loss: 0.5297 - acc: 0.7367\n",
      "Epoch 2/15\n",
      "8198/8198 [==============================] - 30s 4ms/step - loss: 0.4475 - acc: 0.7916\n",
      "Epoch 3/15\n",
      "8198/8198 [==============================] - 30s 4ms/step - loss: 0.4090 - acc: 0.8155\n",
      "Epoch 4/15\n",
      "8198/8198 [==============================] - 30s 4ms/step - loss: 0.3799 - acc: 0.8328\n",
      "Epoch 5/15\n",
      "8198/8198 [==============================] - 30s 4ms/step - loss: 0.3614 - acc: 0.8392\n",
      "Epoch 6/15\n",
      "8198/8198 [==============================] - 30s 4ms/step - loss: 0.3363 - acc: 0.8536\n",
      "Epoch 7/15\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.3106 - acc: 0.8707\n",
      "Epoch 8/15\n",
      "8198/8198 [==============================] - 29s 4ms/step - loss: 0.2917 - acc: 0.8787\n",
      "Epoch 9/15\n",
      "8198/8198 [==============================] - 34s 4ms/step - loss: 0.2744 - acc: 0.8891\n",
      "Epoch 10/15\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.2582 - acc: 0.8964\n",
      "Epoch 11/15\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.2457 - acc: 0.8994\n",
      "Epoch 12/15\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.2239 - acc: 0.9110\n",
      "Epoch 13/15\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.2104 - acc: 0.9179\n",
      "Epoch 14/15\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.2001 - acc: 0.9219: 0s - loss: 0.200\n",
      "Epoch 15/15\n",
      "8198/8198 [==============================] - 33s 4ms/step - loss: 0.1922 - acc: 0.9253\n",
      "----------------------itr = 10--------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_138 (Embedding)    (None, 20, 400)           4076000   \n",
      "_________________________________________________________________\n",
      "dropout_239 (Dropout)        (None, 20, 400)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 19, 100)           80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_35 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_240 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,166,503\n",
      "Trainable params: 90,503\n",
      "Non-trainable params: 4,076,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_139 (Embedding)    (None, 20, 400)           4076000   \n",
      "_________________________________________________________________\n",
      "bidirectional_69 (Bidirectio (None, 256)               541696    \n",
      "_________________________________________________________________\n",
      "dropout_241 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,618,467\n",
      "Trainable params: 542,467\n",
      "Non-trainable params: 4,076,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_140 (Embedding)    (None, 20, 400)           4076000   \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_242 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_70 (Bidirectio (None, 32)                53376     \n",
      "_________________________________________________________________\n",
      "dropout_243 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,769,875\n",
      "Trainable params: 693,875\n",
      "Non-trainable params: 4,076,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_141 (Embedding)    (None, 20, 400)           4076000   \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 17, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_244 (Dropout)        (None, 17, 400)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "lstm_105 (LSTM)              (None, 16)                26688     \n",
      "_________________________________________________________________\n",
      "dropout_245 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,743,139\n",
      "Trainable params: 667,139\n",
      "Non-trainable params: 4,076,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "8198/8198 [==============================] - 24s 3ms/step - loss: 0.5695 - acc: 0.7096\n",
      "Epoch 2/7\n",
      "8198/8198 [==============================] - 7s 836us/step - loss: 0.5089 - acc: 0.7534\n",
      "Epoch 3/7\n",
      "8198/8198 [==============================] - 7s 830us/step - loss: 0.4807 - acc: 0.7715\n",
      "Epoch 4/7\n",
      "8198/8198 [==============================] - 7s 843us/step - loss: 0.4666 - acc: 0.7782\n",
      "Epoch 5/7\n",
      "8198/8198 [==============================] - 7s 865us/step - loss: 0.4539 - acc: 0.7893\n",
      "Epoch 6/7\n",
      "8198/8198 [==============================] - 7s 876us/step - loss: 0.4473 - acc: 0.7898\n",
      "Epoch 7/7\n",
      "8198/8198 [==============================] - 7s 849us/step - loss: 0.4390 - acc: 0.7965\n",
      "1\n",
      "Epoch 1/9\n",
      "8198/8198 [==============================] - 68s 8ms/step - loss: 0.4953 - acc: 0.7619\n",
      "Epoch 2/9\n",
      "8198/8198 [==============================] - 51s 6ms/step - loss: 0.4322 - acc: 0.8029\n",
      "Epoch 3/9\n",
      "8198/8198 [==============================] - 53s 6ms/step - loss: 0.4087 - acc: 0.8159\n",
      "Epoch 4/9\n",
      "8198/8198 [==============================] - 51s 6ms/step - loss: 0.3879 - acc: 0.8239: 0s - loss: 0.3881 - acc: 0.8\n",
      "Epoch 5/9\n",
      "8198/8198 [==============================] - 56s 7ms/step - loss: 0.3701 - acc: 0.8375\n",
      "Epoch 6/9\n",
      "8198/8198 [==============================] - 49s 6ms/step - loss: 0.3538 - acc: 0.8416\n",
      "Epoch 7/9\n",
      "8198/8198 [==============================] - 50s 6ms/step - loss: 0.3381 - acc: 0.8524\n",
      "Epoch 8/9\n",
      "8198/8198 [==============================] - 46s 6ms/step - loss: 0.3149 - acc: 0.8632\n",
      "Epoch 9/9\n",
      "8198/8198 [==============================] - 52s 6ms/step - loss: 0.2994 - acc: 0.8727\n",
      "2\n",
      "Epoch 1/12\n",
      "8198/8198 [==============================] - 51s 6ms/step - loss: 0.4943 - acc: 0.7597\n",
      "Epoch 2/12\n",
      "8198/8198 [==============================] - 32s 4ms/step - loss: 0.4185 - acc: 0.8088\n",
      "Epoch 3/12\n",
      "8198/8198 [==============================] - 32s 4ms/step - loss: 0.3884 - acc: 0.8252\n",
      "Epoch 4/12\n",
      "8198/8198 [==============================] - 32s 4ms/step - loss: 0.3619 - acc: 0.8405\n",
      "Epoch 5/12\n",
      "8198/8198 [==============================] - 32s 4ms/step - loss: 0.3390 - acc: 0.8553\n",
      "Epoch 6/12\n",
      "8198/8198 [==============================] - 32s 4ms/step - loss: 0.3106 - acc: 0.8693\n",
      "Epoch 7/12\n",
      "8198/8198 [==============================] - 37s 4ms/step - loss: 0.2854 - acc: 0.8814\n",
      "Epoch 8/12\n",
      "8198/8198 [==============================] - 32s 4ms/step - loss: 0.2637 - acc: 0.8897\n",
      "Epoch 9/12\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.2398 - acc: 0.9034\n",
      "Epoch 10/12\n",
      "8198/8198 [==============================] - 38s 5ms/step - loss: 0.2179 - acc: 0.9107\n",
      "Epoch 11/12\n",
      "8198/8198 [==============================] - 40s 5ms/step - loss: 0.2128 - acc: 0.9168\n",
      "Epoch 12/12\n",
      "8198/8198 [==============================] - 36s 4ms/step - loss: 0.1918 - acc: 0.9246\n",
      "3\n",
      "Epoch 1/15\n",
      "8198/8198 [==============================] - 50s 6ms/step - loss: 0.5184 - acc: 0.7413\n",
      "Epoch 2/15\n",
      "8198/8198 [==============================] - 33s 4ms/step - loss: 0.4502 - acc: 0.7900\n",
      "Epoch 3/15\n",
      "8198/8198 [==============================] - 33s 4ms/step - loss: 0.4115 - acc: 0.8153\n",
      "Epoch 4/15\n",
      "8198/8198 [==============================] - 32s 4ms/step - loss: 0.3846 - acc: 0.8324\n",
      "Epoch 5/15\n",
      "8198/8198 [==============================] - 33s 4ms/step - loss: 0.3606 - acc: 0.8432\n",
      "Epoch 6/15\n",
      "8198/8198 [==============================] - 35s 4ms/step - loss: 0.3361 - acc: 0.8581\n",
      "Epoch 7/15\n",
      "8198/8198 [==============================] - 31s 4ms/step - loss: 0.3120 - acc: 0.8672\n",
      "Epoch 8/15\n",
      "8198/8198 [==============================] - 34s 4ms/step - loss: 0.2909 - acc: 0.8811\n",
      "Epoch 9/15\n",
      "8198/8198 [==============================] - 31s 4ms/step - loss: 0.2753 - acc: 0.8872\n",
      "Epoch 10/15\n",
      "8198/8198 [==============================] - 32s 4ms/step - loss: 0.2607 - acc: 0.8963\n",
      "Epoch 11/15\n",
      "8198/8198 [==============================] - 31s 4ms/step - loss: 0.2425 - acc: 0.9034\n",
      "Epoch 12/15\n",
      "8198/8198 [==============================] - 31s 4ms/step - loss: 0.2258 - acc: 0.9140\n",
      "Epoch 13/15\n",
      "8198/8198 [==============================] - 30s 4ms/step - loss: 0.2205 - acc: 0.9151\n",
      "Epoch 14/15\n",
      "8198/8198 [==============================] - 32s 4ms/step - loss: 0.2117 - acc: 0.9184\n",
      "Epoch 15/15\n",
      "8198/8198 [==============================] - 30s 4ms/step - loss: 0.1956 - acc: 0.9243\n"
     ]
    }
   ],
   "source": [
    "for train,test in kfold.split(trainX,trainY):\n",
    "    print(\"----------------------itr = {}--------------\".format(count))\n",
    "    stacked_trainX = list(trainX[train])\n",
    "    stacked_trainY = list(trainY[train])\n",
    "    stacked_testX = list(trainX[test])\n",
    "    stacked_testY = list(trainY[test])\n",
    "    \n",
    "    tokenizer = create_tokenizer(stacked_trainX)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    stacked_trainX = encode_text(tokenizer, stacked_trainX, max_len)\n",
    "    stacked_testX = encode_text(tokenizer, stacked_testX, max_len)\n",
    "    stacked_trainY = to_categorical(stacked_trainY,num_classes=number_of_classes)\n",
    "    \n",
    "    embedding_matrix_godin = get_word_embedding_matrix(godin_model,400)\n",
    "    \n",
    "    for i in stacked_testY:\n",
    "        stacked_metalearner_trainY.append(i)\n",
    "    \n",
    "    \n",
    "    base_cnn = cnn(length=max_len,\n",
    "                vocab_size=vocab_size,\n",
    "                n_dense=parameters_cnn['n_dense'],\n",
    "                dropout=parameters_cnn['dropout'],\n",
    "                n_filters=parameters_cnn['n_filters'],\n",
    "                filter_size=int(parameters_cnn['filter_size']),\n",
    "                em = eval(parameters_cnn['em']),\n",
    "                number_of_classes=number_of_classes)\n",
    "\n",
    "    base_bi_lstm = bi_lstm(length=max_len,\n",
    "                            vocab_size=vocab_size,\n",
    "                            dropout=parameters_bi_lstm['dropout'],\n",
    "                            units_out=parameters_bi_lstm['units_out'],\n",
    "                            em=eval(parameters_bi_lstm['em']),\n",
    "                            number_of_classes=number_of_classes)\n",
    "\n",
    "\n",
    "    base_cnn_bi_lstm = cnn_bi_lstm(length=max_len,\n",
    "                                    vocab_size=vocab_size,\n",
    "                                    n_filters=parameters_bi_lstm_cnn['n_filters'],\n",
    "                                    filter_size=parameters_bi_lstm_cnn['filter_size'],\n",
    "                                    em=eval(parameters_bi_lstm_cnn['em']),\n",
    "                                    number_of_classes=number_of_classes,\n",
    "                                    conv_dropout=parameters_bi_lstm_cnn['conv_dropout'],\n",
    "                                    l_or_g_dropout=parameters_bi_lstm_cnn['l_or_g_dropout'],\n",
    "                                    units_out=parameters_bi_lstm_cnn['units_out'])\n",
    "\n",
    "\n",
    "    base_cnn_lstm = cnn_lstm(length=max_len,\n",
    "                                    vocab_size=vocab_size,\n",
    "                                    n_filters=parameters_bi_lstm_cnn['n_filters'],\n",
    "                                    filter_size=parameters_bi_lstm_cnn['filter_size'],\n",
    "                                    em=eval(parameters_bi_lstm_cnn['em']),\n",
    "                                    number_of_classes=number_of_classes,\n",
    "                                    conv_dropout=parameters_bi_lstm_cnn['conv_dropout'],\n",
    "                                    l_or_g_dropout=parameters_bi_lstm_cnn['l_or_g_dropout'],\n",
    "                                    units_out=parameters_bi_lstm_cnn['units_out'])\n",
    "    \n",
    "    stacked_base_models = [(parameters_cnn,base_cnn),(parameters_bi_lstm,base_bi_lstm),(parameters_bi_lstm_cnn,base_cnn_bi_lstm),(parameters_lstm_cnn,base_cnn_lstm)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    temp = np.zeros((len(stacked_testX),len(stacked_base_models)),dtype=np.int64)\n",
    "    for i,m in enumerate(stacked_base_models):\n",
    "        print(i)\n",
    "        history = m[1].fit(stacked_trainX,stacked_trainY,epochs=m[0][\"epoch\"],batch_size=m[0][\"batch\"])\n",
    "        pred = m[1].predict(stacked_testX)\n",
    "        temp[:,i] = [int(np.argmax(x)) for x in pred]\n",
    "    stacked_metalearner_trainX = np.concatenate((stacked_metalearner_trainX, temp), axis=0)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9107"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stacked_metalearner_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9108, 4)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_metalearner_trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_metalearner_trainX = np.delete(stacked_metalearner_trainX, (0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9107, 4)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_metalearner_trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_meta_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_meta_model.fit(stacked_metalearner_trainX, stacked_metalearner_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_class = np.zeros((len(testX),len(stacked_base_models)),dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = [clean_sentence(s) for s in train_sentences]\n",
    "testX = [clean_sentence(s) for s in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 20\n",
      "Vocabulary size: 10940\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(trainX)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "trainX = encode_text(tokenizer, trainX, max_len)\n",
    "testX = encode_text(tokenizer, testX, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,p in enumerate(base_models):\n",
    "    test_pred_class[:,i] = get_pred_class(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_ensemble_pred_class = stacked_meta_model.predict(test_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_ensemble_pred_class = list(stacked_ensemble_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_ensemble_result = get_results(test_labels,stacked_ensemble_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_ensemble_result.insert(0,'stacked_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance.loc[7] = stacked_ensemble_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.623187</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.637957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi_lstm</td>\n",
       "      <td>0.617651</td>\n",
       "      <td>0.654555</td>\n",
       "      <td>0.584686</td>\n",
       "      <td>0.662758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_bi_lstm</td>\n",
       "      <td>0.632167</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.607314</td>\n",
       "      <td>0.672058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.642971</td>\n",
       "      <td>0.669902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_ensemble</td>\n",
       "      <td>0.646064</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>0.682572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>majority_ensemble</td>\n",
       "      <td>0.653894</td>\n",
       "      <td>0.644953</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.682437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blend_ensemble</td>\n",
       "      <td>0.613343</td>\n",
       "      <td>0.677919</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.668149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stacked_ensemble</td>\n",
       "      <td>0.613960</td>\n",
       "      <td>0.678088</td>\n",
       "      <td>0.560914</td>\n",
       "      <td>0.668823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model        f1  precision    recall  accuracy\n",
       "0                cnn  0.623187   0.587997  0.662857  0.637957\n",
       "1            bi_lstm  0.617651   0.654555  0.584686  0.662758\n",
       "2        cnn_bi_lstm  0.632167   0.659142  0.607314  0.672058\n",
       "3           cnn_lstm  0.637507   0.632135  0.642971  0.669902\n",
       "4       avg_ensemble  0.646064   0.659524  0.633143  0.682572\n",
       "5  majority_ensemble  0.653894   0.644953  0.663086  0.682437\n",
       "6     blend_ensemble  0.613343   0.677919  0.560000  0.668149\n",
       "7   stacked_ensemble  0.613960   0.678088  0.560914  0.668823"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance.to_csv('performance.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
