{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import json\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import remove\n",
    "from pprint import pprint\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from gensim.models import KeyedVectors\n",
    "import word2vecReader as godin_embedding\n",
    "import fasttext\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [12,10]\n",
    "from base_learners import cnn,lstm,gru,bi_lstm,bi_gru,cnn_bi_gru,cnn_bi_lstm,cnn_gru,cnn_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(filename,test_flag = False):\n",
    "    data = pd.read_csv(filename, sep=\"\\t\", header=None)\n",
    "    if not test_flag:\n",
    "        data.columns = [\"tweet_id\", \"username\", \"database_id\", \"class\",\"tweet\"]\n",
    "    else:\n",
    "        data.columns = [\"a\", \"b\", \"med\",\"med\", \"tweet\",\"class\",]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data_from_file('dataset/personal_intake_tweets.txt')\n",
    "dev_data = load_data_from_file('dataset/personal_intake_tweets_dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = train_data['tweet'].tolist()+dev_data['tweet'].tolist()\n",
    "train_labels = train_data['class'].tolist()+dev_data['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = load_data_from_file('dataset/task_2_test_full_form.txt',test_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_data['class'].tolist()\n",
    "test_sentences = test_data['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9107, 9107, 7419, 7419)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels),len(train_sentences),len(test_labels),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = [x-1 for x in test_labels]\n",
    "train_labels = [x-1 for x in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = len(set(train_labels))\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1743\n",
      "1 2837\n",
      "2 4527\n"
     ]
    }
   ],
   "source": [
    "for x in range(number_of_classes):\n",
    "    print(x,train_labels.count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1709\n",
      "1 2666\n",
      "2 3044\n"
     ]
    }
   ],
   "source": [
    "for x in range(number_of_classes):\n",
    "    print(x,test_labels.count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    list_punctuation = list(string.punctuation)\n",
    "    for i in list_punctuation:\n",
    "        s = s.replace(i,'')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    #removes links\n",
    "    sentence = re.sub(r'(?P<url>https?://[^\\s]+)', r'', sentence)\n",
    "    # remove @usernames\n",
    "    sentence = re.sub(r\"\\@(\\w+)\", \"\", sentence)\n",
    "    #remove # from #tags\n",
    "    sentence = sentence.replace('#','')\n",
    "    # split into tokens by white space\n",
    "    tokens = sentence.split()\n",
    "    # remove punctuation from each token\n",
    "    # should have used translate but for some reason it breaks on my server\n",
    "    tokens = [remove_punctuation(w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "trainX = [clean_sentence(s) for s in train_sentences]\n",
    "testX = [clean_sentence(s) for s in test_sentences]\n",
    "trainY = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "back_up_for_fasttext = trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(line.split()) for line in trainX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3788., 2996.,  611.,   22.,    4.]),\n",
       " array([ 5, 10, 15, 20, 25, 30]),\n",
       " <a list of 5 Patch objects>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAJCCAYAAAA/XCqxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa76b1fa550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(max(lengths))\n",
    "plt.hist(lengths,bins=[5,10,15,20,25,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_GloVe_embedding(file_name):\n",
    "    print('Loading GloVe word vectors.')\n",
    "    embeddings_index = dict()\n",
    "    f = open(file_name)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_GloVe_embedding_matrix(embeddings_index):\n",
    "    embedding_matrix = np.zeros((vocab_size, 300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fast_text_model(sentences):\n",
    "    try:\n",
    "        m = fasttext.load_model('fast_text_model.bin')\n",
    "        print(\"trained model loaded\")\n",
    "        return m\n",
    "    except:\n",
    "        print(\"traning new model\")\n",
    "        with open('temp_file.txt','w') as temp_file:\n",
    "            for sentence in sentences:\n",
    "                temp_file.write(sentence)\n",
    "        m = fasttext.cbow('temp_file.txt','fast_text_model')\n",
    "        remove('temp_file.txt')\n",
    "        print('model trained')\n",
    "        return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_godin_word_embedding(path):\n",
    "    print(\"Loading Goding model.\")\n",
    "    return godin_embedding.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_google_word2vec(file_name):\n",
    "    print(\"Loading google news word2vec\")\n",
    "    return KeyedVectors.load_word2vec_format(file_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_embedding_matrix(model,dim):\n",
    "    #dim = 300 for google word2vec\n",
    "    #dim = 400 for godin\n",
    "    #dim = 100 for fast text\n",
    "    embedding_matrix = np.zeros((vocab_size,dim))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 20\n",
      "Vocabulary size: 10940\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(trainX)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % max_len)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "trainX = encode_text(tokenizer, trainX, max_len)\n",
    "testX = encode_text(tokenizer, testX, max_len)\n",
    "trainY = to_categorical(trainY,num_classes=number_of_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google news word2vec\n"
     ]
    }
   ],
   "source": [
    "# glove_model = load_GloVe_embedding('word_embeddings/glove.6B.300d.txt')\n",
    "# fast_text_model = load_fast_text_model(back_up_for_fasttext)\n",
    "# godin_model = load_godin_word_embedding(\"word_embeddings/word2vec_twitter_model.bin\")\n",
    "word2vec_model= load_google_word2vec('../word_embeddings/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding_matrix_glove = get_GloVe_embedding_matrix(glove_model)\n",
    "embedding_matrix_word2vec = get_word_embedding_matrix(word2vec_model,300)\n",
    "# embedding_matrix_fast_text = get_word_embedding_matrix(fast_text_model,100)\n",
    "# embedding_matrix_godin = get_word_embedding_matrix(godin_model,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform',name='learning_rate')\n",
    "para_dropout = Categorical(categories=[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],name = 'dropout')\n",
    "# para_em = Categorical(categories=[embedding_matrix_fast_text,embedding_matrix_godin,embedding_matrix_word2vec,embedding_matrix_glove],name='em')\n",
    "para_em = Categorical(categories=['embedding_matrix_word2vec'],name='em')\n",
    "para_em_trainable_flag = Categorical(categories=[True,False],name='em_trainable_flag')\n",
    "para_batch_size = Categorical(categories=[8,16,32,64],name='batch_size')\n",
    "para_epoch = Categorical(categories=[5,10,20,50,100],name='epoch')\n",
    "\n",
    "# para_units_out = Categorical(categories=[64,128,256,512], name='units_out')\n",
    "\n",
    "# para_dropout_cnn_lstm = Categorical(categories=[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],name = 'dropout')\n",
    "\n",
    "para_n_dense = Categorical(categories=[100,200,300,400], name='n_dense')\n",
    "para_n_filters = Categorical(categories=[32,100,200,300],name='n_filters')\n",
    "para_filter_size = Integer(low=1,high=8,name = 'filter_size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_cnn = [para_learning_rate,para_dropout,para_n_dense,para_n_filters,para_filter_size,para_em,para_em_trainable_flag,para_batch_size,para_epoch]\n",
    "# parameters_lstm = [para_learning_rate,para_dropout,para_units_out,para_em,para_em_trainable_flag,para_batch_size,para_epoch]\n",
    "# parameters_cnn_lstm = [para_learning_rate,para_dropout,para_dropout_cnn_lstm,para_units_out,para_n_filters,para_filter_size,para_em,para_em_trainable_flag,para_batch_size,para_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_parameters_cnn = [0.001,0.2,300,100,5,'embedding_matrix_word2vec',True,32,5]\n",
    "# default_parameters_lstm = [0.001,0.2,128,embedding_matrix_word2vec,True,32,20]\n",
    "# default_parameters_cnn_lstm = [0.001,0.2,0.2,128,100,5,embedding_matrix_word2vec,True,32,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = 1\n",
    "record = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f034ff761030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##this will change based on the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0muse_named_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_dense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_filters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mem_trainable_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parameters_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "##this will change based on the model\n",
    "@use_named_args(dimensions=parameters_cnn)\n",
    "def fitness(learning_rate,dropout,n_dense,n_filters,filter_size,em,em_trainable_flag,batch_size,epoch):\n",
    "    global key\n",
    "    global record\n",
    "    global number_of_classes\n",
    "    print('-----------------------------combination no={0}------------------'.format(key))\n",
    "    parameters = {\n",
    "            \"learning_rate\": learning_rate,    \n",
    "            \"dropout\": dropout,\n",
    "            \"n_dense\": n_dense,\n",
    "            \"n_filters\": n_filters,\n",
    "            \"filter_size\": filter_size,\n",
    "            \"em\": em,\n",
    "            \"em_trainable_flag\":em_trainable_flag,\n",
    "            \"batch\": batch_size,\n",
    "            \"epoch\": epoch\n",
    "        }\n",
    "    \n",
    "    pprint(parameters)\n",
    "    \n",
    "    model = cnn(length=max_len,\n",
    "                vocab_size=vocab_size,\n",
    "                n_dense=parameters['n_dense'],\n",
    "                dropout=parameters['dropout'],\n",
    "                learning_rate=parameters['learning_rate'],\n",
    "                n_filters=parameters['n_filters'],\n",
    "                filter_size=int(parameters['filter_size']),\n",
    "                em = eval(parameters['em']),\n",
    "                number_of_classes=number_of_classes,\n",
    "                em_trainable_flag=parameters['em_trainable_flag'])\n",
    "\n",
    "    history = model.fit(trainX,trainY,epochs=parameters[\"epoch\"],batch_size=parameters[\"batch\"])\n",
    "    pred = model.predict(testX)\n",
    "    pred_class = [np.argmax(x) for x in pred]\n",
    "    f1 = f1_score(Y_,pred_labels,labels=[0,1],average='micro')\n",
    "    p = precision_score(Y_,pred_labels,labels=[0,1],average='micro')\n",
    "    r = recall_score(Y_,pred_labels,labels=[0,1],average='micro')\n",
    "    acc = accuracy_score(test_labels,pred_class)\n",
    "    print(f1)\n",
    "    record[key] = {}\n",
    "    record[key][\"parameter\"] = parameters\n",
    "    record[key][\"acc\"] = acc\n",
    "    record[key][\"f1\"] = f1\n",
    "    record[key][\"precision\"] = p\n",
    "    record[key][\"recall\"] = r\n",
    "    with open(\"results/cnn.json\",'w')as fout:\n",
    "        json.dump(record,fout,indent=4)\n",
    "    key+=1\n",
    "    \n",
    "    del model\n",
    "    K.clear_session()\n",
    "    \n",
    "    return -f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------combination no=2------------------\n",
      "{'batch': 32,\n",
      " 'dropout': 0.2,\n",
      " 'em': 'embedding_matrix_word2vec',\n",
      " 'em_trainable_flag': True,\n",
      " 'epoch': 5,\n",
      " 'filter_size': 5,\n",
      " 'learning_rate': 0.001,\n",
      " 'n_dense': 300,\n",
      " 'n_filters': 100}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 24, 300)           5130900   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 20, 100)           150100    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               30300     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1505      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,312,805\n",
      "Trainable params: 5,312,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "9645/9645 [==============================] - 27s 3ms/step - loss: 0.4446 - acc: 0.8009\n",
      "Epoch 2/5\n",
      "9645/9645 [==============================] - 27s 3ms/step - loss: 0.3538 - acc: 0.8366\n",
      "Epoch 3/5\n",
      "9645/9645 [==============================] - 27s 3ms/step - loss: 0.2108 - acc: 0.9137\n",
      "Epoch 4/5\n",
      "9645/9645 [==============================] - 27s 3ms/step - loss: 0.0907 - acc: 0.9663\n",
      "Epoch 5/5\n",
      "9645/9645 [==============================] - 27s 3ms/step - loss: 0.0420 - acc: 0.9857\n",
      "0.41402714932126694\n",
      "-----------------------------combination no=3------------------\n",
      "{'batch': 8,\n",
      " 'dropout': 0.3,\n",
      " 'em': 'embedding_matrix_word2vec',\n",
      " 'em_trainable_flag': True,\n",
      " 'epoch': 10,\n",
      " 'filter_size': 3,\n",
      " 'learning_rate': 0.0030745428370426435,\n",
      " 'n_dense': 100,\n",
      " 'n_filters': 32}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 24, 300)           5130900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 22, 32)            28832     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 505       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,163,537\n",
      "Trainable params: 5,163,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "9645/9645 [==============================] - 77s 8ms/step - loss: 0.4484 - acc: 0.7977\n",
      "Epoch 2/10\n",
      "9645/9645 [==============================] - 79s 8ms/step - loss: 0.3792 - acc: 0.8210\n",
      "Epoch 3/10\n",
      "9645/9645 [==============================] - 77s 8ms/step - loss: 0.2999 - acc: 0.8642\n",
      "Epoch 4/10\n",
      " 856/9645 [=>............................] - ETA: 1:11 - loss: 0.1852 - acc: 0.9189- ETA: 1:12 - loss: 0.1884 - ac"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-59232f39866f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             x0=default_parameters_cnn)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-6b8e5209e1ab>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(learning_rate, dropout, n_dense, n_filters, filter_size, em, em_trainable_flag, batch_size, epoch)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 em_trainable_flag=parameters['em_trainable_flag'])\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mpred_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=parameters_cnn,\n",
    "                            acq_func='EI',\n",
    "                            n_calls=11,\n",
    "                            x0=default_parameters_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters_cnn = {\n",
    "#             \"n_dense\": 250,\n",
    "#             \"dropout\": 0.2,\n",
    "#             \"learning_rate\": 0.001,\n",
    "#             \"n_filters\": 100,\n",
    "#             \"filter_size\": 5,\n",
    "#             \"em\": embedding_matrix_word2vec,\n",
    "#             \"em_trainable_flag\":True,\n",
    "#             \"batch\": 32,\n",
    "#             \"epoch\": 5\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters_lstm_or_gru = {\n",
    "#             \"dropout\": 0.5,\n",
    "#             \"learning_rate\": 0.001,\n",
    "#             \"units_out\": 64,\n",
    "#             \"em\": embedding_matrix_word2vec,\n",
    "#             \"em_trainable_flag\":True,\n",
    "#             \"batch\": 32,\n",
    "#             \"epoch\": 4\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters_cnn_lstm_or_gru = {\n",
    "#             \"n_filters\": 100,\n",
    "#             \"filter_size\": 5,\n",
    "#             \"conv_dropout\": 0.5,\n",
    "#             \"l_or_g_dropout\":0.5,\n",
    "#             \"learning_rate\": 0.001,\n",
    "#             \"units_out\": 64,\n",
    "#             \"em\": embedding_matrix_word2vec,\n",
    "#             \"em_trainable_flag\":True,\n",
    "#             \"batch\": 32,\n",
    "#             \"epoch\": 4\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = cnn(length=max_len,\n",
    "#             vocab_size=vocab_size,\n",
    "#             n_dense=parameters_cnn['n_dense'],\n",
    "#             dropout=parameters_cnn['dropout'],\n",
    "#             learning_rate=parameters_cnn['learning_rate'],\n",
    "#             n_filters=parameters_cnn['n_filters'],\n",
    "#             filter_size=parameters_cnn['filter_size'],\n",
    "#             em = parameters_cnn['em'],\n",
    "#             free_em_dim=parameters_cnn['free_em_dim'],\n",
    "#             number_of_classes=number_of_classes,\n",
    "#             em_trainable_flag=parameters_cnn['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = bi_gru(length=max_len,\n",
    "#              vocab_size=vocab_size,\n",
    "#              learning_rate=parameters_lstm_or_gru['learning_rate'],\n",
    "#              dropout=parameters_lstm_or_gru['dropout'],\n",
    "#              units_out=parameters_lstm_or_gru['units_out'],\n",
    "#              em=parameters_lstm_or_gru['em'],\n",
    "#              number_of_classes=number_of_classes,\n",
    "#              em_trainable_flag=parameters_lstm_or_gru['em_trainable_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = cnn_lstm(length=max_len,\n",
    "#                     vocab_size=vocab_size,\n",
    "#                     n_filters=parameters_cnn_lstm_or_gru['n_filters'],\n",
    "#                     filter_size=parameters_cnn_lstm_or_gru['filter_size'],\n",
    "#                     em=parameters_cnn_lstm_or_gru['em'],\n",
    "#                     number_of_classes=number_of_classes,\n",
    "#                     em_trainable_flag=parameters_cnn_lstm_or_gru['em_trainable_flag'],\n",
    "#                     learning_rate=parameters_cnn_lstm_or_gru['learning_rate'],\n",
    "#                     conv_dropout=parameters_cnn_lstm_or_gru['conv_dropout'],\n",
    "#                     l_or_g_dropout=parameters_cnn_lstm_or_gru['l_or_g_dropout'],\n",
    "#                     units_out=parameters_cnn_lstm_or_gru['units_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
